#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass dlrreport
\use_default_options true
\maintain_unincluded_children false
\language ngerman
\language_package default
\inputencoding utf8
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language german
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Chapter
Implementierung der DLR-Kriging-Verfahren 
\begin_inset CommandInset label
LatexCommand label
name "chap:Implementierung-der-DLR-Kriging-"

\end_inset


\end_layout

\begin_layout Standard
Im Rahmen dieser Arbeit wurde eine Kriging-Software entwickelt und die Implement
ierung eines Multifidelity-Verfahrens in AutoOpti vorgenommen.
 In diesem Kapitel sollen daher die wichtigsten Entwicklungen dargestellt
 werden.
 Hierfür werden im ersten Teil die verwendete Modellierung der Kovarianzfunktion
 und auch die Behandlung von verrauschten Funktionen beschrieben.
 Weiterhin wird eine mögliche Regularisierung der Kovarianzmatrix beschrieben.
 Darauf folgend wird das Training der Kriging-Modelle mithilfe verschiedener
 Minimierungsverfahren beschrieben.
 Das beschriebene RPROP-Minimierungsverfahren ist besonders gut für die
 Problemstellung geeignet.
 Weiterhin wird eine auf das Co-Kriging angepasste Version dieses Verfahrens
 aufgezeigt.
\end_layout

\begin_layout Standard
Da die Verwendung eines Kriging-Verfahrens innerhalb einer größeren Optimierung
 numerisch sehr aufwendig ist, wurden zahlreichen Methoden entwickelt und
 umgesetzt, welche die numerischer Effizienz steigern.
 Diese Methoden werden in den Abschnitten 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:MinimierungsverfahrenTraining"

\end_inset

,
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Umsetzung-der-Entscheidungsfunkt"

\end_inset

 und 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Numerische-Effizienz-steigern"

\end_inset

 vorgestellt.
 
\end_layout

\begin_layout Standard
Als letzter Punkt wird eine in dieser Arbeit entwickelte Analysesoftware
 vorgestellt.
 Mit dieser ist es möglich während einer laufenden Optimierungen die Ersatzmodel
le auf Plausibilität und Effizienz zu überprüfen und evtl.
 Fehler aufzudecken.
\end_layout

\begin_layout Section
Modellierung der Kovarianz- und Korrelationsfunktion 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Kovarianzmatrix"

\end_inset


\end_layout

\begin_layout Standard
In Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Die-Kriging-Verfahren"

\end_inset

 wurden die verschiedenen Kriging-Verfahren beschrieben.
 Innerhalb dieses Kapitels wurden die Begriffe der Kovarianzmatrix und des
 Kovarianzvektors verwendet.
 Um diese aufstellen zu können, ist eine Kovarianzfunktion in der Form 
\begin_inset Formula $cov\left(Z_{g_{1}}^{*}\left(\vec{x_{1}}\right),Z_{g_{2}}^{*}\left(\vec{x_{2}}\right)\right)$
\end_inset

 nötig, wobei 
\begin_inset Formula $\vec{x}_{1},\vec{x}_{2}$
\end_inset

 die Orte von bekannten Stützstellen beschreiben und 
\begin_inset Formula $g_{1},g_{2}\in\left\{ 1,...,s\right\} $
\end_inset

 die jeweiligen Gütestufen.
 Da in der praktischen Anwendung der reale Zufallsprozess 
\begin_inset Formula $Z(\vec{x})$
\end_inset

 nicht bekannt ist und damit auch nicht die Kovarianzfunktion, bedient man
 sich parametrisierter Kovarianzmodelle in der Form 
\begin_inset Formula $cov_{g_{1},g_{2}}\left(\vec{x}_{1},\vec{x_{2}}\right)$
\end_inset

.
 
\end_layout

\begin_layout Standard
Diese Funktionen müssen jedem möglichen Punktepaar eine Kovarianz zuordnen.
 Weiterhin muss die daraus resultierende Matrix positiv definit und symmetrisch
 sein, was die Wahl einer geeigneten Funktion erschwert.
 Das folgende Beispiel zeigt den Aufbau eine beispielhafte Kovarianzmatrix
 
\begin_inset Formula $\mathbf{\mathbf{Cov\in\mathbb{R^{\mathrm{n_{all}\times n_{all}}}}}}$
\end_inset

 für vier verschiedene Samples 
\begin_inset Formula $y_{g}\left(\vec{x}\right)$
\end_inset

 der jeweiligen Gütestufe 
\begin_inset Formula $g\in\left\{ 1,...,s\right\} $
\end_inset

:
\begin_inset Formula 
\begin{equation}
\mathbf{Cov}=\left[\begin{array}{c|cccc}
 & y_{0}\left(\vec{x}_{1}\right) & y_{0}\left(\vec{x}_{2}\right) & y_{1}\left(\vec{x}_{3}\right) & y_{1}\left(\vec{x}_{4}\right)\\
\hline y_{0}\left(\vec{x}_{1}\right) & cov_{0,0}\left(\vec{x}_{1},\vec{x}_{1}\right) & cov_{0,0}\left(\vec{x}_{1},\vec{x}_{2}\right) & cov_{0,1}\left(\vec{x}_{1},\vec{x}_{3}\right) & cov_{0,1}\left(\vec{x}_{1},\vec{x}_{4}\right)\\
y_{0}\left(\vec{x}_{2}\right) & cov_{0,0}\left(\vec{x}_{2},\vec{x}_{1}\right) & cov_{0,0}\left(\vec{x}_{2},\vec{x}_{2}\right) & cov_{0,1}\left(\vec{x}_{2},\vec{x}_{3}\right) & cov_{0,1}\left(\vec{x}_{2},\vec{x}_{4}\right)\\
y_{1}\left(\vec{x}_{3}\right) & cov_{1,0}\left(\vec{x}_{3},\vec{x}_{1}\right) & cov_{1,0}\left(\vec{x}_{3},\vec{x}_{2}\right) & cov_{1,1}\left(\vec{x}_{3},\vec{x}_{3}\right) & cov_{1,1}\left(\vec{x}_{3},\vec{x}_{4}\right)\\
y_{1}\left(\vec{x}_{4}\right) & cov_{1,0}\left(\vec{x}_{4},\vec{x}_{1}\right) & cov_{1,0}\left(\vec{x}_{4},\vec{x}_{2}\right) & cov_{1,1}\left(\vec{x}_{4},\vec{x}_{3}\right) & cov_{1,1}\left(\vec{x}_{4},\vec{x}_{4}\right)
\end{array}\right]\label{eq:KovarianzmatrixBeispiel}
\end{equation}

\end_inset

Um ein solches Modell praktisch nutzbar zu machen, müssen drei verschiedene
 Problemstellungen behandelt werden:
\end_layout

\begin_layout Enumerate
Die Definition der ortsabhängigkeit der Kovarianzfunktion.
 Beispielsweise kann diese nur abhängig vom Radius (radiale Basisfunktionen)
 sein oder nur durch den Verbindungsvektor 
\begin_inset Formula $\vec{h}=\vec{x}_{1}-\vec{x_{2}}$
\end_inset

 beschrieben werden.
 Es gibt auch Modelle, welche eine Abhängigkeit von der absoluten Lage im
 Raum ermöglichen.
 Diese benötigen allerdings eine erhebliche Anzahl an Ersatzmodell-spezifischen
 Parametern (siehe 
\begin_inset CommandInset citation
LatexCommand cite
key "schmidt2003bayesian"

\end_inset

).
 
\end_layout

\begin_layout Enumerate
Es wird ein parametrisiertes Modell für die Kovarianzfunktion benötigt,
 welches zu einer positiv definiten und symmetrischen Matrix führt.
\end_layout

\begin_layout Enumerate
Die darin verwendeten Parameter müssen in einem Trainingsverfahren kalibriert
 werden können.
\end_layout

\begin_layout Standard
Diese Problemstellungen werden in den folgenden zwei Abschnitten behandelt.
\end_layout

\begin_layout Subsection
Ortsabhängigkeit Kovarianzfunktion 
\begin_inset CommandInset label
LatexCommand label
name "sec:Variogramm"

\end_inset


\end_layout

\begin_layout Standard
In diesem Abschnitt wird der Begriff des Variogramms und des Kovariogramms
 erklärt (siehe 
\begin_inset CommandInset citation
LatexCommand cite
key "matheron1963principles"

\end_inset

).
 Diese stellen die Basis für die Kovarianzmodellfunktionen dar und sind
 somit zentraler Bestandteil des Kriging Verfahrens.
 Sei 
\begin_inset Formula $Z\left(\vec{x}\right)$
\end_inset

 ein räumlicher Zufallsprozess, so ist das Variogramm 
\begin_inset Formula $2\gamma\left(\vec{x}_{1},\vec{x}_{2}\right)$
\end_inset

, 
\begin_inset Formula $\vec{x}_{1},\vec{x}_{2}\in\mathbb{R^{\textrm{k}}}$
\end_inset

 definiert über:
\begin_inset Formula 
\begin{align}
2\gamma\left(\vec{x}_{1},\vec{x}_{2}\right) & \coloneqq var\left[Z\left(\vec{x}_{1}\right)-Z\left(\vec{x}_{2}\right)\right]\\
 & =E\left[\left(\left(Z\left(\vec{x}_{1}\right)-Z\left(\vec{x}_{2}\right)\right)-E\left[Z\left(\vec{x}_{1}\right)-Z\left(\vec{x}_{2}\right)\right]\right)^{2}\right]\nonumber \\
 & =E\left[\left(\left(Z\left(\vec{x}_{1}\right)-E\left[Z\left(\vec{x}_{1}\right)\right]\right)-\left(Z\left(\vec{x}_{2}\right)-E\left[Z\left(\vec{x}_{2}\right)\right]\right)\right)^{2}\right]\nonumber 
\end{align}

\end_inset


\begin_inset Formula $\gamma\left(\vec{x}_{1},\vec{x}_{2}\right)$
\end_inset

 wird als Semivariogramm bezeichnet.
 Weiterhin wird das Kovariogramm wie folgt definiert:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
cov\left(\vec{x}_{1},\vec{x}_{2}\right)\coloneqq\frac{1}{2}var\left[Z\left(\vec{x_{1}}\right)\right]+\frac{1}{2}var\left[Z\left(\vec{x_{2}}\right)\right]-\gamma\left(\vec{x}_{1},\vec{x}_{2}\right)
\end{equation}

\end_inset

Einfacher formuliert beschreibt das Variogramm und auch das Kovariogramm
 die räumliche Abhängigkeit eines Punktes zu Nachbarpunkten.
 Es wird die Annahme getroffen, dass dieser räumlicher Zufallsprozess schwach
 stationär ist.
 Die Definition eines räumlich schwach stationären Zufallsprozesses ist
 gegeben durch (vgl.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Cressie1993,Ozkaya2014,akin2013praktische"

\end_inset

): 
\begin_inset Formula 
\begin{align}
E\left[Z\left(\vec{x}\right)\right] & =\mu,\forall\vec{x}\in\mathbb{R^{\textrm{k}}}\label{eq:OrtsAbhKovStationärE}
\end{align}

\end_inset

Weiterhin gilt dann, dass die Kovarianz nur noch abhängig von dem Verschiebevekt
or 
\begin_inset Formula $\vec{h}\in\mathbb{R^{\textrm{k}}};\vec{h}=\vec{x}_{1}-\vec{x}_{2}$
\end_inset

 ist:
\begin_inset Formula 
\begin{align}
cov(\vec{h}) & \coloneqq cov(\vec{x},\vec{x}+\vec{h})\label{eq:OrtsAbhKovStationärcov}
\end{align}

\end_inset

Unter Berücksichtigung von Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:OrtsAbhKovStationärE"

\end_inset

 und Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:OrtsAbhKovStationärcov"

\end_inset

 folgt dann für die gesuchte Kovarianzfunktion: 
\begin_inset Formula 
\begin{equation}
cov(\vec{h})=cov(\vec{0})-2\gamma(\vec{h})=\sigma^{2}-2\gamma(\vec{h})\label{eq:KovariogrammGrundformel}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Wobei 
\begin_inset Formula $cov(\vec{0})=\sigma^{2}$
\end_inset

 der stationären Varianz des Prozesses (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:MinimierungsverfahrenTraining"

\end_inset

) entspricht.
 Die Modellierung von 
\begin_inset Formula $\gamma(\vec{h})$
\end_inset

 wird in Abschnitt 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Kovarianz-parametrisiertes-Model"

\end_inset

 behandelt.
 
\end_layout

\begin_layout Subsection
Kovarianz parametrisiertes Modell
\begin_inset CommandInset label
LatexCommand label
name "subsec:Kovarianz-parametrisiertes-Model"

\end_inset


\end_layout

\begin_layout Standard
Die hier beschriebenen parametrisierten Kovarianzmodelle sind alle im Rahmen
 dieser Arbeit in die Software implementiert worden.
 Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:KovariogrammGrundformel"

\end_inset

 stellt die Basis für ein solches Modell dar.
 Um diese Gleichung in einem realen Modell anwenden zu können, sollte man
 sich vorerst ein typisches Kovariogramm anschauen.
 In Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Beispielhaftes-VarioKovariogramm"

\end_inset

 wird ein solches Kovariogramm gezeigt.
 Der Einfachheit halber beschränkt sich das gezeigte Kovariogramm auf eine
 räumliche Dimension 
\begin_inset Formula $\vec{x},\vec{h}\in\mathbb{R^{\textrm{k}}};k=1$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Wrap figure
lines 16
placement o
overhang 0in
width "50col%"
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../images/KrigingKapitel/KoVariogramm.eps
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Beispielhaftes Kovariogramm
\begin_inset CommandInset label
LatexCommand label
name "fig:Beispielhaftes-VarioKovariogramm"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset

Auf der X-Achse ist die räumliche Distanz und auf der Y-Achse die Kovarianz
 
\begin_inset Formula $cov(\vec{h})$
\end_inset

 aufgetragen, diese nimmt mit steigender Distanz ab.
 
\end_layout

\begin_layout Standard
Empirisch ist oftmals zu beobachten, dass das Kovariogramm bei 
\begin_inset Formula $\vec{h}=0$
\end_inset

 springt.
 Dieser Wert 
\begin_inset Formula $\lambda\in\mathbb{R}$
\end_inset

 wird als 
\begin_inset Quotes gld
\end_inset

Nugget
\begin_inset Quotes grd
\end_inset

 bezeichnet und entspricht einem ortsunabhängigen Rauschen.
 Um dies zu modellieren, wird eine eine Sprungfunktion 
\begin_inset Formula $\delta$
\end_inset

 definiert:
\begin_inset Formula 
\[
\delta(\vec{h})=\begin{cases}
1 & falls\,\vec{h}=\vec{0}\\
0 & sonst
\end{cases}
\]

\end_inset


\end_layout

\begin_layout Standard
Die Summe 
\begin_inset Formula $\sigma^{2}+\lambda$
\end_inset

 (auch 
\begin_inset Quotes gld
\end_inset

Sill
\begin_inset Quotes grd
\end_inset

 genannt) ist gleichzusetzen mit der Gesamtvarianz des stochastischen Prozesses
 selbst und der eingezeichnete Wert 
\begin_inset Formula $\sigma^{2}$
\end_inset

 wird als 
\begin_inset Quotes gld
\end_inset

partial Sill
\begin_inset Quotes grd
\end_inset

 bezeichnet.
 Damit lässt sich Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:KovariogrammGrundformel"

\end_inset

 umformuliert zu:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
cov(\vec{h})=\sigma^{2}+\lambda\delta(\vec{h})-2\gamma(\vec{h})\label{eq:KovarianzmodellAllgemein}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Die Bestimmung der Varianz 
\begin_inset Formula $\sigma^{2}$
\end_inset

 und des Nuggets 
\begin_inset Formula $\lambda$
\end_inset

 innerhalb des Kriging Modells, werden mithilfe eines Trainingsverfahrens
 geschätzt.
 Diese werden in Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:MinimierungsverfahrenTraining"

\end_inset

 beschrieben.
\end_layout

\begin_layout Standard
Für die Variogrammfunktion 
\begin_inset Formula $\gamma\left(\vec{h}\right)$
\end_inset

 muss allerdings noch ein geeignetes Modell gefunden werden.
 Eine Möglichkeit besteht in der Erzeugung eines empirischen Variogramms
 (siehe 
\begin_inset CommandInset citation
LatexCommand cite
key "Cressie1993"

\end_inset

).
 Dieses Verfahren liefert für die Abstände bekannter Stützstellen den entspreche
nden räumlichen Zusammenhang und ist als nicht parametrisches Verfahren
 einzuordnen.
 Diese Art von Verfahren benötigen aber eine sehr große Anzahl an Stützstellen,
 um plausible Variogramme zu liefern.
 Dafür benötigen diese keinerlei Annahmen über den Verlauf des Variogramms
 über der Distanz.
 
\end_layout

\begin_layout Standard
Typischerweise wird auf parametrisierte Modellfunktionen zurückgegriffen,
 welche an die vorhandenen Stützstellen bestmöglich angepasst werden.
 Dadurch kommt diese Art des Verfahrens mit weniger Stützstellen aus als
 eine empirische Schätzung, ist dafür allerdings eingeschränkter was die
 Form der Funktion angeht.
 Diese Funktionen müssen allerdings positiv semidefinit sein (vgl.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Cressie1993,Krueger2013,Schmid2012"

\end_inset

).
 Hier ist insbesondere ein Modell zu erwähnen 
\begin_inset CommandInset citation
LatexCommand cite
key "lophaven2002aspects,Sacks2007"

\end_inset

:
\begin_inset Formula 
\begin{align}
2\gamma(\vec{h})= & \sigma^{2}\left(1-e^{-\frac{1}{2}\underset{l=1}{\overset{l<=k}{\sum}}\left(\theta_{l}\left|h_{l}\right|^{p}\right)}\right)\label{eq:ExpoKorrelationsfunktion}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Wobei 
\begin_inset Formula $\vec{\theta}\in\mathbb{R^{\textrm{k}}}$
\end_inset

 als Hyperparametervektor bezeichnet wird und jeder Eintrag 
\begin_inset Formula $\theta_{l}$
\end_inset

 eine Skalierung für den entsprechenden Parameter 
\begin_inset Formula $l$
\end_inset

 darstellt.
 Die Wahl eines sinnvollen Hyperparametervektors ist Aufgabe des Trainingsverfah
rens (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:MinimierungsverfahrenTraining"

\end_inset

).
 In dem hier implementierten Kriging-Verfahren wird eine abgeänderte Modellfunkt
ion verwendet: 
\begin_inset Formula 
\begin{align}
2\gamma(\vec{h})= & \sigma^{2}\left(1-e^{-\frac{1}{2}\underset{l=1}{\overset{l<=k}{\sum}}\left(e^{\theta_{l}}\left|h_{l}\right|^{p}\right)}\right)\label{eq:ExpoKorrelationsfunktion-1}
\end{align}

\end_inset

Die Benutzung der Exponentialfunktion 
\begin_inset Formula $e^{\theta_{l}}$
\end_inset

 anstelle von 
\begin_inset Formula $\theta_{l}$
\end_inset

 dient der numerischen Stabilität des Trainingsverfahrens.
 Da die Hyperparameter nicht negativ werden dürfen und somit für Formulierung
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:ExpoKorrelationsfunktion"

\end_inset

 eine Nebenbedingung in der Form 
\begin_inset Formula $\theta_{l}>0\forall l$
\end_inset


\begin_inset Formula $\in\left\{ 1,...,k\right\} $
\end_inset

 notwendig wäre.
 Durch Verwendung der Exponentialfunktion ist dies nicht notwendig.
\end_layout

\begin_layout Standard
Für den Fall 
\begin_inset Formula $p=2$
\end_inset

 spricht man auch von einer Gauss'schen Kovarianzfunktion, welche in der
 hier beschriebenen Software auch als Standard gewählt wird.
 Der Vorteil dieser Korrelationsfunktion liegt in der schnellen Berechnung
 und damit in der schnellen Erzeugung der benötigten Kovarianzmatrix.
 
\end_layout

\begin_layout Standard
Neben diesen Korrelationsfunktionen wird häufig ein parametrisierter kubischer
 Spline verwendet, der interessierte Leser sei hierfür auf 
\begin_inset CommandInset citation
LatexCommand cite
key "lophaven2002aspects"

\end_inset

 verwiesen.
 Im Rahmen dieser Arbeit sind diese drei Korrelationsfunktionen implementiert
 und frei wählbar, wobei ein besonderes Augenmerk auf Effizienz gelegt wurden.
 Die genaue softwaretechnische Umsetzung wird in Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:SoftwaretechnKorrelationsfunktionen"

\end_inset

 beschrieben.
\end_layout

\begin_layout Standard
Setzt man die Kovarianzfunktion aus Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:ExpoKorrelationsfunktion"

\end_inset

 in Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:KovarianzmodellAllgemein"

\end_inset

 ein, dann folgt daraus die resultierende Kovarianzfunktion:
\begin_inset Formula 
\begin{align}
cov(\vec{h}) & =\sigma^{2}+\lambda\delta(\vec{h})-\sigma^{2}\left(1-e^{-\frac{1}{2}\underset{l=1}{\overset{l<=k}{\sum}}\left(e^{\theta_{l}}\left|h_{l}\right|^{2}\right)}\right)\label{eq:ExpoKovarianzfunktion}\\
 & =\lambda\delta(\vec{h})+\sigma^{2}e^{-\frac{1}{2}\underset{l=1}{\overset{l<=k}{\sum}}\left(e^{\theta_{l}}\left|h_{l}\right|^{2}\right)}\label{eq:asdasd}
\end{align}

\end_inset

Die für das Trainingsverfahren notwendigen Ableitungen sehen für die gauss'sche
 Kovarianzfunktion (
\begin_inset Formula $p=2$
\end_inset

) wie folgt aus:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
\frac{\partial cov(\vec{h})}{\partial\theta_{a}} & =-\frac{1}{2}\sigma^{2}e^{\theta_{a}}\left|h_{a}\right|^{2}\left(e^{-\frac{1}{2}\underset{l=1}{\overset{l<=k}{\sum}}\left(e^{\theta_{l}}\left|h_{l}\right|^{2}\right)}\right)\label{eq:AbleitungKorrGauss}\\
\frac{\partial cov(\vec{h})}{\partial\sigma^{2}} & =e^{-\frac{1}{2}\underset{l=1}{\overset{l<=k}{\sum}}\left(e^{\theta_{l}}\left|h_{l}\right|^{2}\right)}\label{eq:AbleitungsKorrGauss2}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Die restlichen Gleichungen aller umgesetzten Modellfunktionen und auch deren
 Ableitungen nach Hyperparametern und Ort sind in Anhang 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Kubische-Spline-Korrelationsfunk"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Exponential-Korrelationsfunktion"

\end_inset

 und Anhang 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Gauss-Korrelationsfunktion-mit"

\end_inset

 zu finden.
\end_layout

\begin_layout Subsubsection*
Kovarianzfunktion CO-Kriging
\begin_inset CommandInset label
LatexCommand label
name "subsec:Kovarianzfunktion-CO-Kriging"

\end_inset


\end_layout

\begin_layout Standard
Die Kovarianzfunktion für das CO-Kriging wird aus mehreren Kovarianzfunktionen
 zusammengesetzt, daher werden keine neuen Modelle benötigt.
 Es werden allerdings für jede Gütestufe ein zusätzlicher Hyperparametervektor
 
\begin_inset Formula $\vec{\theta}_{2},\vec{\theta}_{diff}$
\end_inset

 verwendet.
 Geht man von den Gleichungen 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:KovarianzFunktionenalleDrei"

\end_inset

 aus und setzt das entsprechende Kovarianzmodell aus Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:ExpoKovarianzfunktion"

\end_inset

 ein, wobei 
\begin_inset Formula $c_{2}(\vec{h})=e^{-\frac{1}{2}\underset{l=1}{\overset{l<=k}{\sum}}\left(e^{\theta_{l,2}}\left|h_{l}\right|^{2}\right)}$
\end_inset

 und 
\begin_inset Formula $c_{diff}(\vec{h})=e^{-\frac{1}{2}\underset{l=1}{\overset{l<=k}{\sum}}\left(e^{\theta_{l,diff}}\left|h_{l}\right|^{2}\right)}$
\end_inset

, so erhält man:
\begin_inset Formula 
\begin{align}
cov_{1,1}(\vec{x}_{1},\vec{x}_{2})= & a^{2}\sigma_{2}^{2}c_{2}(\vec{h})\\
 & +\lambda_{diff}\delta(\vec{h})+\sigma_{diff}^{2}c_{diff}(\vec{h})\nonumber \\
cov_{1,2}(\vec{x}_{1},\vec{x}_{2})= & a\sigma_{2}^{2}c_{2}(\vec{h})\label{eq:KovarianzfunktionenCoKrigingGauss}\\
cov_{2,2}(\vec{x}_{1},\vec{x}_{2})= & \lambda_{2}\delta(\vec{h})+\sigma_{2}^{2}c_{2}(\vec{h})
\end{align}

\end_inset


\end_layout

\begin_layout Subsection
Numerischen Grenzen für die Hyperparameter
\end_layout

\begin_layout Standard
Betrachtet man sich die Gleichung für die Korrelationen 
\begin_inset Formula $c(\vec{h})=e^{-\frac{1}{2}\underset{l=1}{\overset{l<=k}{\sum}}\left(e^{\theta_{l}}\left|h_{l}\right|^{2}\right)}$
\end_inset

, so können die 
\begin_inset Formula $\theta_{l}$
\end_inset

 Werte sehr große oder kleine Werte annehmen.
 Diese Werte gehen dann in eine verkettete Exponentialfunktion ein.
 Der innere Teil der Exponentialfunktion 
\begin_inset Formula $e^{\theta_{l}}$
\end_inset

 kann sehr große oder sehr kleine Werte annehmen.
 Damit diese Werte noch durch die gewählte Fließkommagenauigkeit dargestellt
 werden können, sollten daher numerische Grenzen für 
\begin_inset Formula $\theta_{l}$
\end_inset

 gelten.
\end_layout

\begin_layout Standard
Um diese Werte zu bestimmen bietet sich ein einfacher numerischer Testfall
 an.
 Hierfür wurde ein kleines Testprogramm geschrieben, welches die Grenzwerte
 für 
\begin_inset Formula $c(\vec{h})=e^{-\frac{1}{2}e^{\theta}}$
\end_inset

 bestimmt.
 Die gefundenen Grenzen für eine 64Bit Fließkommzahl liegen bei 
\begin_inset Formula $\theta\in\mathbb{R}|5<\theta_{l}<-34$
\end_inset

.
 
\end_layout

\begin_layout Section
Regularisierung und Behandlung verrauschter Funktionen
\begin_inset CommandInset label
LatexCommand label
name "sec:RegularisierungUndRauschen"

\end_inset


\end_layout

\begin_layout Standard
Zwei weitere wichtige Punkte der verschiedenen Kriging-Verfahren, sind die
 Berücksichtigungen von schlecht konditionierten Kovarianzmatrizen und der
 Umgang mit verrauschten Funktionen.
 Da die praktische Behandlung beider Problematiken sehr ähnlich ist, werden
 sie innerhalb dieses Kapitels gemeinsam beschrieben.
\end_layout

\begin_layout Subsection
Regularisierung
\begin_inset CommandInset label
LatexCommand label
name "subsec:Regularisierung"

\end_inset


\end_layout

\begin_layout Standard
Während des Trainings wird ein Satz Hyperparameter gesucht, welcher den
 Likelihood Wert (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:COKrigingTraining"

\end_inset

) maximiert.
 Dabei muss für jeden Satz an Hyperparametern die zugehörige Kovarianzmatrix
 aufgestellt werden.
 Bei diesem Prozess kann es passieren, dass die resultierende Matrix schlecht
 konditioniert ist und damit die verwendeten numerischen Verfahren instabil
 werden.
 Die Ursache einer schlecht konditionierten Matrix können sehr vielfältig
 sein und werden in 
\begin_inset CommandInset citation
LatexCommand cite
key "Davis1997"

\end_inset

 genauer beschrieben.
 In der Regel liegt es an schlecht verteilten Stützstellen oder an einer
 ungünstigen Initialisierung der Hyperparameter.
 Auch die Wahl der Kovarianzfunktion kann enormen Einfluss auf die numerische
 Stabilität haben.
 
\end_layout

\begin_layout Standard
Eine gebräuchliche Methode um die Konditionszahl zu verbessern, ist es die
 Hauptdiagonale der Kovarianzmatrix um einen Wert 
\begin_inset Formula $\lambda\in\mathbb{R}$
\end_inset

 (folgend Diagonalaufschlag) zu erhöhen.
 Dieses Vorgehen entspricht einer Tikhonov Regularisierung, wie sie häufig
 für Least Squares Verfahren eingesetzt wird (siehe 
\begin_inset CommandInset citation
LatexCommand cite
key "Sacks2007a,tikhonov2013numerical,hoerl2000"

\end_inset

).
 
\end_layout

\begin_layout Standard
Der Diagonalaufschlag 
\begin_inset Formula $\lambda$
\end_inset

 wurde bei Herleitung von Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:ExpoKovarianzfunktion"

\end_inset

 bereits berücksichtigt.
 Bezüglich der Regularisierung der Matrix sollte er jedoch so klein wie
 möglich gehalten werden, da dessen Größe einen starken Einfluss auf die
 Vorhersagen hat.
 
\end_layout

\begin_layout Paragraph*
Ordinary Kriging
\begin_inset CommandInset label
LatexCommand label
name "par:Ordinary-Kriging"

\end_inset


\end_layout

\begin_layout Standard
Zur Bestimmung eines geeigneten Wertes, ist es sinnvoll die Konditionszahl
 
\begin_inset Formula $\kappa$
\end_inset

 der Kovarianzmatrix zu betrachten.
 Diese ist definiert als Quotient aus maximalem 
\begin_inset Formula $\Xi_{max}$
\end_inset

 und minimalem Eigenwert 
\begin_inset Formula $\Xi_{min}$
\end_inset

:
\begin_inset Formula 
\begin{align*}
\kappa & =\left|\frac{\Xi_{max}\left(\mathbf{Cov}\right)}{\Xi_{min}\left(\mathbf{Cov}\right)}\right|
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Geht man weiterhin von einer Ordinary-Kriging Kovarianzmatrix aus, so kann
 (im Falle 
\begin_inset Formula $\lambda=0)$
\end_inset

 die Varianz 
\begin_inset Formula $\sigma^{2}$
\end_inset

 aus der Matrix ausgeklammert werden und die Korrelationsmatrix 
\begin_inset Formula $\mathbf{R}\in\mathbb{R}^{n\times n}$
\end_inset

 bleibt:
\begin_inset Formula 
\[
\mathbf{Cov}=\sigma^{2}\mathbf{R}
\]

\end_inset


\end_layout

\begin_layout Standard
Die Werte innerhalb der Korrelationsmatrix 
\begin_inset Formula $\mathbf{R\in\mathbb{R}^{n\times n}}$
\end_inset

 können (im Falle 
\begin_inset Formula $\lambda=0)$
\end_inset

 einen maximalen Wert von 1 annehmen (siehe Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:asdasd"

\end_inset

).
 Daraus lässt sich der ungünstigste Fall 
\begin_inset Formula $\mathbf{\widetilde{R}}\in\mathbb{R}^{n\times n}$
\end_inset

 für die Konditionierung der Matrix ableiten, welcher einer reinen Einsmatrix
 entspricht.
\begin_inset Formula 
\begin{align}
\mathbf{Cov} & =\sigma^{2}\left[\begin{array}{ccc}
1 & ... & 1\\
... & ... & ...\\
1 & ... & 1
\end{array}\right]=\mathbf{\sigma^{2}\widetilde{R}}
\end{align}

\end_inset

Die minimalen und maximalen Eigenwerte der Einsmatrix sind für diesen Fall
 bekannt:
\begin_inset Formula 
\begin{align}
\Xi_{min}\left(\mathbf{Cov}\right) & =0\\
\Xi_{max}\left(\mathbf{Cov}\right) & =\sigma^{2}n
\end{align}

\end_inset

Dies würde einer unendlichen Konditionszahl entsprechen 
\begin_inset Formula $\kappa=\infty$
\end_inset

.
 Addiert man nun den Diagonalaufschlag, bekommt man folgende Kovarianzmatrix:
 
\begin_inset Formula 
\begin{align}
\mathbf{\mathbf{Cov}} & =\left[\begin{array}{ccc}
\sigma^{2}+\lambda & ... & \sigma^{2}\\
... & ... & ...\\
\sigma^{2} & ... & \sigma^{2}+\lambda
\end{array}\right]
\end{align}

\end_inset

Daraus ergeben sich die folgenden maximalen und minimalen Eigenwerte:
\begin_inset Formula 
\begin{align}
\Xi_{min}\left(\mathbf{\mathbf{Cov}}\right) & =\lambda\\
\Xi_{max}\left(\mathbf{Cov}\right) & =\lambda+\sigma^{2}n
\end{align}

\end_inset

Und die entsprechende Konditionszahl verbessert sich zu:
\begin_inset Formula 
\begin{align}
\kappa & =\left|\frac{\lambda+\sigma^{2}n}{\lambda}\right|
\end{align}

\end_inset

Da die Matrix positiv definit sein muss und damit nur positive Eigenwerte
 hat, kann der Betrag vernachlässigt werden.
 Wählt man nun für die Konditionszahl eine obere Grenze, erhält man eine
 Untergrenze für den Diagonalaufschlag:
\begin_inset Formula 
\begin{align}
\kappa_{max} & >\frac{\lambda+\sigma^{2}n}{\lambda}\\
\lambda & >\frac{\sigma^{2}n}{\left(\kappa_{max}-1\right)}
\end{align}

\end_inset


\end_layout

\begin_layout Paragraph*
CO-Kriging
\end_layout

\begin_layout Standard
Im Falle des CO-Krigings ist die Kovarianzmatrix partitioniert, bedingt
 durch die unterschiedlichen Gütestufen.
 Der Ansatz aus dem Ordinary-Kriging ist mit dieser partitionierten Matrix
 nicht mehr möglich, dennoch ist es möglich den maximalen Eigenwert 
\begin_inset Formula $\Xi_{max}\left(\mathbf{Cov}\right)$
\end_inset

 der Matrix zu schätzen.
 Für eine diagonalisierbare Matrix gilt allgemein, dass die Summe der Eigenwerte
 
\begin_inset Formula $\Xi_{i},i\in\left\{ 1,...,n_{all}\right\} $
\end_inset

 der Spur der Matrix entspricht:
\begin_inset Formula 
\begin{align}
\sum_{i=1}^{n_{all}}\Xi_{i} & =spur\left(\mathbf{Cov}\right)\label{eq:SpurEqSummeEigenwerte}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Geht man von den Gleichungen 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:KovarianzfunktionenCoKrigingGauss"

\end_inset

 aus, so ergibt sich die Spur als Summe der Diagonaleinträge wie folgt:
\begin_inset Formula 
\begin{align}
spur\left(\mathbf{Cov}\right) & =\sum_{i=1}^{n_{1}}\left(a^{2}\sigma_{2}^{2}c_{2}(\vec{0})+\sigma_{diff}^{2}c_{diff}(\vec{0})+\lambda_{diff}\right)+\sum_{i=1}^{n_{2}}\left(\sigma_{2}^{2}c_{2}(\vec{0})+\lambda_{2}\right)
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Da die Korrelationen der Diagonalen den Wert Eins besitzen,
\begin_inset Formula $c_{2}(\vec{0})=1$
\end_inset

 und 
\begin_inset Formula $c_{diff}(\vec{0})=1$
\end_inset

, gilt für die Spur der Matrix:
\begin_inset Formula 
\begin{align}
\sum_{i=1}^{n_{all}}\Xi_{i}=spur\left(\mathbf{Cov}\right) & =\sum_{i=1}^{n_{1}}\left(a^{2}\sigma_{2}^{2}+\sigma_{diff}^{2}+\lambda_{diff}\right)+\sum_{i=1}^{n_{2}}\left(\sigma_{2}^{2}+\lambda_{2}\right)\\
 & =n_{1}\left(a^{2}\sigma_{2}^{2}+\sigma_{diff}^{2}+\lambda_{diff}\right)+n_{2}\left(\sigma_{2}^{2}+\lambda_{2}\right)
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Übertragen auf Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:SpurEqSummeEigenwerte"

\end_inset

 folgt:
\begin_inset Formula 
\begin{align}
\sum_{i=1}^{n_{all}}\Xi_{i} & =n_{1}\left(a^{2}\sigma_{2}^{2}+\sigma_{diff}^{2}+\lambda_{diff}\right)+n_{2}\left(\sigma_{2}^{2}+\lambda_{2}\right)\geq n_{1}\lambda_{diff}+n_{2}\lambda_{2}\label{eq:EigenwertBedSpur}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Geht man weiterhin von nur einem Regularisierungsterm 
\begin_inset Formula $\lambda_{diff}=\lambda_{2}=\lambda$
\end_inset

 für alle Gütestufen aus, gilt für den maximalen und minimalen Eigenwert
 
\begin_inset Formula $\Xi_{max},\Xi_{min}$
\end_inset

: 
\begin_inset Formula 
\begin{align}
\Xi_{max} & \leq n_{1}\left(a^{2}\sigma_{2}^{2}+\sigma_{diff}^{2}+\lambda\right)+n_{2}\left(\sigma_{2}^{2}+\lambda\right)\\
\Xi_{min} & \geq\lambda;falls\,\Xi_{i}=\Xi_{min}\forall i\label{eq:EigenwertMinGrLambda}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Für die Konditionszahl 
\begin_inset Formula $\kappa$
\end_inset

 lässt sich so eine obere Grenze bestimmen:
\begin_inset Formula 
\begin{align}
\kappa & \leq\frac{n_{1}\left(a^{2}\sigma_{2}^{2}+\sigma_{diff}^{2}+\lambda\right)+n_{2}\left(\sigma_{2}^{2}+\lambda\right)}{\lambda}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Legt man nun für die Konditionszahl einen maximalen Wert 
\begin_inset Formula $\kappa_{max}$
\end_inset

 fest, ergibt sich als Schätzung für den Diagonalaufschlag:
\begin_inset Formula 
\begin{align}
\lambda_{min} & \geq\frac{n_{1}a^{2}\sigma_{2}^{2}+n_{1}\sigma_{diff}^{2}+n_{2}\sigma_{2}^{2}}{\left(\kappa_{max}-\left(n_{2}+n_{1}\right)\right)}\label{eq:DiagonalSchätzungCoKriging}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Die Werte 
\begin_inset Formula $\sigma_{2}^{2},\sigma_{diff}^{2},a$
\end_inset

 werden während des Trainings oftmals verändert, dadurch ändert sich auch
 die untere Grenze des Diagonalaufschlags 
\begin_inset Formula $\lambda_{min}$
\end_inset

 (siehe Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:DiagonalSchätzungCoKriging"

\end_inset

) permanent.
 Für dieses Problem sind zwei Lösungen möglich:
\end_layout

\begin_layout Enumerate
Die untere Grenze für 
\begin_inset Formula $\lambda_{min}$
\end_inset

 in jedem Trainingsschritt neu bestimmen und bei Unterschreitung auf den
 Grenzwert setzen.
\end_layout

\begin_layout Enumerate
Die untere Grenze für 
\begin_inset Formula $\lambda_{min}$
\end_inset

 nur beim Start des Trainings bestimmen.
 
\end_layout

\begin_layout Standard
Die erste Lösung kann dazu führen, dass sich der Grenzwert 
\begin_inset Formula $\lambda_{min}$
\end_inset

 während des Training ändert und der aktuelle Wert 
\begin_inset Formula $\lambda<\lambda_{min}$
\end_inset

 die Grenze unterschreitet.
 Da der Diagonalaufschlag dann bei Unterschreitung der Grenze abhängig von
 den Variablen 
\begin_inset Formula $\sigma_{2}^{2},\sigma_{diff}^{2},a$
\end_inset

 wird, muss dies bei der Ableitung des Likelihoods (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:COKrigingTraining"

\end_inset

) Berücksichtigung finden, was einen hohen Aufwand bedeutet.
\end_layout

\begin_layout Standard
Aus diesem Grund wird die zweite Variante gewählt, also die untere Grenze
 nur initial eingestellt und dann nicht mehr verändert.
 Es sei denn, es treten numerische Probleme während des Trainings auf, dann
 wird in der Software eine entsprechende Exception geworfen.
 Diese wird abgefangen und der letzte Iterationsschritt mit einem höheren
 Diagonalaufschlag wiederholt.
 Dies wird so lange wiederholt bis die numerischen Probleme verschwinden
 oder eine Obergrenze an Wiederholungen erreicht ist.
 Ist diese Obergrenze erreicht, wird ein Fehler ausgegeben und das Training
 abgebrochen.
 
\end_layout

\begin_layout Standard
Ein geeigneter Wert für die obere Grenze der Konditionszahl liegt erfahrungsgemä
ß bei 
\begin_inset Formula $\sim10^{9}$
\end_inset

, dieser Wert kann im Einzelfall natürlich angepasst werden.
 
\end_layout

\begin_layout Subsection
Behandlung verrauschter Funktionen
\begin_inset CommandInset label
LatexCommand label
name "subsec:Approximation"

\end_inset


\end_layout

\begin_layout Standard
Bei Vernachlässigung des Diagonalaufschlags 
\begin_inset Formula $\lambda$
\end_inset

 ist das beschriebene Kriging-Verfahren rein interpolierend.
 In einigen Fällen ist allerdings ein approximierendes Verhalten gewünscht.
 Ein solches Verhalten entspricht dem in Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Variogramm"

\end_inset

 beschriebenen 
\begin_inset Quotes gld
\end_inset

Nugget-Effekt
\begin_inset Quotes grd
\end_inset

.
 Die praktische Umsetzung innerhalb des Kriging Verfahrens ist letztlich
 dieselbe wie bei dem in Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Regularisierung"

\end_inset

 beschriebenen Regularisierungsterm.
 Der hauptsächliche Unterschied besteht in der Größenordnung des Diagonalaufschl
ags 
\begin_inset Formula $\lambda$
\end_inset

 und in dessen Bedeutung.
 Da es sich bei dem Diagonalaufschlag in diesem Fall um eine Varianz handelt
 die einem zufälligen Rauschen entspricht (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Kovarianz-parametrisiertes-Model"

\end_inset

).
 Deswegen ist der Diagonalaufschlag für diesen Fall als Hyperparameter zu
 behandeln und muss daher mit trainiert werden.
 Die Umsetzung soll folgend gezeigt werden.
 
\end_layout

\begin_layout Standard
Die Bildung der Kovarianzfunktion ist in Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Kovarianzfunktion-CO-Kriging"

\end_inset

 beschrieben.
 Um den Rauschterm innerhalb eines gradientenbasierten Trainingsverfahrens
 (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:MinimierungsverfahrenTraining"

\end_inset

) zu verwenden, müssen noch die Ableitungen der Kovarianzfunktionen nach
 den Rauschtermen gebildet werden.
 Diese sind in Anhang 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Ableitungen-des-Kovarianzmodells"

\end_inset

 zu finden.
 Mit diesen Ableitungen ist das Maximum Likelihood Verfahren (siehe Kapitel
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:COKrigingTraining"

\end_inset

 und Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:MinimierungsverfahrenTraining"

\end_inset

) direkt anwendbar.
 
\end_layout

\begin_layout Paragraph*
Rauschterm Beispiel
\end_layout

\begin_layout Standard
In Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Kriging_RauschFunktion"

\end_inset

 wird ein einfaches Beispiel gezeigt, es soll die Wirkung von unterschiedlichen
 Rauschtermen auf die Vorhersage beispielhaft erläutert werden.
 Es handelt sich um eine konstante Null-Funktion mit einem normalverteilten
 Rauschen, welche den Erwartungswert Null und die Standardabweichung Eins
 besitzt: 
\begin_inset Formula $f\left(x\right)=\mathcal{N}\left(0,1\right)$
\end_inset

.
 Jeder eingezeichnete Punkt entspricht einer Stützstelle, wobei jede Stützstelle
 an einem anderen Ort ist.
 Mit Hilfe dieser Stützstellen wird ein Ordinary-Kriging trainiert und dann
 für den entsprechenden Wertebereich Vorhersagen getroffen.
 
\begin_inset Wrap figure
lines 17
placement o
overhang 0in
width "50col%"
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../images/KrigingKapitel/KonstantenRauschFunktion.eps
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Kriging_RauschFunktion"

\end_inset

Konstante Funktion mit normalverteiltem Rauschen
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset

 Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:RauschenBeispiel"

\end_inset

 zeigt zwei mögliche Vorhersagen, beide werden durch den Likelihood Term
 gleichermaßen gut bewertet.
\end_layout

\begin_layout Standard
Die schwarze Linie entspricht dem vorhergesagten Erwartungswert und die
 Fehlerbalken der vorhergesagten Standardabweichung.
 Auf dem linken Bild zeigt das trainierte Kriging eine approximierendes
 Verhalten und auf dem rechten Bild ein interpolierendes Verhalten.
 Auf dem rechten Bild wird jeder der Stützstellen exakt wiedergegeben und
 die vorhersagte Standardabweichung ist an diesen Stellen Null.
 Der Diagonalaufschlag ist bei dieser Lösung ebenfalls Null.
\end_layout

\begin_layout Standard
Auf dem linken Bild hat der Diagonalaufschlag den Wert Eins, was genau der
 Varianz des Rauschterms entspricht.
 Im Extrapolationsbereich zeigen die verschiedenen Vorhersagen exakt dieselben
 Ergebnisse.
 Diese Doppeldeutigkeit kann auf die Einstellungen der Hyperparameter zurückgefü
hrt werden, die wesentlichen Hyperparameter sind die Prozessvarianz 
\begin_inset Formula $\sigma^{2}$
\end_inset

, der Diagonalaufschlag 
\begin_inset Formula $\lambda$
\end_inset

 und die Korrelationslänge 
\begin_inset Formula $\theta$
\end_inset

.
 Tabelle 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:KrigingRauschBspEinstellungn"

\end_inset

 zeigt die Einstellungen der beiden Lösungen.
 Für das Training der beiden Kriging-Modelle wurde der Diagonalaufschlag
 
\begin_inset Formula $\lambda$
\end_inset

 vorher festgelegt und die anderen Größen durch das Training automatisch
 bestimmt.
 
\end_layout

\begin_layout Standard
\begin_inset Wrap table
lines 9
placement o
overhang 0in
width "50col%"
status open

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Interpolierend
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Approximierend
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\sigma^{2}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\lambda$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\theta$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $e^{15}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $e^{-50}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:KrigingRauschBspEinstellungn"

\end_inset

Einstellungen der verschiedenen Kriging-Lösungen
\end_layout

\end_inset


\end_layout

\end_inset

Die interpolierenden Variante besitzt eine Varianz von 
\begin_inset Formula $\sigma^{2}=1$
\end_inset

.
 Diese Varianz entspricht dann dem 
\begin_inset Quotes gld
\end_inset

Sill
\begin_inset Quotes grd
\end_inset

 aus Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Variogramm"

\end_inset

, also der Varianz bei großem Abstand zu einem bekannten Punkt.
 Der Abstand wird durch die Korrelationslänge 
\begin_inset Formula $\theta$
\end_inset

 beeinflusst.
 Wobei ein großer 
\begin_inset Formula $\theta$
\end_inset

 Wert auf einen räumlich sehr kleinen Einfluss deutet.
 Diese Lösung würde also einem sehr steilen Variogramm entsprechen, welches
 bei kleinstem Abstand sofort auf den 
\begin_inset Quotes gld
\end_inset

Sill
\begin_inset Quotes grd
\end_inset

 springt.
 Das Variogramm wird qualitativ in dem rechten Diagramm der Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:VarioApproxInter"

\end_inset

 dargestellt.
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "75col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename ../images/KrigingKapitel/semiSteep.eps
	scale 70
	clip

\end_inset


\end_layout

\end_inset


\begin_inset space \hspace*{\fill}
\end_inset


\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "24col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:VarioApproxInter"

\end_inset

Qualitatives Variogramm für das interpolierende und approximierende Kriging
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Die approximierende Variante hat einen sehr kleinen Skalierungsfaktor 
\begin_inset Formula $\theta=e^{-50}$
\end_inset

 (siehe Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:ExpoKovarianzfunktion"

\end_inset

) und eine Varianz von 
\begin_inset Formula $\sigma^{2}=0$
\end_inset

, was einer konstanten Funktion ohne Unsicherheit entspricht.
 Durch den Rauschterm 
\begin_inset Formula $\lambda=1$
\end_inset

 wird dem Modell eine grundlegende Unsicherheit aufaddiert, welche dem 
\begin_inset Quotes gld
\end_inset

Nugget
\begin_inset Quotes grd
\end_inset

 entspricht.
 Das entsprechende Variogramm wäre unabhängig von der Distanz und entspricht
 dem linken Diagramm in Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:VarioApproxInter"

\end_inset

.
 
\end_layout

\begin_layout Standard
Die beiden gezeigt Lösungen haben denselben Likelihood Wert, werden vom
 Trainingsverfahren also als gleichwertig angesehen.
 Welche Lösung letztlich vom Training gewählt wird, hängt hauptsächlich
 von der gewählten Initialisierung ab.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "75col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename ../images/KrigingKapitel/KonstantenRauschFunktionPunkte.eps
	scale 40

\end_inset


\end_layout

\end_inset


\begin_inset space \hspace*{\fill}
\end_inset


\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "24col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:RauschenBeispiel"

\end_inset

Normalverteiltes Rauschen und zwei mögliche Kriging Modelle.
 Die Fehlerbalken stellen die vorhergesagte Standardabweichung dar
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:RauschBeiespielDiagonalaufschlagVarianz"

\end_inset

 zeigt für verschiedene Diagonalaufschläge den resultierenden Likelihood-Wert,
 wobei hier ein kleiner Likelihood ein besseres Ergebnis darstellt.
 Das Ergebnis zeigt, dass der Likelihood-Wert für einem Diagonalaufschlag
 im Bereich von 
\begin_inset Formula $\lambda>0\land\lambda<1$
\end_inset

 konstant und minimal bleibt.
 Darüber wird der Likelihood-Wert dann deutlich größer.
 Um das Verhalten zu verstehen, wird in Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:RauschBeispielVarianzDiag"

\end_inset

 die eingestellte Varianz 
\begin_inset Formula $\sigma^{2}$
\end_inset

 und der Diagonalaufschlag für den Bereich des optimalen Likelihood-Wertes
 gezeigt.
 Das Ergebnis ist auch hier plausibel, denn in der Summe ergeben die beiden
 Werte immer den Wert 
\begin_inset Formula $\sigma^{2}+\lambda=1$
\end_inset

, was dann wiederum der Varianz des Erzeugungsprozesses entspricht.
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../images/KrigingKapitel/DiagonalLikelihood.eps
	scale 60

\end_inset


\begin_inset Graphics
	filename ../images/KrigingKapitel/DiagonalVarianz.eps
	scale 60

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:RauschBeiespielDiagonalaufschlagVarianz"

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "fig:RauschBeispielVarianzDiag"

\end_inset

 (a) Diagonalaufschlag und Varianz und resultierender Likelihood Wert (b)
 Bereich des optimalen Likelihood-Wertes und Entwicklung des Diagonalaufschlag
 und der Varianz
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Das hier gezeigte Verhalten entspricht also den Erwartungen.
 Allerdings kann dies bei einer geringeren Datenlage oder einer komplexeren
 Funktion dazu führen, dass der Diagonalaufschlag deutlich überschätzt wird.
 Die praktische Erfahrung zeigt auch genau ein solches Verhalten.
 Aus diesem Grund sollte das Training des Diagonalaufschlags als nur optionale
 Funktion des Trainings verfügbar sein.
 
\end_layout

\begin_layout Subsection
Softwaretechnische Umsetzung von Approximation und Regularisierung 
\end_layout

\begin_layout Standard
In den Kapiteln 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Regularisierung"

\end_inset

 und 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Approximation"

\end_inset

 wird ein Diagonalaufschlag verwendet, um eine Regularisierung der Matrix
 zu erreichen und auch um ein approximierendes Verhalten herbeizuführen.
 Praktische Unterschiede ergeben sich nur in der Größe der Werte und in
 der Bestimmung während des Trainings.
 Auf der einen Seite steht der Regularisierungsterm, welcher für die numerische
 Stabilität sorgen soll.
 Dieser soll die Vorhersage möglichst nicht beeinflussen und muss daher
 sehr klein gewählt werden.
 Zudem ist dieser nicht als Hyperparameter anzusehen und daher keine zu
 trainierende Größe.
 Auf der anderen Seite steht der Rauschterm, welcher für ein approximierende
 Verhalten sorgen soll.
 Dieser Parameter wird auch innerhalb des Trainingsverfahrens geschätzt
 und ist als Hyperparameter einzustufen.
 Um nicht für den Regularisierungsterm und den Rauschterm jeweils einen
 eigenen Wert zu verwenden, ist es möglich den Regularisierungsterm als
 minimale Grenze anzunehmen.
 Der Rauschterm kann dann wie beschrieben trainiert werden, besitzt dann
 allerdings eine untere Schranke, die sich wie in Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Regularisierung"

\end_inset

 beschrieben festlegen lässt.
 
\end_layout

\begin_layout Section
Training
\begin_inset CommandInset label
LatexCommand label
name "chap:MinimierungsverfahrenTraining"

\end_inset


\end_layout

\begin_layout Standard
In diesem Kapitel wird das Trainingsverfahren für alle Kriging-Modelle beschrieb
en.
 Dafür wird im ersten Teil das Maximum-Likelihood Verfahren vorgestellt,
 dieses liefert ein Maß für die Güte des Modells unter Berücksichtigung
 der eingestellten Hyperparameter.
 
\end_layout

\begin_layout Standard
Ziel des Trainingsverfahrens ist es, die optimalen Hyperparameter zu finden
 die diesen Term maximieren.
 Zu diesem Zweck werden diverse numerische Minimierungsverfahren und auch
 mögliche Initialisierungsverfahren vorgestellt.
 
\end_layout

\begin_layout Standard
Da einige der Minimierungsverfahren bereits vor der Entwicklung des hier
 vorgestellten Programms vorhanden waren, diese allerdings noch in der Programmi
ersprache C entwickelt wurden, musste eine flexible Software-Schnittstelle
 entwickelt werden.
 Hierfür wurde ein spezielles Klassenmodell unter Benutzung von Boost-Funktionso
bjekten entwickelt, welches am Ende des Kapitels kurz beschrieben wird.
 
\end_layout

\begin_layout Subsection
Maximum Likelihood für alle Kriging Verfahren
\begin_inset CommandInset label
LatexCommand label
name "sec:COKrigingTraining"

\end_inset


\end_layout

\begin_layout Standard
Um ein Kriging-Modell vollständig aufzustellen, müssen sinnvolle Werte für
 die benötigten Hyperparameter der Kovarianz-Modellfunktion (siehe Kapitel
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Kovarianzmatrix"

\end_inset

) gefunden werden.
 Für diesen Zweck wird sehr häufig die Maximum-Likelihood-Methode angewandt,
 welche in diesem Abschnitt erläutert wird.
 
\end_layout

\begin_layout Standard
Die Maximum-Likelihood-Methode ist ein Schätzverfahren in der Statistik,
 um (Hyper)parameter einer angenommenen Verteilungsfunktion bei gegebenen
 Realisierungen zu schätzen.
 Es werden Werte für Hyperparameter gewählt, gemäß derer die Realisierung
 der bereits bekannten Daten am plausibelsten erscheint.
 
\end_layout

\begin_layout Standard
Um diesen Ansatz bei einem Verfahren wie dem Kriging anzuwenden, werden
 die bekannten Funktionswerte als Realisierung einer multivariaten Normalverteil
ung 
\begin_inset Formula $\mathcal{N}\left(\vec{F},\mathbf{Cov}\mathrm{(\vec{h})}\right)$
\end_inset

 angenommen.
 Wobei 
\begin_inset Formula $\mathbf{Cov}\mathrm{(\vec{h})}\mathbf{\mathbb{\in R^{\mathrm{n_{all}\times n_{all}}}}}$
\end_inset

 die jeweilige Kovarianzmatrix in Abhängigkeit der Hyperparameter 
\begin_inset Formula $\vec{h}\in\mathbb{R}{}^{o}$
\end_inset

 darstellt und 
\begin_inset Formula $\vec{Z}=(\vec{Z}_{0},...,\vec{Z}_{g},...\vec{Z}_{mf})^{T}\in\mathbb{R}{}^{m_{f}}$
\end_inset

 den Vektor mit einem Zufallsprozess 
\begin_inset Formula $\vec{Z}_{g}\in\mathbb{R}{}^{n_{g}}$
\end_inset

 für jede Gütestufe 
\begin_inset Formula $g$
\end_inset

 mit jeweils 
\begin_inset Formula $n_{g}$
\end_inset

 Realisierungen.
 Analog dazu beinhaltet der Vektor 
\begin_inset Formula $\vec{F}$
\end_inset

 alle Erwartungswerte der Zufallsprozesse 
\begin_inset Formula $\vec{Z}$
\end_inset

 (siehe Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:FVektor"

\end_inset

).
 Der Vektor 
\begin_inset Formula $\vec{y}_{s}\in\mathbb{R}^{n_{all}}$
\end_inset

 beinhaltet alle bekannten Stützstellen.
 Daraus ergibt sich die folgende Dichtefunktion 
\begin_inset Formula $f_{D}$
\end_inset

 der multivariaten Normalverteilung 
\begin_inset Formula $\mathcal{N}\left(\vec{F},\mathbf{Cov}\mathrm{(\vec{h})}\right)$
\end_inset

:
\begin_inset Formula 
\begin{align}
f_{D}(\vec{Z},\vec{F}(\vec{h}),\mathbf{Cov}\mathrm{(\vec{h})})= & \frac{1}{\left(2\pi\right)^{\frac{n}{2}}\det\left(\mathbf{Cov}\mathrm{(\vec{h})}\right)^{\frac{1}{2}}}e^{-\frac{1}{2}\left(\vec{Z}-\vec{F}\right)^{T}\mathbf{\mathbf{Cov}\mathrm{(\vec{h})}{}^{\textrm{-1}}}\left(\vec{Z}-\vec{F}\right)}\label{eq:LikelihoodMultivariateNorm}
\end{align}

\end_inset


\shape italic
Es gilt: Bei Kenntnis der Realisierungen 
\begin_inset Formula $\vec{y}_{s}$
\end_inset

 sind die Hyperparameter 
\begin_inset Formula $\vec{h}$
\end_inset

 dann am plausibelsten, wenn der Dichtefunktionswert 
\begin_inset Formula $f_{D}$
\end_inset

 der Verteilung 
\begin_inset Formula $\mathcal{N}\left(\vec{F},\mathbf{Cov}(\vec{h})\right)$
\end_inset

 maximal wird.
 
\end_layout

\begin_layout Standard
Daraus ergibt sich dann die sogenannte Likelihood-Funktion 
\begin_inset Formula $L(\vec{h})$
\end_inset

, deren Maximum gesucht wird:
\begin_inset Formula 
\begin{equation}
\max_{h_{1},...,h_{o}}L(\vec{h})=\max_{h_{1},...,h_{o}}\left(\frac{1}{\left(2\pi\right)^{\frac{n}{2}}\det\left(\mathbf{Cov}\mathrm{(\vec{h})}\right)^{\frac{1}{2}}}e^{-\frac{1}{2}\left(\vec{y}_{s}-\vec{F}\right)^{T}\mathbf{\mathbf{Cov}\mathrm{(\vec{h})}{}^{\textrm{-1}}}\left(\vec{y}_{s}-\vec{F}\right)}\right)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Numerisch ist diese Formulierung ungünstig, da die Exponentialfunktion im
 Zähler sehr kleine Werte annehmen kann und die Determinante im Nenner sehr
 große.
 Eine gebräuchliche Lösung ist die Verwendung der logarithmierten Likelihood
 Funktion (vgl.
 
\begin_inset CommandInset citation
LatexCommand cite
key "viertl2013einfuhrung"

\end_inset

):
\begin_inset Formula 
\begin{align}
\log(L(\vec{h}))= & \log(1)-\frac{n}{2}\log(2\pi)-\frac{1}{2}\log\left(\det(\mathbf{\mathbf{Cov}})\right)-\frac{1}{2}\left(\vec{y}_{s}-\overrightarrow{F}\right)^{T}\mathbf{\mathbf{Cov}}^{-1}\left(\vec{y}_{s}-\overrightarrow{F}\right)\label{eq:LogLikelihoodZwischen}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Da der Logarithmus eine streng monoton wachsende Funktion ist, ist jedes
 Minimum der logarithmierten Likelihood-Funktion (Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:LikelihoodMultivariateNorm"

\end_inset

) auch ein Minimum der Likelihood-Funktion (Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:LikelihoodMultivariateNorm"

\end_inset

) selbst.
 Ebenso ist jedes Maximum der logarithmierten Likelihood-Funktion auch ein
 Maximum der Likelihood-Funktion.
 
\end_layout

\begin_layout Standard
Die Konstanten können ignoriert werden, da diese für das Maximum keine Rolle
 spielen, daraus folgt: 
\begin_inset Formula 
\begin{align}
\max_{h_{1},...,h_{o}}L(\vec{h})=\max_{h_{1},...,h_{o}}\log(L(\vec{h}))= & \max_{h_{1},...,h_{o}}\left(-\log\left(\det(\mathbf{\mathbf{Cov}})\right)-\left(\vec{y}_{s}-\overrightarrow{F}\right)^{T}\mathbf{\mathbf{Cov}}^{-1}\left(\vec{y}_{s}-\overrightarrow{F}\right)\right)\label{eq:LogLikelihood}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Im weiteren Verlauf wird der Term kurz mit 
\begin_inset Formula $\log(L)$
\end_inset

 bezeichnet.
 Die Ableitung nach einem beliebigen Hyperparameter 
\begin_inset Formula $h_{l}$
\end_inset

 sieht dann wie folgt aus, die vollständige Herleitung ist in Anhang 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Differentiation-der-Likelihood-Funktion"

\end_inset

 zu finden:
\begin_inset Formula 
\begin{align}
\frac{\partial L\left(\vec{h}\right)}{\partial h_{l}}= & -\textrm{Spur}\left(\mathbf{\mathbf{Cov}}^{-1}\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}\right)+\left(\left(\vec{y}_{s}-\overrightarrow{F}\right)^{T}\mathbf{\mathbf{\mathbf{Cov}}}^{-1}\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}\mathbf{\mathbf{Cov}}^{-1}\left(\vec{y}_{s}-\overrightarrow{F}\right)\right)\label{eq:AbleitungLogLikelihood}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
\noindent
Damit ist es nun möglich die unbekannten Hyperparameter mit einem geeigneten
 Minimierungsverfahren zu bestimmen.
 Einige in dieser Arbeit verwendete Minimierungsverfahren werden in Kapitel
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Minimierungsverfahren"

\end_inset

 beschrieben.
 
\end_layout

\begin_layout Standard
Um eine Vorstellung von der Form einer solchen Likelihood-Funktion für das
 CO-Kriging Verfahren zu bekommen, wird in Anhang 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:AnhangLikelihoodCOKrigingBsp"

\end_inset

 ein einfaches Beispiel in Abhängigkeit verschiedener Hyperparameter gezeigt.
 Die Form der Funktion spielt auch für das gewählte Trainingsverfahren eine
 wesentliche Rolle.
\end_layout

\begin_layout Subsection
Likelihood Schätzer Erwartungswerte und Varianz 
\begin_inset CommandInset label
LatexCommand label
name "subsec:CoKrigingAnalytische-Bestimmung-derErwwartzungswerte"

\end_inset


\end_layout

\begin_layout Standard
Die Maximierung der Likelihood-Funktion in Abhängigkeit der Erwartungswerte
 
\begin_inset Formula $\overrightarrow{F}\in\mathbb{R^{\mathrm{n_{all}}}}$
\end_inset

 ist analytisch lösbar.
 Im Folgenden soll die Lösung dafür gezeigt werden.
 Die Anzahl der Gütestufen wird mit 
\begin_inset Formula $s$
\end_inset

 gekennzeichnet, die Anzahl der Stützstellen einer Gütestufe 
\begin_inset Formula $k\in\left\{ 1,...,s\right\} $
\end_inset

 wird mit 
\begin_inset Formula $n_{k}$
\end_inset

 bezeichnet und 
\begin_inset Formula $n_{all}$
\end_inset

 bezeichnet die Anzahl der Stützstellen aller Gütestufen.
 Das Maximum der Dichtefunktion 
\begin_inset Formula $f_{D}$
\end_inset

 nach dem Maximum Likelihood Ansatz (
\begin_inset Formula $MLE()$
\end_inset

 oder Maximum Likelihood Estimation) bezüglich des Vektors 
\begin_inset Formula $\overrightarrow{F}\in\mathbb{R^{\mathrm{n_{all}}}}$
\end_inset

 sieht wie folgt aus:
\end_layout

\begin_layout Paragraph
\begin_inset Formula 
\[
MLE\left(\overrightarrow{F}\right)=\max_{\overrightarrow{F}}\left(\frac{1}{\left(2\pi\right)^{\frac{n}{2}}|\mathbf{Cov}|^{\frac{1}{2}}}e^{-\frac{1}{2}\left(\overrightarrow{y_{s}}-\overrightarrow{F}\right)^{T}\mathbf{Cov}^{-1}\left(\overrightarrow{y_{s}}-\overrightarrow{F}\right)}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Führt man eine Matrix 
\begin_inset Formula $\mathbf{G}\in\mathbb{R^{\mathrm{n_{all}\times s}}}$
\end_inset

 ein in der Form:
\begin_inset Formula 
\begin{align}
\mathbf{G}= & \overset{s\,Einträge}{\underset{\overbrace{Spalte\,k}}{\overbrace{\left[\begin{array}{ccccc}
1 & \cdots & 0 & \cdots & 0\\
\vdots &  & \vdots &  & \vdots\\
1 & \cdots & 0 & \cdots & 0\\
\vdots &  & \vdots &  & \vdots\\
0 & \cdots & 1 & \cdots & 0\\
\vdots &  & \vdots &  & \vdots\\
0 & \cdots & 1 & \cdots & 0\\
\vdots &  & \vdots &  & \vdots\\
0 & \cdots & 0 & \cdots & 1\\
\vdots &  & \vdots &  & \vdots\\
0 & \cdots & 0 & \cdots & 1
\end{array}\right]}}}\begin{array}{c}
\left\} \begin{array}{c}
\\
n_{1}\,Eintr\ddot{a}ge\\
\\
\end{array}\right.\\
\vdots\\
\left\} \begin{array}{c}
\\
n_{k}\,Eintr\ddot{a}ge\\
\\
\end{array}\right.\\
\vdots\\
\left\} \begin{array}{c}
\\
n_{s}\,Eintr\ddot{a}ge\\
\\
\end{array}\right.
\end{array}
\end{align}

\end_inset

Und einen Vektor 
\begin_inset Formula $\vec{\tilde{F}}\in\mathbb{R^{\mathrm{s\times1}}}$
\end_inset

, so gilt folgende Beziehung:
\begin_inset Formula 
\begin{align*}
\vec{F} & =\mathbf{G}\vec{\tilde{F}}
\end{align*}

\end_inset

Daraus folgt:
\begin_inset Formula 
\begin{align*}
MLE\left(\vec{\tilde{F}}\right) & =\max_{\overrightarrow{F}}\left(\frac{1}{\left(2\pi\right)^{\frac{n}{2}}|\mathbf{Cov}|^{\frac{1}{2}}}e^{-\frac{1}{2}\left(\overrightarrow{y_{s}}-\mathbf{G}\vec{\tilde{F}}\right)^{T}\mathbf{Cov}^{-1}\left(\overrightarrow{y_{s}}-\mathbf{G}\vec{\tilde{F}}\right)}\right)
\end{align*}

\end_inset

Mit dieser Gleichung lässt sich der gesuchte Erwartungswertvektor 
\begin_inset Formula $\vec{\tilde{F}}$
\end_inset

 des Kriging Prozesses innerhalb des Trainings analytisch bestimmen.
 Die Lösung sieht wie folgt aus, wobei der komplette Lösungsweg in Anhang
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Likelihood-Schätzer-Erwartungswe"

\end_inset

 zu finden ist:
\begin_inset Formula 
\begin{align*}
\left(\overrightarrow{y_{s}}^{T}\mathbf{Cov}^{-1}\mathbf{G}\right)\left(\mathbf{G}^{T}\mathbf{Cov}^{-1}\mathbf{G}\right)^{-1} & =\vec{\tilde{F}}^{T}
\end{align*}

\end_inset


\end_layout

\begin_layout Paragraph*
Varianz
\end_layout

\begin_layout Standard
Die direkte analytische Bestimmung der Varianz für das hier vorgestellte
 Co-Kriging ist bisher nicht bekannt.
 Viele Co-Kriging Verfahren aus der Literatur (siehe 
\begin_inset CommandInset citation
LatexCommand cite
key "forrester2007multi,LeGratiet,Kennedy2000"

\end_inset

) wählen einen Co-Kriging Ansatz, welcher an jedem Punkt hoher Güte einen
 Punkt niedriger Güte fordert.
 Damit können die Gütestufen in einem abgestuften Verfahren trainiert werden,
 womit diese Problemstellung weg-fällt.
 Es ist allerdings eine iterative Bestimmung möglich, diese Art der Bestimmung
 wird in Anhang 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Iterative-VarianzbestimmungTraining"

\end_inset

 beschrieben und bringt allerdings viele numerische Probleme mit sich und
 wurde aus diesem Grund nicht verwendet.
 Innerhalb dieses Verfahrens wurden die Varianzen als zusätzlicher Hyperparamete
r innerhalb des Trainings freigegeben und werden dann über das Training
 bestimmt.
 Die Ableitung des Likelihood-Terms aus Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:AbleitungLogLikelihood"

\end_inset

 besitzt auch für die Varianz Gültigkeit.
\end_layout

\begin_layout Subsection
Initialisierung der Hyperparameter für alle Kriging Modelle 
\begin_inset CommandInset label
LatexCommand label
name "sec:Initialisierung-der-Hyperparamet"

\end_inset


\end_layout

\begin_layout Standard
Um das Training starten zu können, ist eine geeignete Initialisierung der
 Hyperparameter von großer Bedeutung.
 Diese kann die Konvergenz und auch die Stabilität der Minimierung stark
 beeinflussen.
 Innerhalb dieser Arbeit wurden mehrere Ansätze entwickelt, um eine geeignete
 Initialisierung zu finden.
 
\end_layout

\begin_layout Subsubsection*
Allgemeine Vorbemerkungen und Definitionen
\end_layout

\begin_layout Standard
Ein wichtiger Punkt ist die initiale Menge an Daten, die für eine sinnvolle
 Schätzung der Hyperparameter notwendig ist.
 In 
\begin_inset CommandInset citation
LatexCommand cite
key "gibbs1997efficient"

\end_inset

 wird vorgeschlagen, mindestens das zehnfache der Parameteranzahl zu verwenden,
 bevor eine vernünftige Schätzung möglich ist.
 Die Arbeit von 
\begin_inset CommandInset citation
LatexCommand cite
key "Jin2001"

\end_inset

 hingegen zeigt, dass je nach Funktion auch dreimal die Anzahl der Parameter
 genügt, um vernünftige Schätzungen zu erwarten.
 Oftmals sind die Prozessketten allerdings so langwierig oder die Konvergenzrate
 sehr schlecht, so dass sehr aufwendige Initialisierungen wie sie 
\begin_inset CommandInset citation
LatexCommand cite
key "gibbs1997efficient"

\end_inset

 vorschlägt nicht möglich sind.
 Eine sehr gute Möglichkeit, um die Datenlage zu beurteilen ist die Nutzung
 der hier entwickelten Kriging-Analysesoftware, siehe 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Laufzeit-Analysesoftware-für-Kri"

\end_inset

.
 So kann in der Initialisierungsphase regelmäßig ein Training durchgeführt
 und Beurteilt werden.
 Besonders der Verlauf des Likelihood-Terms über der Optimierungslaufzeit
 eignet sich, um erkennen zu können ob eine ausreichende Anzahl von Stützstellen
 vorhanden ist oder nicht.
 
\end_layout

\begin_layout Paragraph*
Normalisierung der Daten
\end_layout

\begin_layout Standard
Die innerhalb dieser Arbeit entwickelte Software nimmt intern eine Normalisierun
g der Daten vor.
 Dabei werden die Funktionswerte 
\begin_inset Formula $\overrightarrow{y}_{s}\in\mathbb{R^{\mathrm{n_{all}}}}$
\end_inset

 als auch die Parameter 
\begin_inset Formula $\vec{x}\in\mathbb{R^{\mathrm{k}}}$
\end_inset

 standardnormalverteilt standardisiert.
\begin_inset Formula 
\begin{align}
E[\overrightarrow{y}_{s}]=0\nonumber \\
var[\overrightarrow{y}_{s}]=1\label{eq:NormalisierungYs}\\
\begin{array}{c}
E[x_{i}]=0\\
var[x_{i}]=1
\end{array} & \forall x_{i},i\in\{1,...,k\}
\end{align}

\end_inset

Ändert sich jedoch die Datenbasis für das Training und damit auch die Normalisie
rungskonstanten, so müssen die Hyperparameter neu standardisiert werden,
 in Anhang 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Renormalisierung-der-Hyperparame"

\end_inset

 wird eine solche (Re)standardisierung beschrieben.
 
\end_layout

\begin_layout Paragraph
Aufteilung der Hyperparameter in Klassen
\end_layout

\begin_layout Standard
\begin_inset Wrap table
lines 0
placement o
overhang 0col%
width "50col%"
status open

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Zeichen
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Anzahl 
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Korrelationsl.
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\vec{\theta}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $s$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Varianzen
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\sigma^{2}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $s$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Diagonalauf.
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\lambda$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $s$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Skalierung
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $a$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $s-1$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:Kategorien-von-Hyperparametern"

\end_inset

Kategorien von Hyperparametern bei 
\begin_inset Formula $s$
\end_inset

 Gütestufen
\end_layout

\end_inset


\end_layout

\end_inset

Die in den vorhergehenden Kapiteln 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Die-Kriging-Verfahren"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Kovarianzmatrix"

\end_inset

 und 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:RegularisierungUndRauschen"

\end_inset

 beschriebenen Hyperparameter lassen sich in Kategorien aufteilen, diese
 sind in Tabelle 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Kategorien-von-Hyperparametern"

\end_inset

 aufgelistet.
 
\end_layout

\begin_layout Standard
Diese Einteilung ist für die Initialisierung sehr wichtig, da jede dieser
 Gruppen anders initialisiert werden muss.
 Für die Diagonalaufschläge 
\begin_inset Formula $\lambda$
\end_inset

 wird das in Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Regularisierung"

\end_inset

 beschriebene Verfahren verwendet und wird daher innerhalb dieses Abschnittes
 nicht weiter beschrieben.
 
\end_layout

\begin_layout Subsubsection*
Abschätzung konstanter Hyperparameter 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Const"

\end_inset


\end_layout

\begin_layout Standard
Eine einfache und schnelle Methode eine Initialisierung für die Hyperparameter
 zu wählen, ist in 
\begin_inset CommandInset citation
LatexCommand cite
key "schmitz2013"

\end_inset

 beschrieben.
 Dafür wird für die Hyperparameter nur ein konstanter Wert verwendet und
 obere und untere Grenzen 
\begin_inset Formula $\theta_{min},\theta_{max}\in\mathbb{R}$
\end_inset

 bestimmt.
 
\begin_inset Formula 
\begin{align}
\theta & =\theta_{i}\forall i\in\{1,...,o\}\\
\theta_{min} & \leq\theta\leq\theta_{max}\nonumber 
\end{align}

\end_inset

Danach werden zwischen diesen Grenzen einige Werte ausprobiert und der Likelihoo
d Term berechnet und letztlich der Satz mit dem besten Likelihood-Term gewählt.
 Zur Bestimmung der minimalen und maximalen Grenze wird ein in 
\begin_inset CommandInset citation
LatexCommand cite
key "schmitz2013"

\end_inset

 (Kapitel 5.2) beschriebenes Schätzverfahren verwendet.
 
\end_layout

\begin_layout Subsubsection*
Zufällige Initialisierung der Hyperparameter
\begin_inset CommandInset label
LatexCommand label
name "subsec:RandomInit"

\end_inset


\end_layout

\begin_layout Standard
Eine weitere Möglichkeit zur Initialisierung der Hyperparameter, liegt in
 der zufälligen Erzeugung von Parametersätzen.
 Hierfür werden eine gewisse Anzahl an zufälligen Hyperparametersätzen erzeugt
 und mit der Likelihood-Funktion bewertet.
 Die Skalierungsfaktoren werden innerhalb folgender Grenzen variiert:
\begin_inset Formula 
\begin{align}
0.75 & \leq a\leq1.5
\end{align}

\end_inset

Die zufällige Variation wird mit einer Gleichverteilung realisiert.
 Letztlich wir dann der Parametersatz gewählt, welcher die die beste Likelihood
 Funktion aufweist.
 Die Wahrscheinlichkeit einen sinnvollen Parametersatz zu finden, ist bei
 diesem Verfahren allerdings sehr klein.
 
\end_layout

\begin_layout Subsubsection*
Zufällige Initialisierung der Hyperparameter mit Vererbung
\begin_inset CommandInset label
LatexCommand label
name "subsec:RandomInit2"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Wrap table
lines 0
placement O
overhang 0in
width "52col%"
status open

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Zeichen
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\sigma_{search}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Korrelationsl.
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\vec{\theta}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.05\left|\theta_{max}-\theta_{min}\right|$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Varianzen
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\sigma^{2}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.25$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Skalierung
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $a$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.1$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:Kategorien-von-Hyperparametern-1"

\end_inset

Kategorien von Hyperparametern und die verwendete Suchbreite
\end_layout

\end_inset


\end_layout

\end_inset

Um das zufällige Initialisierungsverfahren zu beschleunigen, kann nur ein
 Wert für die Korrelationslängen einer Gütestufe 
\begin_inset Formula $k\in\{1,...,s\}$
\end_inset

 angenommen werden:
\begin_inset Formula 
\begin{equation}
\theta_{k}=\theta_{i,k}\forall i\in\{1,...,o\}
\end{equation}

\end_inset

Nachdem ein erster erfolgreicher Parametersatz 
\begin_inset Formula $\theta_{k,best}$
\end_inset

 gefunden wurde, wird ausgehend von diesem Satz normalverteilt variiert.
 Dadurch kann eine schnellere Konvergenz erreicht werden.
\begin_inset Formula 
\begin{equation}
\theta_{k}=\mathcal{N}(\theta_{k,best},\sigma_{search})
\end{equation}

\end_inset

Die Standardabweichung 
\begin_inset Formula $\sigma_{search}$
\end_inset

 der Normalverteilung gibt in diesem Fall die Suchbreite an, je größer der
 Wert, desto weiträumiger wird gesucht.
 Der Skalierungsfaktor 
\begin_inset Formula $a$
\end_inset

 und die Prozessvarianzen werden auf die selbe Art und Weise variiert.
 Tabelle 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Kategorien-von-Hyperparametern-1"

\end_inset

 stellt die Suchweiten dar, wobei diese auf Erfahrungswerten beruhen.
 Der Skalierungsfaktor und auch die Prozessvarianz werden bei der Initialisierun
g mit 
\begin_inset Formula $\sigma^{2}=1;a=1$
\end_inset

 belegt.
 Die Initialisierung der Prozessvarianz folgt aufgrund der Normalisierung
 aus Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:NormalisierungYs"

\end_inset

.
\end_layout

\begin_layout Subsubsection*
Initialisierung auf Basis bereits vorhandener Kriging Modelle
\begin_inset CommandInset label
LatexCommand label
name "subsec:UltraRestart"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Wrap figure
lines 31
placement o
overhang 0in
width "45col%"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../images/UltraRestart/Vergleich.png
	lyxscale 15
	scale 15

\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Graphics
	filename ../images/UltraRestart/VergleichTrainingsZeit.png
	lyxscale 15
	scale 15

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:RestartRandomLikelihood"

\end_inset

Vergleich verschiedener Initialisierungsverfahren und deren Auswirkung auf
 eine Testoptimierung
\end_layout

\end_inset


\end_layout

\end_inset

Das Kriging Modell wird in der Regel innerhalb einer Optimierung verwendet.
 Dies bedeutet im Normalfall, dass mehrfach trainiert wird und so die Hyperparam
eter neu bestimmt werden.
 Grundsätzlich wäre es sinnvoll die Hyperparameter aus den letzten trainierten
 Modellen zur Initialisierung zu verwenden.
 Als einfacher Ansatz wäre es z.B.
 möglich die Hyperparameter aus dem letzten Training zu Initialisierung
 zu verwenden.
 Diese Art der Wiederverwendung von alten Trainings ist für das Kriging
 Verfahren ohne Probleme möglich.
 
\end_layout

\begin_layout Standard
Bei der Wiederverwendung alter Hyperparametersätz müssen jedoch zwei Problemstel
lungen beachtet werden:
\end_layout

\begin_layout Enumerate
Das letzte Modell befindet sich in einem lokalen Minimum der Likelihood
 Funktion
\end_layout

\begin_layout Enumerate
Die Hyperparameter der Kovarianz Funktion(en) sind noch nicht richtig eingestell
t
\end_layout

\begin_layout Standard
Im ersten Fall besteht die Gefahr, dass das Training durch die ungünstige
 Initialisierung in einem lokalen Minimum bleibt und so nicht die optimalen
 Hyperparameter findet.
 Das wiederum führt zu schlechten Vorhersagen.
 Im Extremfall kann es sogar passieren, dass das lokale Minimum während
 der gesamten Optimierung nicht mehr verlassen wird.
 
\end_layout

\begin_layout Standard
Der zweite Fall ist insbesondere am Anfang der Optimierung interessant,
 denn am Anfang hat man in der Regel nur wenig Samples zur Verfügung und
 damit ist es dem Kriging Training noch nicht möglich die richtigen Hyperparamet
er für die Kovarianzfunktion zu schätzen.
 Diese Fälle treten erfahrungsgemäß leider sehr häufig auf, deshalb sollte
 man auf diese Art der Initialisierung verzichten.
\end_layout

\begin_layout Standard
Eine rein zufällige Initialisierung hat allerdings den Nachteil, dass die
 Trainingszeit enorm steigt und die Modelle im Laufe der Optimierung sehr
 unterschiedlich ausfallen können.
 Eine andere Möglichkeit der Initialisierung ist eine Mischform zwischen
 zufälliger Initialisierung und der Verwendung alter Modelle.
 In diesem Fall soll ein Kriterium darüber entscheiden, ob ein altes Kriging
 Modell verwendet werden soll oder eine zufällige Initialisierung durchgeführt
 werden soll.
 Zudem ist es sinnvoll nicht nur das letzte Kriging Modell zu betrachten,
 sondern noch weitere Modelle die während der Optimierung entstanden sind.
 Dies macht insbesondere Sinn, da das Ausprobieren eines vorhandenen Hyperparame
ter Satz im Vergleich zum Training nur einen Bruchteil der Zeit benötigt
 und man so einzelne 
\begin_inset Quotes eld
\end_inset

Ausreißer
\begin_inset Quotes erd
\end_inset

 in den Modellen nicht den weiteren Optimierungsverlauf gefährden.
 Der in AutoOpti verwendete Algorithmus sieht wie folgt aus:
\begin_inset listings
lstparams "numbers=left,basicstyle={\scriptsize},tabsize=4"
inline false
status open

\begin_layout Plain Layout

krigingFiles = getLastKrigingFiles(20)
\end_layout

\begin_layout Plain Layout

wenn krigingFiles.size() < 20 
\end_layout

\begin_layout Plain Layout

dann
\end_layout

\begin_layout Plain Layout

	initType = random
\end_layout

\begin_layout Plain Layout

	end()
\end_layout

\begin_layout Plain Layout

		
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

Schleife von i=0 bis  i < krigingFiles.size() Schrittweite 1
\end_layout

\begin_layout Plain Layout

	oldLikelihood = getLikelihood(krigingFiles[i])
\end_layout

\begin_layout Plain Layout

	newLikelihood = calculateLikelihood(krigingFiles[i])
\end_layout

\begin_layout Plain Layout

	wenn newLikelihood < bestLikelihood
\end_layout

\begin_layout Plain Layout

		und newLikelihood < oldLikelihood
\end_layout

\begin_layout Plain Layout

		und newLikelihood < -numberSamples/4.0
\end_layout

\begin_layout Plain Layout

	dann
\end_layout

\begin_layout Plain Layout

		bestLikelihood =newLikelihood
\end_layout

\begin_layout Plain Layout

		bestKrigingFile = krigingFiles[i]
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

wenn bestKrigingFile==leer 
\end_layout

\begin_layout Plain Layout

dann initType = random
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Der Algorithmus startet mit dem Speichern der Dateinamen der letzten 20
 Kriging Modelle aus der laufenden Optimierung (Zeile 2).
 Sind noch keine 20 Kriging Modelle erzeugt worden, soll die Initialisierung
 zufällig erfolgen (Zeile 3-6).
 In der darauffolgenden for Schleife erfolgt nun die Bewertung der einzelnen
 Kriging Modelle.
 Für die Bewertung muss zuerst der alte Likelihood Wert ausgelesen werden,
 dies geschieht in Zeile 10.
 Im nächsten Schritt muss der Likelihood mit der aktuellen Datenbasis neu
 berechnet werden, in der Regel sind an dieser Stelle einige Member zur
 Datenbasis hinzugekommen.
 Dieser Schritt ist numerisch auch der aufwendigste, eine effiziente Methode
 diese Funktion zu berechnen wird in Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Inverse-durch-Gleichungssysteme"

\end_inset

 beschrieben.
 In der darauffolgenden If-Abfrage geht darum das beste Modell der 20 eingelesen
en Kriging Modelle zu finden.
 Hierfür wird einfach der kleinste Likelihood verwendet (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:COKrigingTraining"

\end_inset

).
 Zudem ist eine weitere Bedingung, dass der neu berechnete Likelihood kleiner
 sein muss, als der bereits eingelesene aus dem vorhergehenden Modell.
 Die Überlegung hierbei ist, dass wenn ein neues Sample eingefügt wird und
 dieses nicht in die angenommene Verteilung passt, die Hyperparameter vollständi
g neu eingestellt werden müssen.
 Im umgekehrten Fall, sollte der Likelihood kleiner werden, da dieser linear
 mit der Sample Anzahl sinkt.
 Als letzte Bedingung ist eine absolute Grenze für den Likelihood Wert angegeben
, diese basiert rein auf Erfahrungswerten und soll sicherstellen, dass grundsätz
lich zu schlechte Modelle zufällig initialisiert werden.
 Dies ist meistens am Anfang einer Optimierung der Fall, wenn noch nicht
 genügend Daten vorhanden sind, um die Kovarianzfunktion ausreichend gut
 zu schätzen.
 In diesem Fall ist eine zufällige Initialisierung ebenfalls günstiger.
 Dieses Verfahren wird in der hier vorgestellten Implementierung als Standard
 verwendet und hat sich erfahrungsgemäß als sehr stabil und schnell erwiesen.
 Folgende Abbildung zeigt das Verfahren in Anwendung einer Testoptimierung,
 auf der Ordinate ist der erreichte Likelihoodterm (kleiner ist besser)
 und auf der Abzisse der Optimierungsschritt.
 
\end_layout

\begin_layout Subsection
Minimierungsverfahren 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Minimierungsverfahren"

\end_inset


\end_layout

\begin_layout Standard
Innerhalb des Kriging Modells wurden zwei verschiedene mehrdimensionale
 Minimierungsverfahren eingesetzt.
 Beide Verfahren waren bereits in einer institutseigenen Software Bibliothek
 verfügbar.
 
\end_layout

\begin_layout Subsection*
Minimierungsverfahren angelehnt an Resilient Backpropagation (RPROP)
\begin_inset CommandInset label
LatexCommand label
name "subsec:RPROP"

\end_inset


\end_layout

\begin_layout Standard
Das erste hier verwendete Minimierungsverfahren ist angelehnt an ein Trainingsve
rfahren für Neuronale Netzwerke, genannt RPROP (Resilient Backpropagation)
 
\begin_inset CommandInset citation
LatexCommand cite
key "riedmiller1993direct,NNSchiffmann"

\end_inset

 und ist ein Verfahren erster Ordnung.
 Besonderheit des Verfahrens ist, dass es nur das Vorzeichen der partiellen
 Ableitungen verwendet und nicht den Wert selbst.
 
\end_layout

\begin_layout Standard
Die Änderung der Hyperparameter 
\begin_inset Formula $\theta_{i}$
\end_inset

 für den nächsten Iterationsschritt 
\begin_inset Formula $t+1$
\end_inset

 ergibt sich aus der Schrittweite 
\begin_inset Formula $\gamma_{i}$
\end_inset

.
 Diese wird für jeden Hyperparameter einzeln bestimmt und in jeder Iteration
 geändert.
 Die Änderung hängt nur von dem Vorzeichen der entsprechenden partiellen
 Ableitung 
\begin_inset Formula $\frac{\partial f}{\partial\theta_{i}}$
\end_inset

 zum Zeitpunkt t der zu minimierenden Funktion 
\begin_inset Formula $f$
\end_inset

 ab.
\begin_inset Formula 
\begin{align*}
\theta_{i}^{t+1} & =\theta_{i}^{t}-\gamma_{i}^{t}\textrm{sgn}\left(\left(\frac{\partial f}{\partial\theta_{i}}\right)^{t}\right)
\end{align*}

\end_inset

Die Schrittweite wird in jedem Iterationsschritt für jeden Hyperparameter
 einzeln angepasst.
 Dies wird über zwei Multiplikatoren erzielt 
\begin_inset Formula $\eta^{+}\in\mathbb{R};\eta^{+}>1$
\end_inset

 und 
\begin_inset Formula $\eta^{-}\in\mathbb{R};\eta^{-}<1$
\end_inset

.
 Ist die entsprechende partielle Ableitung aus dem letzten Schritt multipliziert
 mit dem jetzigen Schritt größer als Null, wird die Schrittweite erhöht,
 indem die Schrittweite 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\lang english

\begin_inset Formula $\gamma_{i}^{t}$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
\lang ngerman
 multipliziert wird mit 
\begin_inset Formula $\eta^{+}$
\end_inset

.
 Wenn die partielle Ableitung aus dem letzten Schritt multipliziert mit
 dem jetzigen Schritt kleiner als Null ist, dann wird die Schrittweite verkleine
rt durch Multiplikation mit 
\begin_inset Formula $\eta^{-}$
\end_inset

.
 Für die Schrittweite wird zudem eine Unter- und Obergrenze (
\begin_inset Formula $\gamma_{min},\gamma_{max}$
\end_inset

) festgelegt.
 
\begin_inset Formula 
\begin{align*}
\gamma_{i}^{t+1} & =\begin{cases}
\min\left(\gamma_{i}^{t}\eta^{+},\gamma_{max}\right) & wenn\left(\frac{\partial f}{\partial\theta_{i}}\right)^{t}\left(\frac{\partial f}{\partial\theta_{i}}\right)^{t-1}>0\\
\max\left(\gamma_{i}^{t}\eta^{-},\gamma_{min}\right) & wenn\left(\frac{\partial f}{\partial\theta_{i}}\right)^{t}\left(\frac{\partial f}{\partial\theta_{i}}\right)^{t-1}<0\\
\gamma_{i}^{t} & sonst
\end{cases}
\end{align*}

\end_inset

Bei sehr flachen Bereichen der zu minimierenden Funktion, wo die partiellen
 Ableitungen nur sehr klein sind, würden andere Gradientenverfahren nur
 sehr langsam bis gar nicht mehr vorwärts kommen.
 Da dieses Verfahren allerdings die Größe der Gradienten überhaupt nicht
 berücksichtigt, kann dies nicht passieren.
 Das ist bei der Likelihood Funktion von besonderem Vorteil, da diese bereits
 durch Ihre Definition sehr viele flache Gebiete aufweist.
 
\end_layout

\begin_layout Subsection*
Erweiterung des RPROP-Verfahrens an sehr viele Hyperparameter
\begin_inset CommandInset label
LatexCommand label
name "subsec:RPROP2"

\end_inset


\end_layout

\begin_layout Standard
Ein sehr großes Problem bei dem RPROP-Verfahren ist, dass es relativ viele
 Iterationen benötigt bis es konvergiert.
 In jedem Iterationsschritt muss zum einen der Dichtefunktionswert der Likelihoo
d Funktion berechnet werden (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Inverse-durch-Gleichungssysteme"

\end_inset

) und zum anderen die partiellen Ableitungen nach den Hyperparametern (siehe
 Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Ableitung-LikelihoodRueckMode"

\end_inset

).
 Im Falle eines Co-Krigings skaliert die Anzahl der Hyperparameter 
\begin_inset Formula $o=m_{f}k+3m_{f}$
\end_inset

 mit der Anzahl der Gütestufen 
\begin_inset Formula $m_{f}$
\end_inset

 und der Anzahl an freien Variablen 
\begin_inset Formula $k$
\end_inset

.
 Für jeden dieser 
\begin_inset Formula $o$
\end_inset

 Hyperparameter muss dann jeweils eine partielle Ableitung gebildet werden.
 Ist die Anzahl der Hyperparameter 
\begin_inset Formula $o$
\end_inset

 sehr groß, wie es im Co-Kriging oft der Fall ist, dann übersteigt der Aufwand
 für die Berechnung der partiellen Ableitungen den Aufwand für die Bestimmung
 des Likelihood-Terms.
 Diesen Umstand kann man sich innerhalb des RPROP-Verfahrens zunutze machen:
\end_layout

\begin_layout Standard
Die Lernraten 
\begin_inset Formula $\eta^{+},\eta^{-}$
\end_inset

 sind im RPROP-Verfahren konstant (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:RPROP"

\end_inset

), insbesondere bei den anfänglichen Iterationsschritten führt dies zu einem
 relativ langsamen Anpassen der Deltas 
\begin_inset Formula $\gamma_{i}^{t}$
\end_inset

.
 Es wäre daher wünschenswert die Lernraten ebenfalls zu variieren und dadurch
 eine schnellere Anpassung der Deltas 
\begin_inset Formula $\gamma_{i}^{t}$
\end_inset

 zu erreichen.
 Eine gute Möglichkeit ist es verschiedene Lernraten auszuprobieren, dadurch
 müssen zwar mehr Dichtefunktionsauswertungen gemacht werden.
 Im Gegenzug werden aber deutlich weniger Iterationen benötigt und damit
 auch weniger Berechnungen der partiellen Ableitungen.
 In einem Fall wie dem Co-Kriging kann eine solche Vorgehensweise zu einer
 deutlichen Beschleunigung führen.
 Der folgende Pseudo-Programmcode zeigt die Umsetzung des neuen Verfahrens:
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "basicstyle={\scriptsize},tabsize=4"
inline false
status open

\begin_layout Plain Layout

density = RPROPDensity(eta_plus, eta_minus)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

// Teste kleinere und größere Lernraten für eta_plus
\end_layout

\begin_layout Plain Layout

Schleife von eta_plusFact=0.9 bis eta_plusFact<=1.1 Schrittweite 0.2
\end_layout

\begin_layout Plain Layout

	newEtaPlus = eta_plus*eta_plusFact
\end_layout

\begin_layout Plain Layout

	wenn newEtaPlus<1.2 dann newEtaPlus=1.2
\end_layout

\begin_layout Plain Layout

	wenn newEtaPlus>2.0 dann newEtaPlus=2.0
\end_layout

\begin_layout Plain Layout

	wenn eta_plus==newEtaPlus dann überspringe
\end_layout

\begin_layout Plain Layout

		
\end_layout

\begin_layout Plain Layout

	newDensity = RPROPDensity(newEtaPlus, eta_minus)
\end_layout

\begin_layout Plain Layout

	wenn newDensity<density dann eta_plus=newEtaPlus
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

// Teste kleinere und größere Lernraten für eta_minus
\end_layout

\begin_layout Plain Layout

Schleife von eta_minusFact=0.9 bis eta_minusFact<=1.1 Schrittweite 0.2
\end_layout

\begin_layout Plain Layout

	newEtaMinus = eta_minus*eta_minusFact
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

	wenn newEtaMinus<0.4 dann newEtaMinus=0.4
\end_layout

\begin_layout Plain Layout

	wenn newEtaMinus>0.7 dann newEtaMinus=0.7
\end_layout

\begin_layout Plain Layout

	wenn eta_minus==newEtaMinus dann überspringe
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

	newDensity = RPROPDensity(eta_plus, newEtaMinus)
\end_layout

\begin_layout Plain Layout

	wenn newDensity<density dann eta_minus=newEtaMinus
\end_layout

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
In einem Iterationsschritt, wird dann zuerst der Dichtefunktionswert  mit
 den bisherigen Lernraten 
\begin_inset Formula $\eta^{+},\eta^{-}$
\end_inset

 berechnet.
 Danach wird 
\begin_inset Formula $\eta^{+}$
\end_inset

 leicht erhöht und auch verringert und der Dichtefunktionswert bestimmt.
 Sollte sich das neue 
\begin_inset Formula $\eta^{+}$
\end_inset

 nicht geändert haben, so wird sich die Berechnung der Dichtefunktion gespart.
 Gewählt wird die Lernrate mit dem geringsten Dichtefunktionswert.
 Für die Lernrate 
\begin_inset Formula $\eta^{-}$
\end_inset

 gilt im Prinzip dasselbe.
 
\end_layout

\begin_layout Standard
\begin_inset Wrap table
lines 0
placement o
overhang 0in
width "45col%"
status open

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
RPROP
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
RPROP2
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Zeit
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
346.3s
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
186s
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Mittl.
 Fehler
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.0201
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.0149
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Iterationen
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
781
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
398
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:Ergebnisse-beider-Verfahren"

\end_inset

Ergebnisse beider Verfahren im direkten Vergleich.
 Die Ergebnisse stellen den Mittelwert der 10 durchgeführten Trainings dar.
\end_layout

\end_inset


\end_layout

\end_inset

Für diese Art der Lernratenregelung sind maximal 4 neue Dichtefunktionsauswertun
gen notwendig, im Gegenzug hat man allerdings eine deutliche Verringerung
 der Iterationsanzahl und muss somit deutlich weniger partielle Ableitungen
 bestimmen.
 Diese sollte insbesondere für das CO-Kriging von großem Vorteil sein.
\end_layout

\begin_layout Standard
Um das Verfahren zu validieren, wurde eine Datenbasis aus einer aktuellen
 Optimierung für einen gegenläufigen Rotor verwendet (
\begin_inset CommandInset citation
LatexCommand cite
key "Lengyel-Kampmann2015"

\end_inset

).
 Es gab ca.
 113 freie Parameter und für das CO-Kriging somit 228 Hyperparameter (130*2
 und 2x die Prozessvarianzen der Kovarianzfunktionen) und die Datenbasis
 enthielt zu diesem Zeitpunkt 373 Member.
 Das CO-Kriging wurde mit zufälligen Hyperparametern initialisiert und 10x
 mit dem RPROP Verfahren trainiert und 10x mit dem neuen RPROP2 Verfahren.
 Die Vorhersagen der fertig trainierten Ersatzmodelle wurden dann anhand
 einer Testdatenbasis validiert und ein mittlerer Vorhersagefehler bestimmt.
 Tabelle 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Ergebnisse-beider-Verfahren"

\end_inset

 zeigt die Ergebnisse beider Verfahren.
\end_layout

\begin_layout Standard
\begin_inset Wrap figure
lines 0
placement o
overhang 0in
width "45col%"
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../images/RPROP2/Vergleich.png
	scale 17

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:RPROP_2_Verlauf"

\end_inset

Konvergenzverlauf der beiden Verfahren anhand eines Beispiels
\end_layout

\end_inset


\end_layout

\end_inset

Man kann sehen, dass das RPROP Verfahren in diesem Beispiel die 1.86 fache
 Zeit benötigt um Konvergenz zu erreichen.
 Dies wird hauptsächlich durch die deutlich geringere Iterationsanzahl erreicht.
 Die mittleren Fehler sind in etwa vergleichbar, die etwas geringeren Fehler
 beim RPROP2 sind mit hoher Wahrscheinlichkeit zufälliger Natur.
 Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:RPROP_2_Verlauf"

\end_inset

 zeigt nochmal den gemittelten Trainingsverlauf beider Verfahren.
 Die rote und schwarze Kurve stellt den mittleren Dichtefunktionswert über
 den Iterationsschritten dar.
 Die Fehlerbalken sind die Standardabweichungen der verschiedenen Trainings.
 Auch hier lässt sich gut erkennen, dass das RPROP2 Verfahren eine deutlich
 schnelleren Konvergenzverlauf hat, insbesondere am Anfang.
 Dies wird durch die schneller eingestellten Deltas erreicht.
 
\end_layout

\begin_layout Standard
Bei einem Verfahren wie dem Co-Kriging wo grundsätzlich eine hohe Anzahl
 an Hyperparametern zu erwarten ist, ist es sinnvoll ein solches Verfahren
 einzusetzen.
\end_layout

\begin_layout Subsection*
Quasi Newton
\begin_inset CommandInset label
LatexCommand label
name "subsec:Quasi-Newton"

\end_inset


\end_layout

\begin_layout Standard
Das zweite implementierte Minimierungsverfahren ist ein Verfahren höherer
 Ordnung namens Quasi Newton.
 Basis für diese Art der mehrdimensionalen Minimierung ist eine Taylor Approxima
tion zweiten Grades, wobei 
\begin_inset Formula $t$
\end_inset

 der Iterationsschritt ist und 
\begin_inset Formula $\mathbf{H}$
\end_inset

 die Hesse Matrix: 
\begin_inset Formula 
\begin{align*}
f\left(\vec{\theta}\right) & \approx f\left(\vec{\theta}_{t}\right)+\left(\vec{\theta}-\vec{\theta}_{t}\right)^{T}\nabla f\left(\vec{\theta}_{k}\right)+\frac{1}{2}\left(\vec{\theta}-\vec{\theta}_{t}\right)^{T}\mathbf{H}\left(\vec{\theta}_{t}\right)\left(\vec{\theta}-\vec{\theta}_{t}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Die entsprechende Ableitung dieser Funktion muss im Minimum oder Maximum
 der Funktion Null ergeben:
\begin_inset Formula 
\begin{align*}
\nabla f\left(\vec{\theta}\right) & \approx\nabla f\left(\vec{\theta}_{t}\right)+\mathbf{H}\left(\vec{\theta}_{t}\right)\left(\vec{\theta}-\vec{\theta}_{t}\right)=0
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Besonderheit bei der Quasi Newton Methode ist, dass die Hesse Matrix 
\begin_inset Formula $\mathbf{H}$
\end_inset

, nicht direkt berechnet werden muss, sondern sukzessive über die Gradienten
 angenähert wird.
 Vorteil des Verfahrens ist, dass es deutlich schneller konvergiert als
 das bereits vorgestellte Verfahren erster Ordnung.
 Allerdings ist es weniger robust und kann in flachen Gebieten der Funktion
 langsam bis gar nicht konvergieren.
 Die exakte Umsetzung des Algorithmus und weitere Details können in 
\begin_inset CommandInset citation
LatexCommand cite
key "press2007numerical,gill1981practical,gill2007numerical"

\end_inset

 gefunden werden.
 
\end_layout

\begin_layout Subsection*
Vergleich QuasiNewton / RPROP / RPROP2 und Initialisierungsverfahren
\end_layout

\begin_layout Standard
In diesem Kapitel soll ein direkter Vergleich zwischen den verschiedenen
 Optimierungsverfahren angestellt werden.
 Hierfür wurde ein Testfall aus der Fanstufenoptimierung (siehe Kapitel
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:CRISP-Testfall"

\end_inset

) zusammengestellt.
 
\end_layout

\begin_layout Itemize
Trainingsfunktion: 
\begin_inset Formula $\dot{m}_{OP1}$
\end_inset

 (Massenstrom Betriebspunkt 1)
\end_layout

\begin_layout Itemize
Stützstellen (niedrige / hohe Güte): 300 / 500
\end_layout

\begin_layout Itemize
Testdatenbasis: 400 Stützstellen hoher Güte
\end_layout

\begin_layout Itemize
Maximal 1000 Trainingsiterationen
\end_layout

\begin_layout Itemize
20 Threads auf zwei Intel(R) Xeon(R) CPU E5-2650 v3
\end_layout

\begin_layout Itemize
Pro Testfall 10 aufeinanderfolgende Trainings
\end_layout

\begin_layout Itemize
Das Initialisierungsverfahren, ist das 
\begin_inset Quotes gld
\end_inset

Initialisierung auf Basis vorhandener Kriging Modelle
\begin_inset Quotes grd
\end_inset

 aus Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:UltraRestart"

\end_inset

.
 Das Verfahren nutzt 5 bereits trainierte Kriging Modelle
\end_layout

\begin_layout Standard
\begin_inset Wrap table
lines 7
placement O
overhang 0in
width "50col%"
status collapsed

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="2" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
RPROP
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
RPROP2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
QN
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
53.5s
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
42.83
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
12.7s
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:Mittlere-Trainingszeit-für"

\end_inset

Mittlere Trainingszeit für alle durchgeführten Trainings.
\end_layout

\end_inset


\end_layout

\end_inset

Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Ergebnisse-des-Testfalls."

\end_inset

 zeigt die Ergebnisse der 3 verschiedenen Testfälle.
 Aufgetragen ist jeweils der Wert des Likelihood-Terms, die Trainingszeit
 und der Testfehler.
 Nach 5 Iterationen startet die Initialisierung aus Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:UltraRestart"

\end_inset

, da ab diesem Zeitpunkt genügend alte Kriging-Modelle vorhanden sind.
 Dieser Übergang wird mit einer gestrichelten Linie gekennzeichnet.
 
\end_layout

\begin_layout Standard
\begin_inset Wrap figure
lines 40
placement O
overhang 0in
width "45col%"
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../images/SoftwareTechnUmsetzung/RandomRestartVergleich.eps
	scale 60

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Ergebnisse-des-Testfalls."

\end_inset

Ergebnisse des Testfalls.
 Dargestellt sind die Ergebnisse des Likelihoods, der Trainingszeit und
 des Testfehlers über den Trainingsiterationen.
\end_layout

\end_inset


\end_layout

\end_inset

Der Testfehler ist bei allen Verfahren auf einem ähnlich gutem Niveau (der
 Mittelwert des Massenstroms liegt bei 514 kg/s).
 Das RPROP2 Verfahren zeigt insgesamt den besten Testfehler.
 Das Quasi-Newton Verfahren zeigt bei Iteration 4 einen starken kurzfristigen
 Anstieg des Testfehlers.
 Bei diesem Training wurde der Skalierungsfaktor 
\begin_inset Formula $a$
\end_inset

 (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:COKrigingKovarianzmodell"

\end_inset

) falsch eingeschätzt und die Ergebnisse dadurch verzerrt.
 Der genaue Trainingsverlauf (hier nicht dargestellt) lässt auf ein lokales
 Minimum in der Likelihood Funktion schließen.
 Zu diesem Zeitpunkt war noch die zufällige Initialsierung aktiviert.
 Nachdem die 
\begin_inset Quotes gld
\end_inset

Initialsierung auf Basis vorhandener Kriging Modelle
\begin_inset Quotes grd
\end_inset

 aktiviert wurde, blieb der Testfehler bei allen Verfahren nahezu konstant.
 Der Anstieg des Testfehlers beim Quasi-Newton Verfahren lässt deshalb auf
 eine schlechte Initialsierung als Ursache schließen.
\end_layout

\begin_layout Standard
Die Verläufe des Likelihood-Terms ähneln sich bei den RPROP Verfahren sehr
 stark, beide Verfahren finden bereits in der Phase zufälliger Initialisierung
 direkt den optimalen Likelihood-Term.
 Das Quasi-Newton Verfahren ist in dieser Phase noch sehr instabil.
 
\end_layout

\begin_layout Standard
Die Trainingszeiten zwischen den Verfahren variieren in der 
\begin_inset Quotes gld
\end_inset

zufälligen
\begin_inset Quotes grd
\end_inset

 Phase noch sehr stark, in Tabelle 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Mittlere-Trainingszeit-für"

\end_inset

 werden die mittleren Trainingszeiten aufgelistet.
 Das RPROP2 Verfahren bietet einen Zeitersparnis von ca.
 20% gegenüber dem RPROP Verfahren und das QuasiNewton Verfahren einen Zeiterspa
rnis von ca.
 74% gegenüber dem RPROP Verfahren.
 Nach der 
\begin_inset Quotes gld
\end_inset

zufälligen
\begin_inset Quotes grd
\end_inset

 Phase sind die Trainingszeiten zwischen den Verfahren allerdings nahezu
 identisch.
 
\end_layout

\begin_layout Paragraph*
Fazit
\end_layout

\begin_layout Standard
Dieses Testbeispiel zeigt zum einen die Robustheit der beiden RPROP-Verfahren
 gegenüber dem Quasi-Newton Verfahren und zum anderen den enormen Nutzen
 des in dieser Arbeit entwickelten Intialisierungsverfahrens.
 Das Initialisierungsverfahren verbessert zum einen die Trainingszeit erheblich
 und zum anderen sorgt es auch für ein deutlich besseren Likelihood-Verlauf
 in allen Verfahren.
 
\end_layout

\begin_layout Standard
Aufgrund dieser Ergebnisse wird als Standardverfahren innerhalb der hier
 entwickelten Co-Kriging Software die 
\begin_inset Quotes gld
\end_inset

Initialisierung auf Basis vorhandener Kriging Modelle
\begin_inset Quotes grd
\end_inset

 und das RPROP2 Verfahren gewählt.
 Für den Ordinary- und Gradient-Enhanced-Modus der Kriging-Software wird
 allerdings das RPROP-Verfahren verwendet, da dieses bei einer geringeren
 Anzahl von Hyperparametern zeitlich besser abschneidet.
\end_layout

\begin_layout Section
Umsetzung der Entscheidungsfunktion
\begin_inset CommandInset label
LatexCommand label
name "sec:Umsetzung-der-Entscheidungsfunkt"

\end_inset


\end_layout

\begin_layout Standard
Die Berechnung der in dieser Arbeit entwickelten Entscheidungsfunktion (siehe
 Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Entscheidungsfunktion"

\end_inset

) benötigt die Berechnung einiger Variablen, deren numerische Bestimmung
 von zentraler Bedeutung ist, was die Effizienz und Stabilität des Verfahrens
 angeht.
\end_layout

\begin_layout Standard
Insbesondere ist hierbei die bedingte Varianz 
\begin_inset Formula $\sigma_{g|j}^{2}\left(\vec{x}\right)=\sigma_{g}^{2}\left(\vec{x}\right)\mid y_{j}\left(\vec{x}\right)\in\mathbb{R}$
\end_inset

 (Definition Seite 
\begin_inset CommandInset ref
LatexCommand pageref
reference "BedingteVarianzDefinition"

\end_inset

) und die verschiedenen Zeiten 
\begin_inset Formula $T=\frac{t_{train}+t_{opti}+t_{prh}}{t_{train}+t_{opti}+t_{prl}}$
\end_inset

 von Bedeutung.
 Wie die genaue Berechnung innerhalb der hier entwickelten Software funktioniert
, soll in diesem Abschnitt erläutert werden.
\end_layout

\begin_layout Paragraph*
Bedingten Varianzen
\end_layout

\begin_layout Standard
Eine Möglichkeit die bedingten Varianzen abzuschätzen ist es, Vorhersagen
 niedriger Güte mit dem Ersatzmodell zu treffen und mit diesen Vorhersagen
 das Ersatzmodell neu zu trainieren und wieder neue Vorhersagen zu treffen.
 Diese Vorgehensweise ist softwaretechnisch allerdings sehr aufwendig und
 fehleranfällig.
\end_layout

\begin_layout Standard
Eine einfachere Möglichkeit ist es die Varianz 
\begin_inset Formula $\sigma_{g|j}^{2}\left(\vec{x}\right)$
\end_inset

 mithilfe einer bedingten Normalverteilung zu berechnen.
 Hierfür ist die bedingte Kovarianz 
\begin_inset Formula $\left.cov\left(Z_{g}\left(\vec{x}\right),Z_{j}\left(\vec{x}\right)\right)\right|\vec{y_{s}},\vec{w}$
\end_inset

 (siehe Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:KovarianzPredictor"

\end_inset

) zwischen den verschiedenen Gütestufen 
\begin_inset Formula $g,j$
\end_inset

 an dem Ort 
\begin_inset Formula $\vec{x}\in\mathbb{R}^{k}$
\end_inset

 unter der Bedingung aller bekannten Daten 
\begin_inset Formula $\vec{y_{s}}$
\end_inset

 und Gewichte 
\begin_inset Formula $\vec{w}$
\end_inset

 .
 So gilt für 
\begin_inset Formula $\sigma_{g|j}^{2}\left(\vec{x}\right)$
\end_inset

 bei Annahme einer Multivariaten-Normalverteilung und unter der Kenntnis
 einer Stützstelle 
\begin_inset Formula $y_{j}\left(\vec{x}\right)$
\end_inset

 folgender Zusammenhang:
\begin_inset Formula 
\begin{equation}
\sigma_{g|j}^{2}\left(\vec{x}\right)=\sigma_{g}^{2}\left(\vec{x}\right)-\frac{\left(cov\left(Z_{g}\left(\vec{x}\right),Z_{j}\left(\vec{x}\right)\right)|\vec{w},\vec{y}_{s}\right)^{2}}{\sigma_{j}^{2}\left(\vec{x}\right)}\label{eq:BedingteNormalVertilung}
\end{equation}

\end_inset


\end_layout

\begin_layout Paragraph*
Berechnung der Zeiten
\end_layout

\begin_layout Standard
Grundlegend gibt es für die Entscheidungsfunktion drei verschiedene Zeiten,
 welche berechnet werden müssen.
 
\end_layout

\begin_layout Enumerate
Die Trainingszeit 
\begin_inset Formula $t_{train}$
\end_inset

 
\end_layout

\begin_layout Enumerate
Die Zeit für die Optimierung auf dem Ersatzmodell 
\begin_inset Formula $t_{opti}$
\end_inset


\end_layout

\begin_layout Enumerate
Die Prozesskettenzeit 
\begin_inset Formula $t_{pr}$
\end_inset

, wobei es für jede Gütestufe eine einzelne Zeit gibt.
\end_layout

\begin_layout Standard
Die Zeiten zu bestimmen ist kein großes Problem, da diese innerhalb der
 Optimierung gemessen und gespeichert werden.
 So hat man zumindest die vergangenen Zeiten und kann damit Schätzungen
 anstellen.
 Da diese Zeiten innerhalb der Optimierung sehr stark schwanken können und
 weiterhin einen sehr erheblichen Anteil in der Entscheidungsfunktion besitzen,
 ist es sinnvoll einen Mittelwert aus den vergangenen Zeiten zu bilden.
 Allerdings stellt sich dabei die Frage, wie viele vergangene Zeiten in
 das Mittel aufgenommen werden sollen.
 Hierbei sollte unterschieden werden: 
\end_layout

\begin_layout Standard
Die Prozesskettenzeit 
\begin_inset Formula $t_{pr}$
\end_inset

 ändert sich während einer laufenden Optimierung in der Regel nur unwesentlich,
 da die Prozesskette sich während der Optimierung nicht ändert.
 Bei CFD-Optimierungn ist oftmals eine kleine Reduktion der Prozesskettenzeit
 zum Ende einer Optimierung zu beobachten, da die Member sich dem Optimum
 nähern und somit schneller konvergieren.
 Allerdings ist dies nicht immer der Fall und die zeitliche Differenz nicht
 ausschlaggebend.
 Aus diesem Grund wird in der hier entwickelten Software, das Mittel aus
 allen bereits gemessenen Prozesskettenzeiten 
\begin_inset Formula $t_{pr,i},i\in\{1,...,n\}$
\end_inset

, wobei 
\begin_inset Formula $n$
\end_inset

 die Anzahl aller bisher berechneten Member der betrachteten Gütestufe angibt.
 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
t_{pr}=\frac{1}{n}\stackrel[i=1]{i\leq n}{\sum}t_{pr,i}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Die Trainingszeit 
\begin_inset Formula $t_{train}$
\end_inset

, sowie die Zeit für die Optimierung auf dem Ersatzmodell 
\begin_inset Formula $t_{opti}$
\end_inset

 ändern sich im Verlauf der Optimierung stetig.
 Typischerweise wachsen diese mit steigender Stützstellenanzahl an.
 Verwendet man bswp.
 eine Restart Methode wie die in dieser Arbeit entwickelte (siehe Kapitel
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:UltraRestart"

\end_inset

), dann kann die Trainingszeit schlagartig fallen.
 Aufgrund dieser starken zeitlichen Schwankungen ist es sinnvoller, für
 den Mittelwert der Zeit nur eine kleine Anzahl 
\begin_inset Formula $m$
\end_inset

 an bereits gemessenen Zeiten zu verwenden: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
t_{train} & =\frac{1}{m}\stackrel[i=1]{i\leq m}{\sum}t_{train,(n-i)}\\
t_{opti} & =\frac{1}{m}\stackrel[i=1]{i\leq m}{\sum}t_{opti,(n-i)}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Standardeinstellung in der hier entwickelten Software ist eine Anzahl von
 
\begin_inset Formula $m=15$
\end_inset

, diese hat sich für die meisten Anwendungen als günstig erwiesen.
 
\end_layout

\begin_layout Paragraph*
Minimale Menge an Membern hoher Güte 
\begin_inset CommandInset label
LatexCommand label
name "par:Minimale-Menge-an"

\end_inset


\end_layout

\begin_layout Standard
Es kann vorkommen, dass die HF und LF Funktionen so stark korreliert sind,
 dass die Entscheidungsunktion sich nur noch für die Prozessketten niedriger
 Güte entscheidet.
 Grundlegend ist dieses Verhalten auch sinnvoll und erwünscht.
 Jedoch interessiert den Anwender letztendlich das Ergebnis hoher Güte.
 Aus diesem Grund wird der Volume-Gain-Term im Raum hoher Güte berechnet.
 Um es kurz zu beschreiben: 
\shape italic
Mit einem Member niedriger Güte kann kein Volumenzugewinn erreicht werden,
 es wird nur das Ersatzmodell verbessert.
 
\end_layout

\begin_layout Standard
Aus diesem Grund ist es sinnvoll eine Mindestrate von Membern hoher Güte
 vorzugeben.
 In der hier entwickelten Software wird dafür ein prozentualer Anteil hoher
 Güte (HFProzent Soll) vorgegeben.
 Wird dieser Anteil unterschritten, so soll ein Member hoher Güte erzwungen
 werden.
 Um die Entscheidungsfunktion aber nicht vollständig zu umgehen, soll bei
 besonders aussichtsreichen Membern weiterhin möglich sein, einen Member
 niedriger Güte zu berechnen.
 
\end_layout

\begin_layout Standard
Die Grundidee ist es, die Grenze für das Entscheidungskriterium (KriteriumGrenze
) auf einen höheren Wert zu setzen und damit die Wahrscheinlichkeit für
 die Wahl eines Members hoher Güte zu erhöhen.
 Dafür werden als erstes die aktuellen Anteile hoher Güte bestimmt (HFProzentIst
) und dann das Maximum der letzten 10 berechneten Entscheidungskriterien
 (Kriterium10Max) bestimmt.
 Die neue Grenze für das Kriterium wird dann so entschieden:
\end_layout

\begin_layout Itemize
Ist die Differenz zwischen Soll und Ist HF Prozentsatz größer als 0% aber
 kleiner als 5% 
\end_layout

\begin_deeper
\begin_layout Itemize
Setze das Kriterium auf das Maximum der letzten 10.
 Die Wahrscheinlichkeit für einen HF Member ist also sehr hoch, bekommt
 das Entscheidungskriterium aber einen Member welcher einen höheren Wert
 als die letzten 10 hatte, so kann trotzdem nochmal ein LF Member erzeugt
 werden.
 Die soll verhindern, dass besonders gute LF Member verworfen werden.
\end_layout

\end_deeper
\begin_layout Itemize
Ist die Differenz zwischen Soll und Ist HF Prozentsatz größer als 5% 
\end_layout

\begin_deeper
\begin_layout Itemize
Erzwinge einen HF Member
\end_layout

\end_deeper
\begin_layout Standard
Dieser Algorithmus sorgt im Normalfall für eine gleichmäßige Berechnung
 von Membern hoher Güte.
 Bei einem besonders aussichtsreichen Member niedriger Güte, kann dieser
 aber noch vorgezogen werden.
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "numbers=left,basicstyle={\scriptsize},showstringspaces=false,tabsize=4"
inline false
status open

\begin_layout Plain Layout

HFProzentSoll      = holeUserInput()
\end_layout

\begin_layout Plain Layout

HFProzentIst       = holeAktuellenHFAnteilInProzent()
\end_layout

\begin_layout Plain Layout

Kriterium10        = holeLetze10EntscheidungsKriterien()
\end_layout

\begin_layout Plain Layout

Kriterium10Max     = Maximum(Kriterium10)
\end_layout

\begin_layout Plain Layout

KriteriumAktuell   = Entscheidungsfunktion()
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

KriteriumGrenze = Kriterium10Max
\end_layout

\begin_layout Plain Layout

Wenn  (HFProzentIst > HFProzentSoll) oder (Kriterium10Max < 1.0) 
\end_layout

\begin_layout Plain Layout

	KriteriumGrenze = 1.0
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

Wenn (HFProzentSoll-HFProzentIst>0.05)
\end_layout

\begin_layout Plain Layout

	KriteriumGrenze = inf	
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Umschalten auf HF bei einem sehr guten Ersatzmodell
\begin_inset CommandInset label
LatexCommand label
name "par:Umschalten-auf-HF"

\end_inset


\end_layout

\begin_layout Standard
Die Vorhersagefehler der Ersatzmodelle gehen bei ausreichender Anzahl an
 Stützstellen nahezu gegen 0.
 Dieser Zustand kann für einzelne Ersatzmodelle vorkommen, wenn eine sehr
 hohe Anzahl an Stützstellen erreicht wurde oder wenn die zu lernende Funktion
 besonders einfach ist.
 Trifft zusätzlich der Umstand ein, dass die Korrelation zwischen hoher
 und niedriger Güte extrem hoch ist, so könnte es passieren, dass die Entscheidu
ngsfunktion sich zu oft für die Prozesskette niedriger Güte entscheidet.
 
\end_layout

\begin_layout Standard
Um die Problematik zu verdeutlichen soll ein Gedankenexperiment helfen:
 Angenommen es soll eine Funktion optimiert werden, welche von dem Ersatzmodell
 bereits nach der Initialisierungsphase perfekt gelernt wurde.
 Zusätzlich sind die niedrige und hohe Gütestufe nahezu vollständig korreliert,
 die niedriger Gütestufen ist aber deutlich schneller.
 Der Optimierungsalgorithmus wäre also in der Lage, das Optimum sofort finden
 zu können.
 Typischerweise möchte der Anwender aber das hochwertigste Ergebnis, da
 dieses das Vertrauenswürdigste darstellt.
 Die Entscheidungsfunktion sollte also bei ausreichender Genauigkeit eher
 zu Entscheidungen hoher Güte tendieren.
\end_layout

\begin_layout Standard
Um ein solches Verhalten automatisiert zu verwirklichen wird vor dem eigentliche
n Aufruf der Entscheidungsfunktion der Quotient aus vorhersagter Standardabweich
ung 
\begin_inset Formula $\sigma_{h}\left(\vec{x}\right)$
\end_inset

 und der globalen Standardabweichung aller bekannten Stützstellen 
\begin_inset Formula $\sigma_{h,all}$
\end_inset

 ins Verhältnis gesetzt: 
\begin_inset Formula $\frac{\sigma_{h}\left(\vec{x}\right)}{\sigma_{h,all}}$
\end_inset

 
\end_layout

\begin_layout Standard
Für diesen Fall wurde die Standardabweichung gegenüber der Varianz bevorzugt,
 da diese in der Größenordnung der Funktion selbst liegt und somit für den
 Anwender einfacher zu interpretieren ist.
\end_layout

\begin_layout Standard
Der Anwender hat nun die Möglichkeit eine Grenze für dieses Verhältnis anzugeben.
 Wird diese Unterschritten, so wird diese Funktion nicht für die Entscheidung
 berücksichtigt und erhöht somit nicht den Wert des Entscheidungskriteriums.
 Werden dadurch bspw.
 alle Funktionen nicht berücksichtigt, so würde das Kriterium Null werden
 und sich zugunsten der hochwertigeren Prozesskette entscheiden.
\end_layout

\begin_layout Standard
Typische Werte sind 1%, allerdings ist dieser Wert sehr Anwendungs- und
 Anwender-spezifisch.
 Der Anwender hat so auch die Möglichkeit die Optimierung frühzeitig in
 Richtung hoher Güte zu bringen, indem er diesen Wert erhöht.
 
\end_layout

\begin_layout Section
Softwaretechnische Umsetzung 
\begin_inset CommandInset label
LatexCommand label
name "sec:Numerische-Effizienz-steigern"

\end_inset


\end_layout

\begin_layout Standard
Innerhalb dieses Abschnittes sollen die wichtigsten softwaretechnischen
 Entwicklungen, welche im Rahmen dieser Arbeit entstanden sind, vorgestellt
 werden.
 Hierzu zählen z.B.
 der Modulare Aufbau der Software, der es ermöglicht verschiedene Verfahren
 wie Supporting-Vector-Machines und alle Kriging-Verfahren innerhalb einer
 Software unterzubringen und so Redundanzen zu vermeiden.
 
\end_layout

\begin_layout Standard
Weiterhin wurden zahlreiche Anstrengungen unternommen um die Software möglichst
 effizient zu gestalten.
 Hierzu zählt eine eigene Matrix-Klasse, welche zahlreiche Architekturen
 abdeckt wie z.B.
 GPUs, Intel MKL Bibkiotheken und OpenMP mit AVX/SSE Beschleunigung.
 Dadurch ist es möglich, die Software sehr flexibel auf unterschiedlichen
 Systemen einzusetzen und die vorhandene Prozessorarchitektur effizient
 zu nutzen.
 Weiterhin wurde eine Netzwerkbibliothek entwickelt, welche es ermöglicht
 zahlreiche numerische Operationen asynchron auf mehrere Rechner zu verteilen,
 unabhängig von der Architektur.
 Das System ist zudem stark ausfallsicher: Fällt ein Server aus, übernimmt
 ein anderer dessen Aufgaben.
 
\end_layout

\begin_layout Standard
Neben diesen beschriebenen Maßnahmen werden noch einige andere Entwicklungen
 beschrieben, die den Einsatz der Kriging-Software für den Bereich des Turbomasc
hinendesigns im industriellen Umfeld effizient nutzbar macht.
 
\end_layout

\begin_layout Subsection
Softwarearchitektur und Laufzeitumgebung
\begin_inset CommandInset label
LatexCommand label
name "subsec:Softwarearchitektur-und-Laufzeit"

\end_inset


\end_layout

\begin_layout Standard
Zahlreiche in der Literatur vorgestellten Ansätze (siehe 
\begin_inset CommandInset citation
LatexCommand cite
key "LeGratiet,forrester2007multi"

\end_inset

) sind oftmals in Matlab oder ähnlichen Umgebungen umgesetzt, dadurch entstehen
 oftmals Schwächen in der Performance und insbesondere der Benutzerfreundlichkei
t.
 Das hier entwickelte Verfahren ist objektorientiert, verwendet moderne
 Interface basierte Programmierung Dies ermöglicht eine sehr große Flexibilität
 und Modularität in der Software, was bereits an den zahlreichen integrierten
 Verfahren und nutzbaren Architekturen zu sehen ist.
 Die gewählte Programmiersprache ist C++, wobei der GCC-Compiler ab Version
 4.7 unterstützt wird.
 Eine Kompilierung mit dem Intel Compiler ist ebenfalls ab Version 12.1 möglich.
 Weiterhin werden die Messaging-Middleware-ZeroMQ und die Boost Bibliothek
 Version 1.62 benötigt.
 
\end_layout

\begin_layout Standard
Im folgenden sollen die wichtigsten Klassen benannt und kurz beschrieben
 werden.
 
\end_layout

\begin_layout Paragraph*
Point
\end_layout

\begin_layout Standard
Die Klasse 
\begin_inset Quotes gld
\end_inset

Point
\begin_inset Quotes grd
\end_inset

 (siehe Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Klassenstruktur-der-Klasse"

\end_inset

) beschreibt eine Stützstelle innerhalb des Kriging-Verfahrens.
 Ein Objekt dieser Klasse beinhaltet alle Parameter, Funktionswerte und
 ggf.
 partielle Ableitungen (Gradient-Enhanced-Kriging).
 Die partiellen Ableitungen werden als assoziatives Datenfeld gespeichert,
 um die Zuordnung zu den Parametern zu gewährleisten und um unvollständige
 Daten zuzulassen.
 Der Zugriff auf Variablen, Funktionswerte und partielle Ableitungen erfolgt
 über entsprechende 
\begin_inset Quotes gld
\end_inset

Getter
\begin_inset Quotes grd
\end_inset

 und 
\begin_inset Quotes gld
\end_inset

Setter
\begin_inset Quotes grd
\end_inset

 Methoden.
 Zudem implementiert die Klasse das Interface 
\begin_inset Quotes gld
\end_inset

SaveableOnServer
\begin_inset Quotes grd
\end_inset

.
 Objekte dieser Klasse können somit über das Netzwerk verteilt werden.
 In Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Verteiltes-Rechnen-1"

\end_inset

 wird dieser Punkt noch genauer erklärt.
\end_layout

\begin_layout Paragraph*
CorrelationFunction
\begin_inset CommandInset label
LatexCommand label
name "par:CorrelationFunction"

\end_inset


\end_layout

\begin_layout Standard
Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Klassenstruktur-der-Kovarianzfun"

\end_inset

 zeigt die Generalisierungsklasse 
\begin_inset Quotes gld
\end_inset

CorrelationFunction
\begin_inset Quotes grd
\end_inset

 und deren Spezialisierungen.
 Die Klasse 
\begin_inset Quotes gld
\end_inset

CorrelationFunction
\begin_inset Quotes grd
\end_inset

 legt den Aufbau der Kovarianzklassen fest und in den Spezialisierungen
 sind die Implementierungen der einzelnen Kovariansfunktionen.
 Im Rahmen dieser Arbeit wurden die 
\begin_inset Quotes gld
\end_inset

Gauss
\begin_inset Quotes grd
\end_inset

, 
\begin_inset Quotes gld
\end_inset

Spline
\begin_inset Quotes grd
\end_inset

 und 
\begin_inset Quotes gld
\end_inset

Exponential
\begin_inset Quotes grd
\end_inset

 Kovarianzfunktionen umgesetzt.
 Die Gleichungen der Funktionen und auch deren Ableitungen nach Hyperparametern
 und Ort sind in Anhang 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Kubische-Spline-Korrelationsfunk"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Exponential-Korrelationsfunktion"

\end_inset

,
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Gauss-Korrelationsfunktion-mit"

\end_inset

 zu finden.
 Der Name 
\begin_inset Quotes gld
\end_inset

CorrelationFunction
\begin_inset Quotes grd
\end_inset

 mag hier etwas verwirrend sein, da es sich eigentlich um Kovarianzfunktionen
 handelt.
 Diese ungünstige Namensgebung ist historisch entstanden und kann nur mit
 großem Aufwand geändert werden, aus diesem Grund wurde bisher darauf verzichtet.
 
\end_layout

\begin_layout Standard
Für ein Co-Kriging gibt es die Spezialisierung 
\begin_inset Quotes gld
\end_inset

CorrelationFunctionLinearCombination
\begin_inset Quotes grd
\end_inset

, die Funktionsweise dieser Kovarianzfunktion soll hier kurz erläutert werden:
 Um die Kovarianzmatrix für das hier beschriebene Co-Kriging-Modell aufzustellen
, werden drei Kovarianzfunktionen benötigt.
 Diese können wiederum über zwei Kovarianzmodellfunktionen 
\begin_inset Formula $cov_{2}\left(\vec{h}\right),cov_{diff}\left(\vec{h}\right)$
\end_inset

 und einer Skalierung 
\begin_inset Formula $a$
\end_inset

 abgebildet werden: 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $cov_{1,1}\left(\vec{x}_{1},\vec{x}_{2}\right)=a^{2}cov_{2}\left(\vec{h}\right)+cov_{diff}\left(\vec{h}\right)$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $cov_{1,2}\left(\vec{x}_{1},\vec{x}_{2}\right)=acov_{2}\left(\vec{h}\right)$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $cov_{2,2}\left(\vec{x}_{1},\vec{x}_{2}\right)=cov_{2}\left(\vec{h}\right)$
\end_inset


\end_layout

\begin_layout Standard
Innerhalb des Programms werden also nur zwei Kovarianzmodellfunktionen mit
 eigenen Hyperparametersätze benötigt, die dritte 
\begin_inset Formula $cov_{1,1}\left(\vec{x}_{1},\vec{x}_{2}\right)$
\end_inset

 wird über eine Summe abgebildet.
 Konkret bedeutet dies, dass zwei Instanzen einer Kovarianzfunktion 
\begin_inset Quotes gld
\end_inset

CorrelationFunctionGauss
\begin_inset Quotes grd
\end_inset

 oder 
\begin_inset Quotes gld
\end_inset

CorrelationFunctionSpline
\begin_inset Quotes grd
\end_inset

 erzeugt werden müssen.
 Die Kovarianzfunktion 
\begin_inset Formula $cov_{1,1}\left(\vec{x}_{1},\vec{x}_{2}\right)$
\end_inset

 wird dann über die 
\begin_inset Quotes gld
\end_inset

CorrelationFunctionLinearCombination
\begin_inset Quotes grd
\end_inset

 abgebildet, indem diese die Referenzen auf die beiden bereits vorhandenen
 Kovarianzfunktionen erhält.
 Die Steuerung und Instantiierung der Objekte wird von der Klasse 
\begin_inset Quotes gld
\end_inset

CorrelationContainer
\begin_inset Quotes grd
\end_inset

 übernommen, welche im folgenden noch erläutert wird.
 
\end_layout

\begin_layout Standard
Weiterhin sind die Methoden getAllCov und getAllCovPartialDerTheta beschrieben.
 Diese berechnen die eigentliche Kovarianzfunktion zwischen zwei Punkten
 
\begin_inset Quotes gld
\end_inset

point1
\begin_inset Quotes grd
\end_inset

 und 
\begin_inset Quotes gld
\end_inset

point2
\begin_inset Quotes grd
\end_inset

 und deren partielle Ableitung nach einem Hyperparameter 
\begin_inset Quotes gld
\end_inset

partialDerNumber
\begin_inset Quotes grd
\end_inset

.
 Die Ergebnisse werden von den Methoden in die Matrix 
\begin_inset Quotes gld
\end_inset

CovMat
\begin_inset Quotes grd
\end_inset

 und 
\begin_inset Quotes gld
\end_inset

CovMatrixDer
\begin_inset Quotes grd
\end_inset

 geschrieben, welche jeweils als Referenz übergeben werden.
 Im Falle eine Gradient-Enhanced-Krigings werden die benötigten Kovarianzfunktio
nen der vorgegebenen partiellen Ableitungen direkt mit bestimmt und ebenfalls
 in die Matrix geschrieben.
 Die Position der jeweiligen Einträge in der Matrix wird in einer internen
 Map gespeichert, welche zu Anfang des Programms erzeugt wird und den Objekten
 bekannt ist.
 Auf diese Weise übergibt man der Kovarianzfunktion nur zwei Objekte der
 Point Klasse und die Kovarianzfunktion schreibt die korrekten Ergebnisse
 direkt an die korrekte Stelle der entsprechenden Matrix.
 Weiterhin wird in Abschnitt 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:SoftwaretechnKorrelationsfunktionen"

\end_inset

 gezeigt, wie die Berechnung der Kovarianzfunktion mit SIMD-Instruktionen
 beschleunigt werden kann.
 
\end_layout

\begin_layout Paragraph*
CorrelationContainer - Behälter und Kontrolle für die benötigten Korrelationsfun
ktionen
\end_layout

\begin_layout Standard
Die Klasse CorrelationContainer beinhaltet und steuert alle Instanzen der
 verwendeten Kovarianzfunktionen.
 Bei der Initialisierung des Kriging-Modells erzeugt diese Klasse alle nötigen
 Kovarianzfunktionen und setzt im Falle des Multifidelity-Verfahrens die
 entsprechenden Referenzen (siehe 
\begin_inset CommandInset ref
LatexCommand ref
reference "par:CorrelationFunction"

\end_inset

 
\begin_inset Quotes gld
\end_inset

CorrelationFunction
\begin_inset Quotes grd
\end_inset

).
 Alle weiteren Zugriffe auf die Kovarianzfunktionen erfolgen immer über
 ein Objekt dieser Klasse und niemals direkt.
 Weiterhin wird die Zuordnung der Kovarianzobjekte auf entsprechende Gütestufenp
aare von dieser Klasse übernommen.
 Dies bedeutet konkret, dass das Aufstellen der Kovarianzmatrizen immer
 mit Hilfe des CorrelationContainer erfolgt und niemals direkt über die
 Kovarianzfunktionen selbst.
 Da die Kovarianzfunktionen an sehr vielen Stellen im Programm aufgerufen
 werden, kann durch diese Zentralisierung die Fehleranfälligkeit des Programms
 deutlich reduziert werden.
\end_layout

\begin_layout Standard
Neben der Steuerung der Kovarianzfunktionen übernimmt diese Klasse auch
 die Steuerung der Hyperparameter.
 Innerhalb des Programms werden die Hyperparameter in mehrere Gruppen aufgeteilt
 und in unterschiedlichen Objekten gespeichert.
 Dies kommt durch die unterschiedliche Natur der Hyperparameter zustande.
 Beispielsweise kann der Skalierungsfaktor 
\begin_inset Formula $a$
\end_inset

 nicht direkt einer Kovarianzmodellfunktion zugeordnet werden, da er von
 mehreren Kovarianzmodellfunktionen verwendet wird und sollte aus diesem
 Grund in einer übergeordneten Instanz verwaltet werden.
 Diese übergeordnete Instanz ist der CorrelationContainer.
 Ebenfalls stellen die Diagonalaufschläge eine Besonderheit dar und werden
 aus diesem Grund ebenfalls dort zentral verwaltet.
 
\end_layout

\begin_layout Standard
Eine weitere Aufgabe ist die zentrale Speicherung der Positions-Tabelle,
 diese ordnet einem Paar der Klasse 
\begin_inset Quotes gld
\end_inset

Point
\begin_inset Quotes grd
\end_inset

 eine Position in der Kovarianzmatrix und deren Ableitungen zu.
 
\end_layout

\begin_layout Paragraph*
DensityFunction - Implementierung unterschiedlicher Verfahren in einem Softwarep
aket 
\begin_inset CommandInset label
LatexCommand label
name "par:DensityFunction---Implementierun"

\end_inset


\end_layout

\begin_layout Standard
Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Vereinfachtes-UML-Diagramm"

\end_inset

 zeigt die abstrakte Klasse 
\begin_inset Quotes gld
\end_inset

DensityFunction
\begin_inset Quotes grd
\end_inset

 und deren Spezialisierungen an.
 Diese Klassenstruktur soll es ermöglichen unterschiedlichste Interpolations/Kla
ssifikations-Verfahren innerhalb des Programms umsetzen zu können.
 Prinzipiell lassen sich mit dieser Klassenstruktur alle Arten von Verfahren
 einbinden, die folgende Merkmale aufweisen:
\end_layout

\begin_layout Itemize
Abstands- oder Kovarianzmatrix mit Ableitungen
\end_layout

\begin_layout Itemize
Verwendung einer Abstandsfunktion in Form der Klasse 
\begin_inset Quotes gld
\end_inset

CorrelationFunction
\begin_inset Quotes grd
\end_inset

, siehe Abschnitt 
\begin_inset CommandInset ref
LatexCommand ref
reference "par:CorrelationFunction"

\end_inset

 
\end_layout

\begin_deeper
\begin_layout Itemize
Hyperparameter welche die Kovarianzmatrix beeinflussen
\end_layout

\end_deeper
\begin_layout Itemize
Bewertungsfunktion des aktuellen Hyperparametersatzes, z.B.
 Likelihood mit Ableitungen nach den Hyperparametern
\end_layout

\begin_layout Standard
Sofern diese Merkmale vorhanden sind, kann eine neue Spezialisierung der
 Klasse 
\begin_inset Quotes gld
\end_inset

DensityFunction
\begin_inset Quotes grd
\end_inset

 erzeugt werden.
 Die Bewertungsfunktion soll mit der Methode 
\begin_inset Quotes gld
\end_inset

calcDensity
\begin_inset Quotes grd
\end_inset

 umgesetzt werden und einen Fließkommawert zurückgeben, welcher die Qualität
 des aktuellen Modells zurück gibt.
 Wobei hier kleinere Werte als besser angesehen werden.
 Die Methode 
\begin_inset Quotes gld
\end_inset

calcDensityDerivative
\begin_inset Quotes grd
\end_inset

 gibt alle Ableitungen der Bewertungsfunktion nach allen Hyperparametern
 in Form einer Matrix zurück.
 Die Matrix hat in der Regel nur eine Dimension eines Vektors.
 Die Methode createAndInvertCovMat soll die Kovarianzmatrix erzeugen und
 eine notwendige Invertierung oder Zerlegung vornehmen.
 Bisher implementierte Spezialisierungen sind:
\end_layout

\begin_layout Itemize
ReducedNormalDistribution: Likelihood Funktion für alle Kriging-Verfahren
 
\end_layout

\begin_layout Itemize
SVMDistribution: Eine Implementierung des Klassifikators 
\begin_inset Quotes gld
\end_inset

Supporting Vector Machines
\begin_inset Quotes grd
\end_inset

.
 Diese wurden im Rahmen einer studentischen Bachelorarbeit implementiert,
 weitere Informationen sind in 
\begin_inset CommandInset citation
LatexCommand cite
key "schu2014"

\end_inset

 zu finden.
\end_layout

\begin_layout Itemize
CorrelationClassificator: Einfacher Klassifikator auf Basis von Korrelationsfunk
tionen.
 Zu diesem Verfahren existieren bis zum jetzigen Zeitpunkt noch keine Veröffentl
ichungen.
\end_layout

\begin_layout Standard
Die Verfahren 
\begin_inset Quotes gld
\end_inset

SVMDistribution
\begin_inset Quotes grd
\end_inset

 und 
\begin_inset Quotes gld
\end_inset

CorrelationClassificator
\begin_inset Quotes grd
\end_inset

 sollen hier nicht weiter thematisiert werden, da sie nicht Teil dieser
 Arbeit waren.
 Dennoch soll damit gezeigt werden, dass die hier etablierte Klassenstruktur
 es mit wenig Aufwand ermöglicht zahlreiche Verfahren zu implementieren.
 Zumindest wenn eine gewisse Ähnlichkeit zum Kriging-Verfahren vorhanden
 ist.
\end_layout

\begin_layout Paragraph*
AutoOpti Schnittstelle
\end_layout

\begin_layout Standard
Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Vereinfachtes-UML-Diagramm-1"

\end_inset

 zeigt den Aufbau der Schnittstelle zwischen AutoOpti und externen Ersatzmodelle
n.
 Die Klasse MetaModel in innerhalb des Programms 
\begin_inset Quotes gld
\end_inset

AutoOpti
\begin_inset Quotes grd
\end_inset

 (hier als Package dargestellt) definiert und ermöglicht über die Methodendefini
tion eine Anbindung an das Verfahren.
 Um die Anbindung vornehmen zu können, sind allerdings detaillierte Kenntnisse
 über die Funktionsweise von AutoOpti nötig, da der Austausch von Informationen
 über die 
\begin_inset Quotes gld
\end_inset

Member
\begin_inset Quotes grd
\end_inset

 Struktur erfolgt.
 Diese Struktur beinhaltet zahlreiche verschachtelte Informationen, welche
 innerhalb der Schnittstellenimplementationen bekannt sein müssen.
 Weiterhin folgt diese Struktur einem älteren C-Standard, welcher eine Übersetzu
ng der Speicherverwaltung ins modernere C++ notwendig macht.
 Bei den Klassen 
\begin_inset Quotes gld
\end_inset

KrigingInterface
\begin_inset Quotes grd
\end_inset

 und 
\begin_inset Quotes gld
\end_inset

NNInterface
\begin_inset Quotes grd
\end_inset

 bezieht sich das Wort Interface in diesem Fall auf die Schnittstelle zwischen
 den verschiedenen Programmen und ist nicht, wie im sonst üblich, im Sinne
 einer objektorientierten Interface Programmierung gemeint.
 Das Kriging-Interface stellt hier auch die Schnittstellen zwischen den
 Programmiersprachen C und C++ dar, da AutoOpti in C geschrieben wurde und
 das gesamte Kriging in C++.
 Es finden dort zahlreiche Übersetzungen von C-Strukturen in C++-Objekte
 usw.
 statt.
 Die exakte Funktionsweise stellt allerdings keinen Mehrwert für diese Arbeit
 dar und soll daher nicht weiter beschrieben werden.
 
\end_layout

\begin_layout Standard
Über diese Schnittstelle sind das hier beschrieben Kriging-Verfahren angebunden
 und eine DLR-Neuronale-Netzwerk Entwicklung.
 
\end_layout

\begin_layout Paragraph*
Minimierungsverfahren
\end_layout

\begin_layout Standard
Die abstrakte Klasse 
\begin_inset Quotes gld
\end_inset

MinimizerInterface
\begin_inset Quotes grd
\end_inset

 beschreibt die Schnittstelle für ein Minimierungsverfahren.
 Fünf Minimierungsverfahren implementieren diese Schnittstelle.
 Die gesamte Struktur wird in dem UML-Diagramm in Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:UML-Diagramm-der-Klasse"

\end_inset

 beschrieben.
 Die Spezialisierungen 
\begin_inset Quotes gld
\end_inset

MinimizerRandom
\begin_inset Quotes grd
\end_inset

 und 
\begin_inset Quotes gld
\end_inset

MinimizerRandom2
\begin_inset Quotes grd
\end_inset

 werden in Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Initialisierung-der-Hyperparamet"

\end_inset

 beschrieben, wobei es sich dabei um zufällige Initialisierungsverfahren
 handelt.
 Die Software macht allerdings keinen Unterschied zwischen einem Trainings-
 und Initialisierungsverfahren, beide Verfahren wären also auch als Trainingsver
fahren zulässig und umgekehrt.
 Die Spezialisierungen 
\begin_inset Quotes gld
\end_inset

MinimizerRPROP
\begin_inset Quotes grd
\end_inset

, 
\begin_inset Quotes gld
\end_inset

MinimizerRPROP2
\begin_inset Quotes grd
\end_inset

 und 
\begin_inset Quotes gld
\end_inset

MinimizerQN
\begin_inset Quotes grd
\end_inset

 stellen die Trainingsverfahren aus Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Minimierungsverfahren"

\end_inset

 dar.
 Die Schnittstelle 
\begin_inset Quotes gld
\end_inset

MinimizerInterface
\begin_inset Quotes grd
\end_inset

 schreibt zwei 
\begin_inset Quotes gld
\end_inset

public
\begin_inset Quotes grd
\end_inset

 Methoden vor: 
\end_layout

\begin_layout Itemize
callMinimizer: Mit diesem Aufruf wird das Verfahren gestartet und das Minimum
 gesucht.
\end_layout

\begin_layout Itemize
MinimizerInterface (Konstruktor): Diesem Konstruktor muss Objekt vom Typ
 
\begin_inset Quotes gld
\end_inset

DensityFunction
\begin_inset Quotes grd
\end_inset

 übergeben werden, womit dann das gesamte Minimierungsproblem beschrieben
 ist (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "par:DensityFunction---Implementierun"

\end_inset

 - 
\begin_inset Quotes gld
\end_inset

DensityFunction
\begin_inset Quotes grd
\end_inset

).
 Innerhalb des Objekts vom Typ 
\begin_inset Quotes gld
\end_inset

DensityFunction
\begin_inset Quotes grd
\end_inset

 werden dann die Methoden 
\begin_inset Quotes gld
\end_inset

calcDensity
\begin_inset Quotes grd
\end_inset

 und 
\begin_inset Quotes gld
\end_inset

calcDensityDerivative
\begin_inset Quotes grd
\end_inset

 verwendet, diese liefern den zu minimierenden Term und dessen Ableitungen.
\end_layout

\begin_layout Standard
Die privaten Methoden implementieren das Minimierungsverfahren selbst und
 werden innerhalb der Methode 
\begin_inset Quotes gld
\end_inset

callMinimizer
\begin_inset Quotes grd
\end_inset

 angesprochen.
 Diese privaten Methoden sprechen dann wiederum die Methoden aus dem übergebeben
en Objekt vom Typ 
\begin_inset Quotes gld
\end_inset

DensityFunction
\begin_inset Quotes grd
\end_inset

 an.
 
\end_layout

\begin_layout Standard
Beispielsweise die Methode 
\begin_inset Quotes gld
\end_inset

function
\begin_inset Quotes grd
\end_inset

 beschreibt die Auswertung der zu minimierenden Funktion und wird in der
 Methode 
\begin_inset Quotes gld
\end_inset

callMinimizer
\begin_inset Quotes grd
\end_inset

 verwendet.
 Diese wird mit dem aktuellen Hyperparametersatz 
\begin_inset Quotes gld
\end_inset

variables
\begin_inset Quotes grd
\end_inset

 aufgerufen und übergibt diese dann weiter an das Objekt des Typs 
\begin_inset Quotes gld
\end_inset

DensityFunction
\begin_inset Quotes grd
\end_inset

.
 Wurden die Parameter erfolgreich übergeben, wird die Methode 
\begin_inset Quotes gld
\end_inset

calcDensity
\begin_inset Quotes grd
\end_inset

 aufgerufen und der Funktionswert bestimmt.
 Die Methode 
\begin_inset Quotes gld
\end_inset

saveFunction
\begin_inset Quotes grd
\end_inset

 beschreibt das Verhalten des Verfahrens, wenn ein Iterationsschritt nicht
 erfolgreich war.
 Zum Beispiel, wenn die Zerlegung der Matrix nicht funktioniert hat.
 In der Regel wird die Schrittweite halbiert und der letzte Schritt nochmal
 ausgeführt oder der Diagonalaufschlag erhöht.
 Wenn keine dieser Maßnahmen greift, wird das Minimierungsverfahren abgebrochen.
 Die Methode 
\begin_inset Quotes gld
\end_inset

convergenceCheck
\begin_inset Quotes grd
\end_inset

 prüft die Konvergenz des Verfahrens.
 Typischerweise gilt das Verfahren als konvergiert, wenn sich die Funktionswerte
 seit einer bestimmten Anzahl an Iterationen nicht mehr verändert oder verbesser
t haben.
 Die Methode 
\begin_inset Quotes gld
\end_inset

constraintFunction
\begin_inset Quotes grd
\end_inset

 und 
\begin_inset Quotes gld
\end_inset

constraintFunctionDerivative
\begin_inset Quotes grd
\end_inset

 gibt einen Restriktionsterm, bzw.
 dessen Ableitung zurück.
 Diese Methode ist allerdings nur optional, falls diese nicht implementiert
 werden soll, so muss ein konstanter Integer Wert von 0 zurückgeben werden
 womit die Restriktionen dann ignoriert werden.
 Die Methode 
\begin_inset Quotes gld
\end_inset

functions
\begin_inset Quotes grd
\end_inset

 bekommt eine Liste von Variablensätzen und wertet diese dann parallel aus.
 
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
Ein weiterer interessanter Punkt bei dieser Klasse ist die Nutzung von externen
 C-Minimierungs-Bibliotheksfunktionen.
 Beispielsweise wurde das RPROP-Verfahren innerhalb der AutoOpti-Umgebung
 in einer C-Bibliothek angeboten.
 Um Redundanz zu vermeiden und zukünftige Änderungen an diesem Verfahren
 nicht mehrfach machen zu müssen, ist es sinnvoll dieses bereits vorhandene
 Verfahren zu nutzen.
 
\end_layout

\begin_layout Standard
Die Ausführung des C-Minimierungsverfahrens erfolgt in diesem Fall durch
 Aufruf einer Minimierungsfunktion, welche zwei Funktionspointer erwartet.
 Diese Funktionspointer stellen dann die zu minimierende Funktion und deren
 Ableitungen dar.
 Die direkte Nutzung dieser Funktion ist innerhalb des hier beschrieben
 Programms nicht möglich, da die C++ Objektmethoden 
\begin_inset Quotes gld
\end_inset

function
\begin_inset Quotes grd
\end_inset

 und 
\begin_inset Quotes gld
\end_inset

functionDerivative
\begin_inset Quotes grd
\end_inset

 inkompatibel zu den in C verwendeten Funktionspointern sind.
 Insbesondere da die Spezialisierungen von MinimizerInterface ein polymorphes
 Klassenkonstrukt darstellt und für ein C-Programm immer unterschiedlichen
 Typs wäre.
 Eine elegante Lösung für dieses Problem bietet die Bibliothek Boost mit
 der Unterbibliothek 
\begin_inset Quotes gld
\end_inset

function
\begin_inset Quotes grd
\end_inset

.
 Hiermit ist es möglich aus einer Methode eines beliebigen Objekts ein allgemein
es Funktionsobjekt zu machen, welches ebenfalls polymorphe Eigenschaften
 besitzt und somit austauschbar ist.
 In diesem Fall ist es möglich ein Funktionsobjekt zu erzeugen, welche der
 Schnittstelle MinimizerInterface entspricht.
 Damit lassen sich alle Spezialisierungen von 
\begin_inset Quotes gld
\end_inset

MinimizerInterface
\begin_inset Quotes grd
\end_inset

 in der externen Bibliothek elegant nutzen.
 
\end_layout

\begin_layout Subsubsection*
Matrixoperationen
\begin_inset CommandInset label
LatexCommand label
name "subsec:Matrixoperationen"

\end_inset


\end_layout

\begin_layout Standard
Für die Vorhersage (siehe Gleichungen 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Erwartungswert"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Varianz-des-Schätzfehlers"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Kovarianz-zwischen-zwei"

\end_inset

) wie auch für das Training (siehe Gleichungen 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:AbleitungLogLikelihood"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:LogLikelihood"

\end_inset

) eines Kriging-Modells sind viele komplexe Matrixoperationen notwendig.
 Die Laufzeiten von Vorhersage und Training hängen hauptsächlich von diesen
 Matrixoperationen ab.
 Weiterhin werden diese Modelle innerhalb verschiedenster Hardware-Architekturen
 verwendet, bspw.
 AMD/Intel CPUs und NVidia GPUs.
 Für jede dieser Hardwarearchitekturen gibt es verschiedene Hersteller-Bibliothe
ken und damit Implementierungen der benötigten Matrix Operationen.
 Jede dieser Implementierungen ist stark auf die jeweilige Architektur optimiert
 und bringt enorme Geschwindigkeitsvorteile.
 Eine einheitliche Softwareschnittstelle existiert hierfür leider nicht.
 Aus diesem Grund wurde innerhalb dieser Arbeit ein einheitliches polymorphes
 Matrix-Interface und verschiedene Implementierungen entwickelt (siehe Abbildung
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:MatrixKlasseUML"

\end_inset

).
 Die Implementierungen sind also untereinander konvertier- und austauschbar.
 Bislang stehen drei verschiedene Spezialsierungen zur Verfügung, welche
 im folgenden erläutert werden: 
\end_layout

\begin_layout Subparagraph
Matrix 
\end_layout

\begin_layout Standard
Innerhalb der Superklasse 
\begin_inset Quotes gld
\end_inset

Matrix
\begin_inset Quotes grd
\end_inset

 wird hauptsächlich die Speicherverwaltung und Zugriffsmethoden auf eine
 beliebige Matrix Klasse vorgegeben.
 Durch diese einheitliche Speicherverwaltung ist die Austauschbarkeit der
 einzelnen Spezialisierungen erst möglich.
 Diese Klasse ist also keine abstrakte Klasse, sondern vererbt einige Methoden
 und auch Attribute an die Sub-Klassen.
 Die Klasse implementiert auch das Interface 
\shape italic

\begin_inset Quotes gld
\end_inset

SaveableOnServer
\begin_inset Quotes grd
\end_inset

,
\shape default
 wodurch die Matrixklassen über das in Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Verteiltes-Rechnen-1"

\end_inset

 beschriebene Verfahren asynchron und rechnerweit parallelisierbar sind.
 
\end_layout

\begin_layout Standard
\begin_inset Wrap table
lines 0
placement o
overhang 0col%
width "50col%"
status open

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="5">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
n
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
m
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
isSym
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
frei
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Matrix
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
64Bit
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
64Bit
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
64Bit
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
320Bit
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
x Byte
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multicolumn="1" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

$
\backslash
underbrace{
\backslash
qquad
\backslash
qquad
\backslash
qquad
\backslash
qquad
\backslash
qquad
\backslash
qquad
\backslash
qquad}_{512Bit Header}$
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell multicolumn="1" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $x=\begin{cases}
8*m*n & nicht\,symmetrisch\\
4*n*(n-1) & symmetrisch
\end{cases}$
\end_inset

 
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:128Bit-Speicherausrichtung-1"

\end_inset

Interne Speicherstruktur der Matrix Klassen 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Die vollständige Datenstruktur der Klasse Matrix und deren Spezialisierungen
 sind in dem Array 
\begin_inset Quotes gld
\end_inset

elements
\begin_inset Quotes grd
\end_inset

 gespeichert.
 In Tabelle 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:128Bit-Speicherausrichtung-1"

\end_inset

 ist die Struktur ersichtlich.
 Neben den eigentlichen Matrixeinträgen sind hier in den ersten Feldern
 noch zusätzliche Informationen, wie Zeilen-, Spaltenanzahl und ein Symmetriefla
g gespeichert.
 Dies ermöglicht eine einfache Serialisierung der Daten für das Netzwerksystem.
 Zusätzlich sind noch 320Bit freier Speicher verfügbar, dies hat zwei Gründe:
 
\end_layout

\begin_layout Enumerate
Falls noch zusätzliche Informationen über das Netzwerk transportiert werden
 müssen, ist keine Änderung der Speicherstruktur nötig.
\end_layout

\begin_layout Enumerate
Diese 512Bit sind linear im Speicher ausgerichtet, was eine Nutzung von
 SSE/AVX/AVX512 erst möglich macht (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "par:Einschub-Speicherausrichtung"

\end_inset

 
\begin_inset Quotes gld
\end_inset

Speicherausrichtung
\begin_inset Quotes grd
\end_inset

).
 Da die SIMD Routinen nur auf die Daten der Matrix selbst angewendet werden
 sollen, müssen die 
\begin_inset Quotes gld
\end_inset

Header-Daten
\begin_inset Quotes grd
\end_inset

 von den SIMD Routinen übersprungen werden.
 Dies ist nur möglich, wenn die entsprechende lineare Speicherausrichtung
 in Größe der SIMD-Routine selbst (SSE:128Bit,AVX:256Bit,AVX512:512Bit)
 gewährleistet ist.
 Andernfalls würde das Programm abstürzen.
 
\end_layout

\begin_layout Subparagraph
OpenMPMatrix 
\end_layout

\begin_layout Standard
Die Klasse 
\shape italic
OpenMPMatrix
\shape default
 beeinhaltet SSE/AVX-beschleunigte und Thread-parallelisierte Implementierung
 der Matrix Operationen.
 Die Parallelisierung erfolgt hierbei durch OpenMP 
\begin_inset CommandInset citation
LatexCommand cite
key "dagum1998openmp"

\end_inset

.
 Alle Algorithmen sind im Rahmen dieser Arbeit umgesetzt worden und bieten
 für die meisten CPU-Architekturen eine hohe Effizienz, der wesentliche
 Vorteil liegt hier allerdings in der Unabhängigkeit gegenüber einzelner
 Hersteller.
 
\end_layout

\begin_layout Subparagraph
MKLMatrix 
\end_layout

\begin_layout Standard
Die Klasse 
\shape italic
MKLMatrix 
\shape default
bietet alle Optimierungen der Intel-MKL 
\begin_inset CommandInset citation
LatexCommand cite
key "INTEL"

\end_inset

 Bibliothek und ist somit nur für Intel-CPUs brauchbar.
 Die Bibliothek gilt allgemein als äußerst effizient, besonders im Hinblick
 auf sehr große und komplexe Matrizenoperationen.
 
\end_layout

\begin_layout Subparagraph
CudaMatrix 
\end_layout

\begin_layout Standard
Die Klasse 
\shape italic
CudaMatrix 
\shape default
bietet die Möglichkeit der Nutzung von Nvidia-GPUs 
\begin_inset CommandInset citation
LatexCommand cite
key "Cuda2018"

\end_inset

 zur Beschleunigung der Matrix Operationen.
 Als Basis wurde die CuBLAS Bibliothek von Nvidia verwendet.
 Diese bietet eine effiziente Umsetzung aller Level 1-3 BLAS Routinen 
\begin_inset CommandInset citation
LatexCommand cite
key "lawson1979basic"

\end_inset

 auf modernen Nvidia-GPUs.
 Nähere Informationen zu der genauen Implementierung der Klassen sind in
 
\begin_inset CommandInset citation
LatexCommand cite
key "Kueppers2016c"

\end_inset

 zu finden.
 Weiterhin wird die Verwendung von GPUs für die Beschleunigung der hier
 entwickelten Ersatzmodelle innerhalb einer Optimierungen in Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Verwendung-von-GPGPU"

\end_inset

 diskutiert.
 
\end_layout

\begin_layout Standard
Der Aufbau und einige Methode der 
\begin_inset Quotes gld
\end_inset

CudaMatrix
\begin_inset Quotes grd
\end_inset

 und 
\begin_inset Quotes gld
\end_inset

MKLMatrix
\begin_inset Quotes grd
\end_inset

 innerhalb der studentischen Arbeit 
\begin_inset CommandInset citation
LatexCommand cite
key "kueppers2016,kueppers2016b"

\end_inset

 entwickelt wurden.
 Diese studentische Arbeit wurde im Rahmen dieser Dissertation betreut und
 angeleitet.
 Die Methoden zur Rückwärtsdifferenzierung der Cholesky Zerlegung (siehe
 Abschnitt 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Ableitung-LikelihoodRueckMode"

\end_inset

) und auch die OpenMP-Klasse sowie der gesamte Aufbau der Schnittstellenklasse
 
\begin_inset Quotes gld
\end_inset

Matrix
\begin_inset Quotes grd
\end_inset

 erfolgte innerhalb dieser Arbeit.
 
\end_layout

\begin_layout Subsection
Verteiltes Rechnen 
\begin_inset CommandInset label
LatexCommand label
name "chap:Verteiltes-Rechnen-1"

\end_inset

 
\end_layout

\begin_layout Standard
Im Rahmen dieser Arbeit wurde eine umfangreiche Bibliothek entwickelt, welche
 es ermöglicht  Matrix-Operationen asynchron auf mehrere Rechner zu verteilen.
 Die Rechner können dabei unterschiedliche Architektur besitzen, bspw.
 ist eine gleichzeitige Nutzung von Servern mit GPUs und konventionellen
 CPUs möglich.
 Theoretisch können so auch Rechnungen über das Internet verteilt werden,
 wobei das System zur Zeit nicht dafür ausgelegt ist da es nicht den notwendigen
 Sicherheitsstandards entspricht.
 Hierfür müssten noch Verschlüsselungsalgorithmen, ein Benutzersystem und
 Absicherungen gegenüber 
\begin_inset Quotes gld
\end_inset

Remote-Exploits
\begin_inset Quotes grd
\end_inset

 eingeführt werden, um Missbrauch zu vermeiden.
 Ein wichtiger Punkt bei der Entwicklung war die Vermeidung von MPI-Bibliotheken.
 Die Gründ dafür lagen in den zahlreichen inkompatiblen MPI-Umsetzungen,
 der inkompatibeln Verisonen innerhalb einzelner MPI Pakete und der zwangsweisen
 Synchronität der Netzwerkkommunikation.
 Die Asynchronität war hierbei der wichtigste Punkt, dies liegt daran, dass
 Optimierungen oftmals über Wochen laufen und es durchaus vorkommt, dass
 einzelnen Rechenknoten ausfallen.
 Verwendet man MPI, so fällt die gesamte Rechnung damit aus.
 Bei einer asynchronen Umsetzung, übernimmt ein anderer Knoten die Aufgaben
 des ausgefallenen.
 
\end_layout

\begin_layout Standard
Nach der anfänglichen Entwicklung wurde im Rahmen dieser Dissertation die
 Bachelorarbeit von Kueppers (siehe 
\begin_inset CommandInset citation
LatexCommand cite
key "kueppers2016"

\end_inset

) betreut und angeleitet.
 In dieser wurde der Client um weitere Matrixoperationen erweitert, der
 Scheduler auf ein Round Robin Verfahren erweitert, weitere Klassen Serialisiert
 und die Fehlertoleranz erhöht.
 Nach Abschluss der Bachelorarbeit wurde eine gemeinsame Abhandlung 
\begin_inset CommandInset citation
LatexCommand cite
key "kueppers2016b"

\end_inset

 im Rahmen des DGLR Kongress veröffentlicht.
 
\end_layout

\begin_layout Standard
\begin_inset Wrap figure
lines 0
placement o
overhang 0col%
width "50col%"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../images/SoftwareTechnUmsetzung/loadbalancing_round_robin.eps
	scale 45

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Schematische-Darstellung-der"

\end_inset

Schematische Darstellung der Client/Server Verbindungen und des Round-Robin
 Schedulers
\end_layout

\end_inset


\end_layout

\end_inset

Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Schematische-Darstellung-der"

\end_inset

 zeigt den schematischen Aufbau der etablierten Client-/Server-Verbindungen.
 Der Client stellt das auszuführende Programm dar, welches die zu berechnenden
 Probleme stellt.
 In diesem Fall handelt es sich dabei um das Kriging, dieses muss eine Client-Kl
asse implementieren und auch aufrufen.
 Die Client Klasse wird im späterem Verlauf dieses Abschnitts erklärt.
 Auf der anderen Seite sind mehrere Server die jeweils einen Dämon-Prozess
 starten, welche dann im Hintergrund laufen, einen Netzwerk-Port öffnen
 und auf Aufgaben des Clients warten.
 Die Server-Programme können auf CPUs sowie GPUs rechnen und verbrauchen
 im Wartemodus praktisch keine Resourcen.
 
\end_layout

\begin_layout Standard
Eine weitere Besonderheit ist, dass jeder Client auf jedem Server virtuelle
 Variablen/Objekte allokieren kann, z.B.
 eine Matrix.
 Es werden dann die Daten auf Client-Seite serialisiert und übertragen.
 Auf dem Server ist dann also ein vollständiges Objekt mit eigenen Namen
 verfügbar, welches alle Methoden und Attribute des Originalobjekts besitzt.
 Die Methoden und Attribute können dann von Client-Seite aus über ein eigenes
 Protokoll angesprochen und auf dem Server ausgeführt werden.
 Ergebnisse können dann in eine neues virtuelles Objekt gespeichert werden,
 welches der Client dann wieder zurück übertragen kann.
 Voraussetzung dafür ist allerdings, dass die Klasse des Objekts das 
\begin_inset Quotes gld
\end_inset

SaveableOnServer
\begin_inset Quotes grd
\end_inset

-Interface implementiert hat (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Softwarearchitektur-und-Laufzeit"

\end_inset

).
 
\end_layout

\begin_layout Standard
Steht auf Client-Seite eine Aufgabe an, so wird diese dort in kleinere Teilaufga
ben zerlegt und auf einem 
\begin_inset Quotes gld
\end_inset

Aufgabenstack
\begin_inset Quotes grd
\end_inset

 abgelegt.
 Falls auf Server-Seite dafür Objekte/Daten benötigt werden (z.B.
 eine Matrix), so kann der Client dafür auf dem Server ein virtuelles Objekt
 desselben Typs mit Variablennamen allokieren.
 Ein 
\begin_inset Quotes gld
\end_inset

Round-Robin
\begin_inset Quotes grd
\end_inset

 Scheduler verteilt diese Aufgaben dann nach und nach an die verbundenen
 Server, sofern diese bereit sind.
 Die Server erledigen diese Teilaufgabe und senden dieses an den Client
 zurück und stehen dann für neue Aufgaben zur Verfügung.
 Die Größe dieser Pakete/Teilaufgaben wird jeweils vom Scheduler bestimmt
 und ist wichtig für die Effizienz des Verfahrens, die genaue Aufteilung
 wird in 
\begin_inset CommandInset citation
LatexCommand cite
key "kueppers2016"

\end_inset

 detailliert beschrieben und soll hier nicht weiter thematisiert werden.
 Der Client sammelt alle Teillösungen und setzt diese am Ende dann wieder
 zu einer Gesamtlösung zusammen und kann die Server dann beenden oder im
 Wartemodus belassen.
 
\end_layout

\begin_layout Paragraph*
Exemplarischer Ablauf einer Matrix Addition
\end_layout

\begin_layout Standard
Um den Ablauf deutlich zu machen und die Prozessinteraktionen zu verstehen,
 wird folgend ein Beispiel anhand einer Matrixaddition auf zwei Servern
 gezeigt:
\end_layout

\begin_layout Enumerate
Die Server-Software müssen auf den entsprechenden Rechnern gestartet werden.
 
\end_layout

\begin_layout Enumerate
Der Client wird gestartet und belegt die zu addierenden Matrizen.
\end_layout

\begin_layout Enumerate
Der Client verbindet sich mit beiden Servern 
\end_layout

\begin_layout Enumerate
Der Client startet für jeden Server einen Überwachungsthread, welcher in
 regelmäßigen Abständen einen Ping sendet um zu überprüfen ob der jeweilige
 Server noch verfügbar ist.
\end_layout

\begin_layout Enumerate
Der Client startet die Matrix-Addition mit einem Befehl.
\end_layout

\begin_deeper
\begin_layout Enumerate
Intern: Der Client zerlegt die Addition in mehrere Teilmatrix-Additionen
\end_layout

\begin_layout Enumerate
Intern: Der Client allokiert alle nötigen Teilmatrizen auf jedem Server
 und übersendet die serialisierten Daten.
\end_layout

\begin_layout Enumerate
Intern: Alle Teil-Matrix-Additions Befehle werden auf den Stack vom Client
 gelegt
\end_layout

\begin_layout Enumerate
Intern: Der Client startet den Scheduler, dieser verteilt dann alle Teilaufgaben
 der Reihe nach
\end_layout

\begin_layout Enumerate
Intern: Jeder Server speichert die Teilmatrizen in ein neue Matrix und konvertie
rt diese in den Typ 
\begin_inset Quotes gld
\end_inset

SaveableOnServer
\begin_inset Quotes grd
\end_inset

 
\end_layout

\end_deeper
\begin_layout Enumerate
Der Client sammelt alle Teilergebnisse ein, wandelt diese in Matrix Objekte
 um und setzt die Teilmatrizen zu einer Gesamtmatrix zusammen
\end_layout

\begin_layout Standard
Besonders bei einer Multifidelity-Optimierung oder einer gradientenunterstützte-
Optimierung kann das Training zum Flaschenhals der ganzen Optimierung werden.
 Prinzipiell sind hier zwei Fälle zu unterscheiden:
\end_layout

\begin_layout Enumerate
Multifidelity-Optimierung mit Nutzung eines Co-Kriging: Anzahl an zu trainierend
en Hyperparameter ist sehr hoch (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:COKrigingKovarianzmodell"

\end_inset

).
\end_layout

\begin_layout Enumerate
Gradientenunterstützte Optimierung mit Nutzung eines Gradient-Enhanced-Kriging
 (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Gradient-Enhanced-Kriging"

\end_inset

): Die Kovarianzmatrix kann sehr groß werden, durch die zusätzlichen partiellen
 Ableitungen.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Paragraph
Netzwerkobjekte
\end_layout

\begin_layout Standard
\begin_inset Wrap figure
lines 0
placement o
overhang 0col%
width "50col%"
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../images/SoftwareTechnUmsetzung/UML/SaveableIOnServer.eps
	scale 41

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:UML-Diagramm-des"

\end_inset

UML Diagramm des SaveAbleOnServer Interface
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Alle Objekte die potenziell über das Netzwerk übertragen werden und als
 virtuelle Variable auf Servern zur Verfügung stehen, müssen das Interface
 
\begin_inset Quotes gld
\end_inset

SaveableOnServer
\begin_inset Quotes grd
\end_inset

 implementieren.
 Das Interface erzwingt folgende Methoden, die die entsprechende Klasse
 bereitstellen muss:
\end_layout

\begin_layout Itemize
getSerializedData: Ein typloser Datenstrom mit allen benötigten Daten, um
 die Klasse zu beschreiben.
 Tabelle 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:128Bit-Speicherausrichtung-1"

\end_inset

 beschreibt einen solchen Datenstrom, mit diesem ist ein vollständiges Matrix-Ob
jekt beschrieben.
 
\end_layout

\begin_layout Itemize
setSerializedData: Ein leeres Objekt eines Typs welches das Interface 
\begin_inset Quotes gld
\end_inset

SaveableOnServer
\begin_inset Quotes grd
\end_inset

 implementiert, kann über diese Methode einen Datenstrom erhalten.
 Dieser Datenstrom wird dann wieder zerlegt und in die entsprechenden Attribute
 kopiert oder verschoben.
 
\end_layout

\begin_layout Itemize
getBaseType: Der Ursprungstyp der Objekts (z.B.
 Matrix) als String.
 
\end_layout

\begin_layout Itemize
freeMem: Der belegte Speicher des Objekts wird vollständig geleert.
\end_layout

\begin_layout Standard
Die Serialisierung und Deserialisierung ist in diesem Fall also über das
 Interface sichergestellt.
 Die korrekte Implementierung der (De-)Serialisierung allerdings nicht,
 dies ist mit der Programmiersprache C++ allerdings auch nicht möglich.
 Bei korrekter Implementierung ist es mit diesem System möglich komplette
 Objekte über das Netzwerk zu verschicken.
 Das besondere dabei ist, dass diese Objekte auf dem Server Typunabhängig
 gespeichert werden und dadurch sehr flexibel miteinander interagieren können.
 
\end_layout

\begin_layout Paragraph
Client
\end_layout

\begin_layout Standard
Der Client ist das ausführende Programm, in diesem Fall das Kriging selbst.
 Sorgt für die Aufgaben und deren Verteilung an die Server mithilfe eines
 Round-Robin Verfahrens.
 Das UML Diagramm ist in Anhang 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Kapitel-5--asd"

\end_inset

 zu finden.
 Die Struktur besteht im Wesentlichen aus einer 
\begin_inset Quotes gld
\end_inset

ZMQClient
\begin_inset Quotes grd
\end_inset

 Klasse, welche alle Verbindungen und Kommunikation mit den Servern verwaltet.
 Weiterhin gibt es eine 
\begin_inset Quotes gld
\end_inset

ClientFunctions
\begin_inset Quotes grd
\end_inset

 Klasse, diese beinhaltet die aufrufbaren Methoden wie z.B.
 die Matrix Multiplikation usw..
 Diese Methoden werden dann innerhalb des Kriging-Programms aufgerufen und
 liefern dann die entsprechenden Ergebnisse sofort zurück.
\end_layout

\begin_layout Paragraph
Server
\end_layout

\begin_layout Standard
Die hier beschriebene Server Software ist ein eigenständiges Programm, welches
 auf einem Rechner ausgeführt wird und dann auf Aufgaben wartet.
 Solange es keine Aufgaben erfüllt, verbraucht es praktisch keine Kapazitäten
 und wartet im Hintergrund.
 Der Aufbau der zugehörigen Klassen ist in Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:UML-Diagramm-der"

\end_inset

 dargestellt.
 Kern des Programms ist die 
\begin_inset Quotes gld
\end_inset

ZMQServer
\begin_inset Quotes grd
\end_inset

 Klasse.
 Diese enthält genau zwei Verbindungen, eine zur hauptsächlichen Kommunikation
 mit dem Client und eine Ping-Verbindung.
 Die Ping-Verbindung sendet in regelmäßigen Abständen kleine Netzwerk-Pings
 und der Client weiß damit, dass der Server noch funktioniert.
 
\end_layout

\begin_layout Standard
Weiterhin stellt der 
\begin_inset Quotes gld
\end_inset

ZMQServer
\begin_inset Quotes grd
\end_inset

 die Verwaltung der virtuellen Variablen bereit.
 Hierfür ist ein assoziativer Container in Form einer Map namens 
\begin_inset Quotes gld
\end_inset

vars
\begin_inset Quotes grd
\end_inset

 vorgesehen.
 Dieser bildet einen Variablennamen auf ein 
\begin_inset Quotes gld
\end_inset

SaveableOnServer
\begin_inset Quotes grd
\end_inset

 Objekt ab.
 Dadurch können alle Objekte mit dem Interface SaveableOnServer innerhalb
 dieses Containers gespeichert werden.
 
\end_layout

\begin_layout Standard
Die Klasse 
\begin_inset Quotes gld
\end_inset

MatrixServerFunctions
\begin_inset Quotes grd
\end_inset

 stellt alle Methoden bereit, welche vom Client benötigt werden und hat
 Zugriff auf den Variablen-Container.
 Die Berechnung einer Matrix Addition der Matrizen 
\begin_inset Quotes gld
\end_inset

mat1
\begin_inset Quotes grd
\end_inset

 und 
\begin_inset Quotes gld
\end_inset

mat2
\begin_inset Quotes grd
\end_inset

 auf einem Server würde wie folgt ablaufen:
\end_layout

\begin_layout Enumerate
Der Client muss die beiden Matrizen per Typumwandlung in 
\begin_inset Quotes gld
\end_inset

SaveableOnServer
\begin_inset Quotes grd
\end_inset

 Objekte umwandeln.
 Dies ist nur möglich, wenn das Interface implementiert wurde.
 Diese Objekte können dann serialisiert und übertragen werden.
\end_layout

\begin_layout Enumerate
Der ZMQServer erhält diese Objekte und speicher die Objekte und kann diese
 dann in der 
\begin_inset Quotes gld
\end_inset

vars
\begin_inset Quotes grd
\end_inset

 Map mit dem vorgesehenen Namen speichern.
\end_layout

\begin_layout Enumerate
Der Client ruft über das Netzwerkprotokoll den Befehl auf, die Matrizen
 
\begin_inset Quotes gld
\end_inset

mat1
\begin_inset Quotes grd
\end_inset

 und 
\begin_inset Quotes gld
\end_inset

mat2
\begin_inset Quotes grd
\end_inset

 zu addieren und in 
\begin_inset Quotes gld
\end_inset

mat3
\begin_inset Quotes grd
\end_inset

 zu speichern.
\end_layout

\begin_layout Enumerate
Der Server erhält den Befehl und ruft die 
\begin_inset Quotes gld
\end_inset

matrixAddition
\begin_inset Quotes grd
\end_inset

 Methode auf, als Parameter werden nur die Namen 
\begin_inset Quotes gld
\end_inset

mat1
\begin_inset Quotes grd
\end_inset

,
\begin_inset Quotes grd
\end_inset

mat2
\begin_inset Quotes grd
\end_inset

 und 
\begin_inset Quotes gld
\end_inset

mat3
\begin_inset Quotes grd
\end_inset

 übergeben.
 Zusätzlich können noch die Werte 
\begin_inset Quotes gld
\end_inset

from
\begin_inset Quotes grd
\end_inset

 und 
\begin_inset Quotes gld
\end_inset

to
\begin_inset Quotes grd
\end_inset

 belegt werden, welche die zu addierenden Zeilen beschreiben.
 Damit könnte auch nur ein Teil der Matrix addiert werden.
\end_layout

\begin_layout Enumerate
Die Funktion führt eine Typumwandlung auf die Einträge 
\begin_inset Quotes gld
\end_inset

mat1
\begin_inset Quotes grd
\end_inset

 und 
\begin_inset Quotes gld
\end_inset

mat2
\begin_inset Quotes grd
\end_inset

 des 
\begin_inset Quotes gld
\end_inset

vars
\begin_inset Quotes grd
\end_inset

 Containers durch und wandelt diese in Objekte vom Typ 
\begin_inset Quotes gld
\end_inset

Matrix
\begin_inset Quotes grd
\end_inset

 um.
 Diese können dann addiert und in einem neuen Matrix Objekt 
\begin_inset Quotes gld
\end_inset

mat3
\begin_inset Quotes grd
\end_inset

 gespeichert werden.
 Dieses wird per Typumwandlung wieder in ein 
\begin_inset Quotes gld
\end_inset

SaveableOnServer
\begin_inset Quotes grd
\end_inset

 Objekt umgewandelt und kann dann in dem 
\begin_inset Quotes gld
\end_inset

vars
\begin_inset Quotes grd
\end_inset

 Container unter dem Namen 
\begin_inset Quotes gld
\end_inset

mat3
\begin_inset Quotes grd
\end_inset

 gespeichert werden.
 
\end_layout

\begin_layout Enumerate
Der Client kann nun das 
\begin_inset Quotes gld
\end_inset

SaveableOnServer
\begin_inset Quotes grd
\end_inset

 Objekt 
\begin_inset Quotes gld
\end_inset

mat3
\begin_inset Quotes grd
\end_inset

 zurück übertragen und in ein Objekt vom Typ 
\begin_inset Quotes gld
\end_inset

Matrix
\begin_inset Quotes grd
\end_inset

 umwandeln und hat dann das fertige Ergebnis.
 
\end_layout

\begin_layout Standard
Bei mehreren Servern würde die Typumwandlung genauso verlaufen, es würden
 dann nur Teilmatrizen übertragen werden oder nur Teilrechnungen ausgeführt
 werden.
 
\end_layout

\begin_layout Paragraph
Messaging Middleware ZeroMQ
\end_layout

\begin_layout Standard
ZeroMQ ist eine asynchrone Messaging-Bibliothek, welche eine hocheffiziente
 Nachrichtenübermittlung anbietet.
 ZeroMQ ist für Problemstellungen entwickelt worden, welche eine hoch optimierte
 und schnelle Datenübertragung benötigen.
 Für weitere Informationen sei auf 
\begin_inset CommandInset citation
LatexCommand cite
key "ZeroMQ,Dworak2011"

\end_inset

 verwiesen.
\end_layout

\begin_layout Paragraph
Ausfallsicherheit
\end_layout

\begin_layout Standard
Damit der Client erkennen kann, welche Server aktuell im Netzwerk vorhanden
 sind, existiert neben jeder Haupt- verbindung eine zusätzliche Ping-Verbindung
 zu jedem bekannten Server.
 Diese wiederum öffnen analog zum Client auch einen zusätzlichen Socket,
 der lediglich für die Verwaltung des periodischen Pingsignals zuständig
 ist.
 Der Ping besteht dabei aus der Signatur des Clients, anhand derer der Server
 erkennen kann, mit welchem Client dieser sich verbunden hat.
 Die Antwort des Servers wiederum besteht aus der Signatur des Clients,
 mit welchem er aktuell gekoppelt ist.
 Sollte ein zweiter Client eine Anfrage an einen bereits gekoppelten Server
 senden, kann dieser anhand der zurückgesendeten Signatur feststellen, dass
 der Server bereits anderweitig vergeben ist.
 Auch Ausfälle eines Servers während der Programmlaufzeit können so vom
 Client erkannt werden.
 
\end_layout

\begin_layout Paragraph
Geschwindigkeit bei mehreren Servern
\end_layout

\begin_layout Standard
\begin_inset Wrap figure
lines 0
placement o
overhang 0col%
width "50col%"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../images/SoftwareTechnUmsetzung/Fabiab_Netzwerk_one_many_total_speedup.eps

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Beschleunigungsfaktor-eines-Krig"

\end_inset

Beschleunigungsfaktor eines Kriging-Trainings mit n Stützstellen im Vergleich
 zu einer Einzelrechnung bei Nutzung von mehreren Servern.
 Quelle: 
\begin_inset CommandInset citation
LatexCommand cite
key "kueppers2016b,kueppers2016"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

Bei einem verteilten System leidet die Geschwindigkeit der Operationen oft
 erheblich, da für die Kommunikation und die Verwaltung der Teilberechnungen
 ein großer Anteil der Rechenzeit aufgewendet wird.
 Meist steigt der Aufwand mit steigender Server-Anzahl und lohnt sich erst
 ab einer gewissen Problemgröße.
 Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Beschleunigungsfaktor-eines-Krig"

\end_inset

 zeigt die Messung des zeitlichen Faktors eines Kriging-Trainings bei steigender
 Server-Anzahl und unterschiedlichen Problemgrößen.
 Das Training wurde auf dem DLR-AT Cluster ausgeführt (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "par:Laufzeitumgebung"

\end_inset

).
 Als Testfall dienten zufällige Stützstellen der in Anhang 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:ZDT3"

\end_inset

 beschriebenen ZDT3 Funktion mit 20 freien Variablen.
 Eine Anzahl an Servern von 0 stellt ein lokales Training dar und eine Anzahl
 von 1 eine 1:1 Verbindung.
\end_layout

\begin_layout Standard
Man kann sehen, dass der Verlust eine 1:1 Verbindung sehr klein ist, der
 Verlust über die reine Netzwerkkommunikation ist also als gering einzustufen.
 Bei einer Anzahl von 2-3 Servern ist der Verlust ab einer Stützstellenanzahl
 von 2000 ebenfalls sehr klein.
 Mit zunehmender Anzahl an Servern nimmt dann auch der Verlust auch weiter
 zu, dieses Verhalten ist allerdings auch so zu erwarten.
 Die Problemstellung ist für eine so hohe Anzahl an so leistungsstarken
 Rechnern noch zu klein, dennoch lässt sich bei 7 Servern eine maximale
 Beschleunigung des Faktors 5 erreichen, also 71% der Rechenleistung werden
 effektiv genutzt.
 Bedenkt man weiterhin die Flexibilität und Ausfallsicherheit des System,
 so ist der Einsatz bei entsprechend großen Problemen sehr lohnenswert.
 
\end_layout

\begin_layout Subsection
Effiziente Berechnung der Kovarianzfunktion
\begin_inset CommandInset label
LatexCommand label
name "sec:SoftwaretechnKorrelationsfunktionen"

\end_inset


\end_layout

\begin_layout Standard
Die in Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Kovarianzmatrix"

\end_inset

 beschriebenen Kovarianzfunktionen müssen für jeden Eintrag in der Kovarianzmatr
ix und auch deren Ableitung nach den Hyperparametern bestimmt werden.
 Für jeden Trainingsschritt mit einem Dichtefunktionsaufruf und den dazugehörige
n partiellen Ableitungen ergeben sich folgend Anzahl an Aufrufen der Kovarianzfu
nktion:
\end_layout

\begin_layout Enumerate
Berechnung der Dichtefunktion: 
\begin_inset Formula $\frac{n\left(n+1\right)}{2}$
\end_inset

 Aufrufe der Kovarianzfunktion
\end_layout

\begin_layout Enumerate
Berechnung von 
\begin_inset Formula $o$
\end_inset

 partiellen Ableitungen der Likelihood Funktion: 
\begin_inset Formula $o\frac{n\left(n+1\right)}{2}$
\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
Geht man von einem üblichen Beispiel mit 1000 Stützstellen und 80 Hyperparameter
n aus, so ergeben sich für die Dichtefunktion ca.
 500.000 Aufrufe und für die partiellen Ableitungen dann 80x500.000 Aufrufe.
 Insgesamt sind dies ca.
 40.5 Millionen Aufrufe für eine Iteration.
 Dies bedeutet, dass jeder gesparte Befehl innerhalb des Kovarianzfunktionsaufru
fs sich sehr stark auf die Laufzeit auswirkt.
 Folgend sind einige Möglichkeiten aufgelistet, wie man die Berechnung beschleun
igen kann:
\end_layout

\begin_layout Itemize
Exponentialfunktion der Hyperparameter 
\begin_inset Formula $e^{\theta_{l}}$
\end_inset

 im Vorraus berechnen
\end_layout

\begin_layout Itemize
Gauss Kovarianzfunktion: Puffern von Zwischenergebnissen
\end_layout

\begin_layout Itemize
Exponentialfunktion durch schnellere ersetzen
\end_layout

\begin_layout Itemize
CPU-Befehlssätze SSE/AVX verwenden
\end_layout

\begin_layout Paragraph*
Exponentialfunktion im Voraus berechnen
\end_layout

\begin_layout Standard
Da die Hyperparameter für eine Iteration konstant bleiben, ist es sinnvoll
 die Berechnung von 
\begin_inset Formula $e^{\theta_{l}}$
\end_inset

 (siehe Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:ExpoKorrelationsfunktion-1"

\end_inset

) nur einmal zu Anfang der Iteration durchzuführen und dann abzuspeichern.
 
\end_layout

\begin_layout Paragraph*
Puffern der Exponentialfunktion
\end_layout

\begin_layout Standard
Da für die Aufstellung der Kovarianzmatrix der innere Teil 
\begin_inset Formula $e^{-\frac{1}{2}\underset{l=1}{\overset{l<=k}{\sum}}\left(e^{\theta_{l}}\left|h_{l}\right|^{p}\right)}$
\end_inset

 (siehe Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:ExpoKovarianzfunktion"

\end_inset

) in den Gleichungen für die partiellen Ableitungen der Kovarianzfunktion
 nach den Hyperparametern (siehe Gleichungen 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:AbleitungKorrGauss"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:AbleitungsKorrGauss2"

\end_inset

) derselbe ist, macht es Sinn diesen zu puffern und bei Bedarf wiederzuverwenden.
 Da der Abruf aus dem RAM deutlich schneller ist, als die erneute Berechnung
 der Exponentialfunktion, beschleunigt dies die Berechnung der Ableitungsmatrize
n erheblich.
\end_layout

\begin_layout Paragraph*
Schnellere Exponentialfunktion 
\end_layout

\begin_layout Standard
Da die Implementierung der Exponentialfunktion der GCC-Bibliothek (Stand
 GCC v4.9) relativ langsam ist, diese Funktion aber mehrere Millionen Mal
 aufgerufen wird, ist es sinnvoll eine schnellere Implementierung zu verwenden.
 In 
\begin_inset CommandInset citation
LatexCommand cite
key "fmath2018"

\end_inset

 wird eine AVX beschleunigte Implementierung der Exponentialfunktion beschrieben
, diese ist ca.
 5x schneller als die GCC-Version.
 Der Fehler der berechneten Werte ist vergleichbar mit der GCC-Version.
 
\end_layout

\begin_layout Paragraph*
Streaming SIMD Extensions (SSE)
\begin_inset CommandInset label
LatexCommand label
name "subsec:Streaming-SIMD-Extensions"

\end_inset


\end_layout

\begin_layout Standard
\noindent
Die Streaming SIMD Extensions (SSE) sind eine von Intel entwickelte Befehlssatze
rweiterung der x86-Architektur.
 Mit Einführung des Pentium-III-(Katmai)-Prozessors wurde diese 1999 vorgestellt.
 Aufgabe der SSE Befehle ist es Programme durch Parallelisierung auf Instruktion
slevel zu beschleunigen, auch SIMD (Single Instruction Multiple Data) genannt.
 Die SSE-Befehlssatzerweiterung umfasst ursprünglich 70 Instruktionen und
 8 neue Register, genannt XMM0 bis XMM7.
 Ursprünglich wurden die 128
\begin_inset space ~
\end_inset

Bit breiten Register allerdings nicht in einem Schritt verarbeitet.
 Bei heutigen CPUs (z.B.
 Intel Core CPUs) werden die Register in einem Schritt verarbeitet, zudem
 wurde die Anzahl der Register von 8 auf 16 erhöht.
 
\end_layout

\begin_layout Standard
Es gibt zahlreiche Umsetzungen der SSE Befehle.
 Diese reichen von SSE bis SSE5, wobei ab SSE3 AMD und Intel jeweils eigene
 Implementationen der SSE Architektur vornahmen.
 Der Nachfolger von SSE heißt AVX (Advanced Vector Extensions) und verbreitert
 die Register auf 16x
\begin_inset space ~
\end_inset

256
\begin_inset space ~
\end_inset

Bit.
 
\end_layout

\begin_layout Standard
Innerhalb dieser Arbeit wurden nur SSE Befehle verwendet, da diese praktisch
 von allen aktuellen CPUs und auch Compilern unterstützt werden.
 Für die Verwendung von AVX sind relativ neue Kompiler und CPUs notwendig,
 dies kann bei einigen Anwendern zu Problemen führen.
 Durch die 128
\begin_inset space ~
\end_inset

Bit Register können nun in einem Rechenschritt vier float (32
\begin_inset space ~
\end_inset

Bit) oder zwei double (64
\begin_inset space ~
\end_inset

Bit) Werte gleichzeitig verarbeitet werden.
 Um diese Funktionen zu nutzen, müssen im C++-Code spezielle SSE Befehle
 verwendet werden 
\begin_inset CommandInset citation
LatexCommand citep
key "AGN,INTEL"

\end_inset

.
 Das folgende Listing zeigt die Umsetzung der Gauss Korrelationsfunktion
 mit SSE Befehlen, wobei die Parallelisierung hier über die Hyperparameter
 gemacht wird.
 
\shape italic
Auf die Anwendung von Pseudocode wird in diesem Fall aufgrund der sehr spezielle
n SSE Befehle weitestgehend verzichtet.

\shape default
 Diese Methode wird zur Berechnung der Einträge der Kovarianzmatrix verwendet
 und wird dementsprechend oft aufgerufen.
 
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "language={C++},float,numbers=left,basicstyle={\scriptsize},tabsize=4"
inline false
status open

\begin_layout Plain Layout

__m128d correlSSE=0.0
\end_layout

\begin_layout Plain Layout

__m128d thetasExpSSE, point1SSE, point2SSE, pointDiffSSE
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

array thetasExpArray
\end_layout

\begin_layout Plain Layout

array point1Array
\end_layout

\begin_layout Plain Layout

array point2Array
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

for(i=0; i<point1.getNumVars()-1 ; i+=2)
\end_layout

\begin_layout Plain Layout

		thetasExpSSE =_mm_load_pd(&(thetasExpArray[i]))
\end_layout

\begin_layout Plain Layout

		point1SSE =_mm_load_pd(&(point1Array[i]))
\end_layout

\begin_layout Plain Layout

		point2SSE =_mm_load_pd(&(point2Array[i]))
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

		pointDiffSSE = _mm_sub_pd(point1SSE,point2SSE)
\end_layout

\begin_layout Plain Layout

		pointDiffSSE = _mm_mul_pd(pointDiffSSE,pointDiffSSE)
\end_layout

\begin_layout Plain Layout

		pointDiffSSE = _mm_mul_pd( thetasExpSSE, pointDiffSSE  )
\end_layout

\begin_layout Plain Layout

		correlSSE = _mm_add_pd( correlSSE,  pointDiffSSE )
\end_layout

\begin_layout Plain Layout

	
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

correlSSE = _mm_hadd_pd(correlSSE,correlSSE)
\end_layout

\begin_layout Plain Layout

_mm_store_sd(&correl,correlSSE)
\end_layout

\begin_layout Plain Layout

for(; i<point1.getNumVars() ; i++) 	
\end_layout

\begin_layout Plain Layout

		correl += thetasExp[0][i] * (point1.getVar(i) - point2.getVar(i))^2
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

correl=e^(-0.5*correl)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
In den Zeilen 1-2 werden verschiedene Variablen definiert vom Typ 
\begin_inset Quotes eld
\end_inset

__m128d
\begin_inset Quotes erd
\end_inset

, dieser Typ stellt ein 128 Bit großes SSE Datentypen dar und kann zwei
 64
\begin_inset space ~
\end_inset

Bit double Werte aufnehmen.
 Zudem wird die Variable correlSSE mithilfe der Funktion_mm_setzero_pd()
 auf 0 gesetzt.
 Die Zeilen 4-6 stellen Arrays dar, welche für die Berechnung der Korrelationsfu
nktion benötigt werden.
 Das Array thetasExpArray beinhaltet die berechneten Hyperparameter 
\begin_inset Formula $e^{\theta_{l}}$
\end_inset

.
 Da diese Werte für alle Einträge in der Kovarianzmatrix identisch sollten
 sie daher vor dem Belegen der Kovarianzmatrix berechnet werden.
 Danach werden die beiden Arrays initialisiert, welche die Ortsvariablen
 
\begin_inset Formula $\vec{x}_{1},\vec{x}_{2}\in\mathbb{R^{\mathrm{k}}}$
\end_inset

 beinhalten.
 Die darauffolgende for-Schleife iteriert über die Anzahl an freien Variablen.
 Der Zähler wird hier immer um den Wert 2 erhöht, da mit den SSE Routinen
 2 double Werte gleichzeitig berechnet werden können.
 In den Zeilen 9-11 werden 128Bit aus den Arrays an der Stelle i in die
 SSE-Register der CPU übertragen.
 Aus diesem Grund muss der Speicher zwingend 128Bit Speicherausrichtung
 besitzen.
 
\end_layout

\begin_layout Paragraph
Einschub: Speicherausrichtung
\begin_inset CommandInset label
LatexCommand label
name "par:Einschub-Speicherausrichtung"

\end_inset


\end_layout

\begin_layout Standard

\shape italic
In aktuellen C++ Compilern wird eine Speicherausrichtung von 128Bit im Normalfal
l gewährleistet.
 Tabelle 
\shape default

\begin_inset CommandInset ref
LatexCommand ref
reference "tab:128Bit-Speicherausrichtung"

\end_inset


\shape italic
 zeigt die Speicherausrichtung und die damit entstehende Problematik beim
 Programmieren.
 Die erste Zeile der Tabelle beschreibt den Index eines normalen Arrays
 mit 6 Einträgen und jeder Eintrag hat die Größe eines 64Bit (z.B.
 double) Werts.
 Der Compiler garantiert in diesem Fall einen zusammenhängenden Speicher
 von 128Bit, dargestellt durch die dritte Zeile.
\end_layout

\begin_layout Standard
\begin_inset Wrap table
lines 0
placement o
overhang 0col%
width "50col%"
status open

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
64Bit
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
64Bit
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
64Bit
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
64Bit
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multicolumn="1" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

$
\backslash
underbrace{128Bit aligned}$
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:128Bit-Speicherausrichtung"

\end_inset

128Bit Speicherausrichtung
\end_layout

\end_inset


\end_layout

\end_inset

Die Zeilen 13-16 stellen dann die eigentliche Berechnung in den SSE-Registern
 der CPU dar.
 Durch die breiteren Register werden hier immer zwei Werte auf einmal verarbeite
t.
 In Zeile 19 werden die beiden Werte in den Registern zusammenaddiert und
 dann in Zeile 20 wieder zurück in den RAM kopiert.
 
\end_layout

\begin_layout Standard
Ist die Anzahl der Variablen nicht durch zwei teilbar, so bleibt ein Rest
 bestehen.
 Dieser wird in Zeile 21-23 auf konventionelle Weise berechnet.
 Die gemessenen Geschwindigkeitsvorteile durch SSE4 liegen bei ca.
 30
\begin_inset space ~
\end_inset

%.
 
\end_layout

\begin_layout Subsection
Reduktion von Stützstellen
\begin_inset CommandInset label
LatexCommand label
name "subsec:Reduktion-von-Stützstellen"

\end_inset


\end_layout

\begin_layout Standard
Während einer Optimierung können eine Vielzahl an Stützstellen erzeugt werden
 und damit große Kovarianzmatrizen entstehen.
 Aus diesem Grund ist es sinnvoll nur Stützstellen zu verwenden, welche
 dem jeweiligen Ersatzmodell einen wirklichen Informationszugewinn bringen.
 Eine gute Möglichkeit ist es, räumlich eng beieinander liegende Stützstellen
 zu entfernen.
 Als notwendige Metrik bietet sich die Verwendung der Korrelationsfunktion
 (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Kovarianzmatrix"

\end_inset

) an.
 Stützstellen mit sehr hohen Korrelationen haben nur einen sehr kleinen
 Abstand zueinander und sollten dem Ersatzmodell nur einen geringen Informations
anteil liefern.
 Solche Stützstellen könnten dann für das Training außer Acht gelassen werden.
 Allerdings macht dieses Vorgehen nur Sinn, wenn die Korrelationslängen
 des jeweiligen Kriging-Modells bereits gut geschätzt sind.
 Um dies zu gewährleisten, wird die Reduktion der Stützstellen nur durchgeführt,
 wenn die in Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:UltraRestart"

\end_inset

 beschriebene Initialisierungsoption gewählt wurde.
 Zusätzlich gilt die Bedingung, dass sich die Initialisierung bereits im
 
\begin_inset Quotes gld
\end_inset


\shape italic
Restart
\shape default

\begin_inset Quotes grd
\end_inset

 Modus befinden muss.
\end_layout

\begin_layout Standard
Folgend wird der verwendete Algorithmus vereinfacht dargestellt:
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "float,numbers=left,basicstyle={\scriptsize},tabsize=4,extendedchars=true"
inline false
status open

\begin_layout Plain Layout

korrMap = AssoziativerContainer[float][paar(int,int)]
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

schleife p1 über alle points
\end_layout

\begin_layout Plain Layout

	schleife p2=p1.next() über alle points
\end_layout

\begin_layout Plain Layout

		korrelation = correlation(p1,p2)
\end_layout

\begin_layout Plain Layout

		korrMap[korrelation] =paar(p1,p2)
\end_layout

\begin_layout Plain Layout

	
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

pointsToDelete=[]
\end_layout

\begin_layout Plain Layout

schleife korrPair über alle korrMap
\end_layout

\begin_layout Plain Layout

	wenn (korrMap.p1 in pointsToDelete) oder (korrMap.p2 in pointsToDelete)
\end_layout

\begin_layout Plain Layout

		überspringe
\end_layout

\begin_layout Plain Layout

	deleteIndices.append(random(p1,p2))
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

schleife deletePoint über alle deleteIndices
\end_layout

\begin_layout Plain Layout

	points.remove(deletePoint)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Wrap figure
lines 12
placement o
overhang 0in
width "50col%"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../images/SoftwareTechnUmsetzung/SampleFilterAlgo_All.eps
	scale 20

\end_inset


\begin_inset Graphics
	filename ../images/SoftwareTechnUmsetzung/SampleFilterAlgo_Filtered.eps
	scale 20

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:PunkteFilterBeispiel"

\end_inset

Anwendung des Filters anhand eines analytischen Beispiels
\end_layout

\end_inset


\end_layout

\end_inset

In Zeile 3-8 werden die Korrelationen für alle möglichen Punktepaare berechnet
 und innerhalb der Map direkt sortiert.
 Die Schleife in Zeile 11-15 geht die sortierte Map durch, angefangen bei
 dem Größten Korrelationswert.
 Innerhalb der Schleife wird geprüft, ob einer der beiden Punkte bereits
 zum Löschen markiert wurde oder nicht.
 Wurde einer markiert, so wird nichts weiter unternommen.
 Wurde kein Punkt markiert, so wird dieser zum Löschen eingetragen.
 Auf diese Weise kann sichergestellt werden, dass nicht beide Punkte gelöscht
 werden.
 
\end_layout

\begin_layout Standard
In Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:PunkteFilterBeispiel"

\end_inset

 wird ein Beispiel für diesen Filter gezeigt.
 Es wurde die ZDT3 Funktion mit 2 Variablen verwendet (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:ZDT3"

\end_inset

).
 Auf dem linken Bild wurden 500 gleichverteilte Stützstellen erzeugt und
 nochmals 500 weitere Stützstellen normalverteilt um die Mitte des betrachteten
 Bereichs gelegt (mit einer Standardabweichung von 10% der Raumgröße).
 Damit soll eine lokale Anhäufung von Stützstellen simuliert werden.
 
\end_layout

\begin_layout Standard
Daraufhin wurde ein Ordinary-Kriging trainiert und der Filter angewandt,
 wobei der Filter die Stützstellen auf 100 reduziert hat.
 Das Ergebnis ist in Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:PunkteFilterBeispiel"

\end_inset

 rechts zu sehen.
 Die lokale Anhäufung in der Mitte ist praktisch nicht mehr vorhanden und
 die Verteilung der Punkte ist sehr gleichmäßig.
 Die Laufzeit des Filters ist im Vergleich zur restlichen Laufzeit zu vernachläs
sigen.
\end_layout

\begin_layout Subsection
Likelihood: Inverse durch Gleichungssysteme ersetzen 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Inverse-durch-Gleichungssysteme"

\end_inset


\end_layout

\begin_layout Standard
Mit Hilfe der Cholesky-Zerlegung (siehe Anhang 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Cholesky-Zerlegung"

\end_inset

) können lineare Gleichungssysteme sehr effizient gelöst werden.
 Dies kann man sich zunutze machen, um bei der Likelihood Berechnung auf
 die direkte Bestimmung der Inversen verzichten.
 Das Maximum des Likelihoodterm (siehe 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:LogLikelihood"

\end_inset

) sieht wie folgt aus:
\begin_inset Formula 
\begin{align*}
\underset{\vec{h}}{\max}\log(L)= & -\log\left(\det(\mathbf{\mathbf{Cov}})\right)-\left(\vec{y}_{s}-\overrightarrow{F}\right)^{T}\mathbf{\mathbf{Cov}}^{-1}\left(\vec{y}_{s}-{}_{1}\overrightarrow{F}\right)
\end{align*}

\end_inset

Die Invertierung der Kovarianzmatrix besteht aus zwei Schritten:
\end_layout

\begin_layout Enumerate
Berechnung der Cholesky Zerlegung 
\begin_inset Formula $\frac{1}{6}n^{3}+\mathcal{O}(n^{2})$
\end_inset

 Gleitkomma-Operationen (Quelle 
\begin_inset CommandInset citation
LatexCommand cite
key "press2007numerical"

\end_inset

), wobei 
\begin_inset Formula $\mathbf{\mathbf{Cov}\in\mathbb{R}}^{n\times n}$
\end_inset


\end_layout

\begin_layout Enumerate
Vor- und Rückwärtssubstitution mit 
\begin_inset Formula $n^{3}$
\end_inset

 Gleitkomma-Operationen
\end_layout

\begin_layout Standard
Die Determinante der Kovarianzmatrix wird aus der Cholesky Zerlegung gewonnen
 (siehe 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Cholesky-Zerlegung"

\end_inset

).
 Der quadratische Term 
\begin_inset Formula $\left(\vec{y}_{s}-\overrightarrow{F}\right)^{T}\mathbf{\mathbf{Cov}}^{-1}\left(\vec{y}_{s}-\overrightarrow{F}\right)$
\end_inset

 beinhaltet allerdings noch die Inverse Kovarianzmatrix.
 Dieser kann mit Hilfe der Cholesky Zerlegung gewonnen werden, wir führen
 hierfür die Hilfsvektoren 
\begin_inset Formula $\vec{e}$
\end_inset

 und 
\begin_inset Formula $\vec{d}$
\end_inset

 ein:
\begin_inset Formula 
\begin{align*}
\left(\vec{y}_{s}-\overrightarrow{F}\right) & =\vec{e}\\
\mathbf{\mathbf{Cov}}^{-1}\vec{e} & =\vec{d}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\noindent
Bei der Cholesky Zerlegung wird die Matrix 
\begin_inset Formula $\mathbf{\mathbf{Cov}}$
\end_inset

 in ein Produkt aus einer unteren Dreicksmatrix und deren Transponierten
 zerlegt, die Dreiecksmatrix 
\begin_inset Formula $\mathbf{L}$
\end_inset

 gilt an dieser Stelle als bekannt:
\begin_inset Formula 
\begin{align*}
\mathbf{L}\mathbf{L}^{T} & =\mathbf{\mathbf{Cov}}
\end{align*}

\end_inset

Daraus folgt:
\begin_inset Formula 
\begin{align*}
\mathbf{\mathbf{\left(\mathbf{L}\mathbf{L}^{T}\right)}}^{-1}\vec{e} & =\vec{d}\\
\vec{e} & =\vec{d}\mathbf{\mathbf{\mathbf{L}\mathbf{L}^{T}}}
\end{align*}

\end_inset

Führt man nun folgende Substitution ein:
\begin_inset Formula 
\begin{align*}
\vec{d_{tmp}} & =\vec{d}\mathbf{\mathbf{\mathbf{L}}}\\
\vec{e} & =\vec{d_{tmp}}\mathbf{\mathbf{\mathbf{L}^{T}}}
\end{align*}

\end_inset

So kann dieses Gleichungssystem durch eine einfache Rückwärtssubstitution
 
\begin_inset Formula $\vec{d}_{tmp}$
\end_inset

 gelöst werden.
 Danach kann direkt das folgende Gleichungssystem durch Vorwärtseinsetzen
 gelöst werden und der Vektor 
\begin_inset Formula $\vec{d}$
\end_inset

 ist hiermit bekannt.
 
\begin_inset Formula 
\[
\vec{d_{tmp}}=\vec{d}\mathbf{\mathbf{\mathbf{L}}}
\]

\end_inset

Damit ergibt sich folgender Aufwand:
\end_layout

\begin_layout Enumerate
Berechnung der Cholesky Zerlegung 
\begin_inset Formula $\frac{1}{6}n^{3}+\mathcal{O}(n^{2})$
\end_inset

 Gleitkomma-Operationen (Quelle 
\begin_inset CommandInset citation
LatexCommand cite
key "press2007numerical"

\end_inset

), wobei 
\begin_inset Formula $\mathbf{\mathbf{Cov}\in\mathbb{R}}^{n\times n}$
\end_inset


\end_layout

\begin_layout Enumerate
Lösung von zwei Gleichungssysteme mit 
\begin_inset Formula $2n^{2}$
\end_inset

 Gleitkomma-Operationen
\end_layout

\begin_layout Standard
Der zweite Schritt ist in diesem Fall also deutlich günstiger.
 Allerdings wird die Inverse bei der Berechnung der partiellen Ableitungen
 der Likelihood Funktion benötigt.
 Eine Lösung für dieses Problem wird in Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Ableitung-LikelihoodRueckMode"

\end_inset

 aufgezeigt.
 
\end_layout

\begin_layout Subsection
Ableitung Likelihood: Verzicht auf Inverse - Rückwärtsdifferentiation der
 Cholesky Zerlegung 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Ableitung-LikelihoodRueckMode"

\end_inset


\end_layout

\begin_layout Standard
Wie in Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:SpurApprox"

\end_inset

 bereits erwähnt, ist es bei der Berechnung des Likelihood Terms möglich
 auf die Invertierung der Kovarianzmatrix zu verzichten.
 Bei der Bestimmung der partiellen Ableitungen des Likelihood Terms nach
 den Hyperparametern ist dies allerdings schwieriger.
 Die Bestimmung der partiellen Ableitungen folgt dem folgenden Berechnungsschema
:
\end_layout

\begin_layout Enumerate
Über alle benötigen Hyperparameter 
\begin_inset Formula $h_{l}$
\end_inset


\end_layout

\begin_deeper
\begin_layout Enumerate
Bestimmung der Ableitung der Kovarianzmatrix
\begin_inset Formula $\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}$
\end_inset


\end_layout

\begin_layout Enumerate
Berechnung der Ableitung der quadratischen Form: 
\begin_inset Formula $\left(\vec{y}_{s}-\beta_{1}\overrightarrow{F}\right)^{T}\mathbf{\mathbf{\mathbf{Cov}}}^{-1}\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}\mathbf{Cov}^{-1}\left(\vec{y}_{s}-\beta_{1}\overrightarrow{F}\right)$
\end_inset


\end_layout

\begin_layout Enumerate
Berechnung der Ableitung der Determinante: 
\begin_inset Formula $\textrm{Spur}\left(\mathbf{\mathbf{Cov}}^{-1}\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}\right)$
\end_inset


\end_layout

\end_deeper
\begin_layout Standard
Punkt a bedeutet vom Aufwand die Aufstellung der symmetrischen Matrix 
\begin_inset Formula $\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}$
\end_inset

.
 Die Komplexität des Algorithmus liegt bei 
\begin_inset Formula $\mathcal{O}\left(n^{2}\right)$
\end_inset

 und kann zudem sehr gut parallelisiert werden.
 Die Bestimmung der einzelnen Ableitungen der Kovarianzmatrix hängt stark
 von dem verwendeten Kriging Modell und der verwendeten Korrelationsfunktion
 ab.
 Beim Gradient Enhanced Kriging können diese Einzelableitungen komplexer
 werden und damit auch vom numerischen Aufwand teurer.
 Dennoch können in der Regel sehr viele Teile aus der Aufstellung der Kovarianzm
atrix wiederverwendet werden, was den Aufwand erheblich reduziert und daher
 eher unerheblich macht.
 
\end_layout

\begin_layout Standard
Punkt b ist vom Aufwand her nahezu vernachlässigbar.
 In der Regel wurde der Vektor 
\begin_inset Formula $\left(\vec{y}_{s}-\beta_{1}\overrightarrow{F}\right)^{T}\mathbf{\mathbf{\mathbf{Cov}}}^{-1}$
\end_inset

 bereits in der Likelihood Berechnung bestimmt und es muss nur noch eine
 Vektor Matrix Multiplikation durchgeführt werden.
\end_layout

\begin_layout Standard
Punkt c ist der aufwendigste Teil, da nur für diesen Teil die Inverse bestimmt
 werden muss.
 Die Inverse wird natürlich außerhalb dieser Schleife nur einmal berechnet,
 dennoch könnte man ohne diesen Teil vollständig auf die direkte Berechnung
 der Inversen verzichten.
 Ist die Inverse bestimmt, liegt die Komplexität zur Berechnung der Spur
 bei 
\begin_inset Formula $\mathcal{O}\left(n^{2}\right)$
\end_inset

.
 
\end_layout

\begin_layout Standard
Der Hauptaufwand liegt also in der Berechnung der Inversen.
 Der genaue Ablauf zur Bestimmung der Inversen folgt dem Schema aus Kapitel
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Cholesky-Zerlegung"

\end_inset

.
 Grundlegend besteht dieses Schema aus zwei Schritten:
\end_layout

\begin_layout Enumerate
Cholesky Zerlegung der Kovarianzmatrix
\end_layout

\begin_layout Enumerate
Vorwärts- und Rückwärtssubstitution zur Bestimmung der Inversen
\end_layout

\begin_layout Standard
Der Aufwand beider Schritte liegt bei 
\end_layout

\begin_layout Enumerate
Ungefähr 
\begin_inset Formula $\frac{1}{6}n^{3}$
\end_inset

Multiplikationen/Additionen, 
\begin_inset Formula $\frac{1}{2}n^{2}$
\end_inset

 Divisionen, 
\begin_inset Formula $n$
\end_inset

 Wurzeloperationen 
\end_layout

\begin_layout Enumerate
Vorwärts- und Rückwärtseinsetzen insgesamt: 
\begin_inset Formula $n^{3}$
\end_inset

 Multiplikationen/Additionen
\end_layout

\begin_layout Standard
Der Hauptaufwand liegt also bei der Vorwärts- und Rückwärtssubstitution.
 Wobei sich diese für den Fall einer Invertierung hervorragend parallelisieren
 lässt.
 Da man das Vorwärts- und Rückwärtseinsetzen bei der Invertierung über 
\begin_inset Formula $n$
\end_inset

 Vektoren macht, kann man die Berechnung über die Vektoren parallelisieren.
 SIMD Routinen sind hier besonders effizient, da für jeden Vektor immer
 dieselbe Routine durchlaufen wird und nur die Daten sich ändern.
 Eine GPU, SSE oder AVX Beschleunigung ist hier also besonders anzustreben.
 Denkbar ist aber auch eine Parallelisierung auf Prozessebene, diese ließe
 sich nach demselben Schema aufteilen und die Teile dann natürlich auch
 über SIMD Befehle beschleunigen.
 
\end_layout

\begin_layout Standard
Ein kompletter Verzicht auf die Vorwärts- und Rückwärtssubstitution wäre
 dennoch erstrebenswert, da diese den größten Teil des Aufwands ausmacht.
 
\end_layout

\begin_layout Standard
Einen interessanten Ansatz hierzu kann man in 
\begin_inset CommandInset citation
LatexCommand cite
key "toal2009adjoint"

\end_inset

 finden.
 Dieser bedient sich der algorithmischen Differentiation im Rückwärtsmodus,
 der interessierte Leser sei auf 
\begin_inset CommandInset citation
LatexCommand cite
key "Mader2008,Griewank2008"

\end_inset

 verwiesen, welche einen sehr guten Überblick über die algorithmische Differenti
ation bieten.
 Dieser Ansatz bietet die Möglichkeit auf die Vor- und Rückwärtssubstitution
 zu verzichten, allerdings werden rückwärtsdifferenzierte Algorithmen des
 Cholesky Algorithmus und auch der Vor- und Rückwärtssubstitution benötigt.
 Für diese Algorithmen gibt es keine performante Implementation über Bibliotheke
n.
 
\end_layout

\begin_layout Standard
Aus diesem Grund wurde in 
\begin_inset CommandInset citation
LatexCommand cite
key "Toal2011"

\end_inset

 ein Algorithmus vorgeschlagen, welcher die Invertierung zwar benötigt,
 aber keine rückwärtsdifferenzierten Algorithmen.
 Ein Geschwindigkeitsvorteil wird hierbei bei der Aufstellung der partiellen
 Ableitungen der Kovarianzmatrix 
\begin_inset Formula $\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}$
\end_inset

 erreicht.
 Diese muss bei dem verwendeten Algorithmus nicht mehr direkt erzeugt werden.
 Die Vorwärts- und Rückwärtssubstitution muss dennoch durchgeführt werden.
 Diese stellt grundlegend auch den Hauptanteil bei der Berechnung des Likelihood
s und der Ableitungen dar.
 Weiterhin müssen für jedes Kovarianzmodell eigene Algorithmen aufgestellt
 werden, was den Enticklungsaufwand stark erhöht.
\end_layout

\begin_layout Standard
\noindent
Eine andere Möglichkeit bietet die alleinige Rückwärtsdifferentiation der
 Determinante der Kovarianzmatrix.
 Dieser Ansatz bietet einen Geschwindigkeitsvorteil und zudem den Vorteil,
 dass der Quellcode sich nur minimal ändert und damit für alle Kriging-Verfahren
 und auch Kovarianzfunktionen gilt.
 Es wird allerdings eine rückwärtsdifferenzierte Version des Cholesky Algorithmu
s benötigt.
 Für diese bestehen mittlerweile aber sehr effiziente BLAS-Implementierungen.
 Der grundlegende Ansatz ist die Bestimmung der folgenden Ableitung:
\begin_inset Formula 
\begin{align}
 & \frac{\partial\left(ln\left(det\left(\mathbf{\mathbf{\mathbf{Cov}}}\left(h_{l}\right)\right)\right)\right)}{\partial h_{l}}\label{eq:lnDetCovRuckmodus}
\end{align}

\end_inset

Wobei die Determinante das Produkt über alle quadrierten Diagonalelemente
 der Cholesky zerlegten Dreiecksmatrix 
\begin_inset Formula $LL^{T}$
\end_inset

 ist:
\begin_inset Formula 
\begin{align}
ln\left(det\left(\mathbf{\mathbf{\mathbf{Cov}}}\left(h_{l}\right)\right)\right) & =ln\left(\prod_{i}L_{i,i}^{2}\right)=2\sum ln\left(L_{i,i}\right)
\end{align}

\end_inset

Daraus ergibt sich die folgende Verkettung, welche die Cholesky Zerlegung
 berücksichtigt 
\begin_inset Formula $f_{chol}$
\end_inset


\begin_inset Formula 
\begin{align}
 & \frac{\partial\left(ln\left(det\left(f_{chol}\left(\mathbf{\mathbf{\mathbf{Cov}}}\left(h_{l}\right)\right)\right)\right)\right)}{\partial h_{l}}
\end{align}

\end_inset

Die bestehenden Abbildungen sehen wie folgt aus:
\begin_inset Formula 
\begin{align}
\mathbf{\mathbf{\mathbf{Cov}}}:\mathbb{R}\longmapsto\mathbb{R}^{n^{2}}\\
f_{chol}:\mathbb{R}^{n^{2}}\longmapsto\mathbb{R}^{n^{2}}\nonumber \\
det:\mathbb{R}^{n^{2}}\longmapsto\mathbb{R}\nonumber \\
ln:\mathbb{R}\longmapsto\mathbb{R}\nonumber 
\end{align}

\end_inset

Der Logarithmus der Determinante wird als 
\begin_inset Formula $f_{lndet}$
\end_inset

 zusammengefasst
\begin_inset Formula 
\begin{align}
 & \frac{\partial\left(f_{lndet}\left(f_{chol}\left(\mathbf{\mathbf{\mathbf{Cov}}}\left(h_{l}\right)\right)\right)\right)}{\partial h_{l}}\\
 & f_{lndet}:\mathbb{R}^{n^{2}}\longmapsto\mathbb{R}\nonumber 
\end{align}

\end_inset

es gilt also
\begin_inset Formula 
\begin{align}
f_{lndet}\circ f_{chol}\circ\mathbf{\mathbf{\mathbf{Cov}}} & :\mathbb{R}\longmapsto\mathbb{R}
\end{align}

\end_inset

daraus resultieren die Jacobi Matrizen 
\begin_inset Formula $D_{cov}$
\end_inset

 der Größe 
\begin_inset Formula $n^{2}\times1$
\end_inset

, 
\begin_inset Formula $D_{chol}$
\end_inset

 der Größe 
\begin_inset Formula $n^{2}\times n^{2}$
\end_inset

 und 
\begin_inset Formula $D_{flndet}$
\end_inset

 der Größe 
\begin_inset Formula $1\times n^{2}$
\end_inset

 wobei 
\begin_inset Formula $\mathbf{\mathbf{C_{i,j}}}$
\end_inset

 einen Eintrag der Matrix 
\begin_inset Formula $\mathbf{\mathbf{\mathbf{Cov}}}$
\end_inset

 bedeutet.
 Damit wird die gesamte Ableitung zu:
\begin_inset Formula 
\begin{align}
\frac{\partial\left(f_{lndet}\left(f_{chol}\left(\mathbf{\mathbf{\mathbf{Cov}}}\left(h_{l}\right)\right)\right)\right)}{\partial h_{l}} & =D_{flndet}D_{chol}D_{cov}\label{eq:KettenregelCholesky}\\
 & =\sum_{i}\sum_{_{j<=i}}\sum_{k}\sum_{_{m<=k}}\frac{\partial f_{lndet}}{\partial\mathbf{\mathbf{\mathbf{L_{i,j}}}}}\frac{\partial\mathbf{\mathbf{\mathbf{L_{i,j}}}}}{\partial\mathbf{\mathbf{\mathbf{C_{k,m}}}}}\frac{\partial\mathbf{\mathbf{C_{k,m}}}}{\partial h_{l}}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Es gilt nun sich zu überlegen, wie man die hier gezeigte mehrdimensionale
 Kettenregel möglichst effizient bestimmen kann.
 Berechnet man die vollständige Summe, dann wäre die Komplexität für die
 Berechnung der Ableitung bei 
\begin_inset Formula $\mathcal{O}\left(n^{4}\right)$
\end_inset

.
 Der Aufwand wäre also deutlich größer als über die Bestimmung der Inversen.
 Benötigt wird also ein Algorithmus, welcher die notwendigen Terme der mehrdimen
sionalen Kettenregel ohne große Matrizen berechnen kann.
 Als erste Vereinfachung kann man sich versuchen die einzelnen Jacobi Vektoren
 zu bestimmen.
 Der Vektor 
\begin_inset Formula $D_{cov}$
\end_inset

 entspricht einfach nur allen Einträgen der Matrix 
\begin_inset Formula $\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}$
\end_inset

 und ist im Kriging daher bekannt.
 Als nächstes kann man den Vektor 
\begin_inset Formula $D_{flndet}$
\end_inset

 bestimmen, da man die Funktion 
\begin_inset Formula $f_{lndet}$
\end_inset

 kennt:
\begin_inset Formula 
\begin{align}
D_{flndet}^{T} & =\left(\begin{array}{c}
\frac{\partial f_{lndet}}{\partial\mathbf{\mathbf{\mathbf{L_{1,1}}}}}\\
\frac{\partial f_{lndet}}{\partial\mathbf{\mathbf{\mathbf{L_{2,1}}}}}\\
\vdots\\
\frac{\partial f_{lndet}}{\partial\mathbf{\mathbf{\mathbf{L_{n-1,n}}}}}\\
\frac{\partial f_{lndet}}{\partial\mathbf{\mathbf{\mathbf{L_{n,n}}}}}
\end{array}\right)=\left(\begin{array}{c}
\frac{\partial2\sum ln\left(L_{i,i}\right)}{\partial\mathbf{\mathbf{\mathbf{L_{1,1}}}}}\\
\frac{\partial2\sum ln\left(L_{i,i}\right)}{\partial\mathbf{\mathbf{\mathbf{L_{2,1}}}}}\\
\vdots\\
\frac{\partial2\sum ln\left(L_{i,i}\right)}{\partial\mathbf{\mathbf{\mathbf{L_{n-1,n}}}}}\\
\frac{\partial2\sum ln\left(L_{i,i}\right)}{\partial\mathbf{\mathbf{\mathbf{L_{n,n}}}}}
\end{array}\right)=\left(\begin{array}{c}
\frac{2}{L_{1,1}}\\
0\\
\vdots\\
0\\
\frac{2}{L_{n,n}}
\end{array}\right)
\end{align}

\end_inset

Die Bestimmung des Vektors kann auch als Diagonalmatrix interpretiert werden
 welche sehr schnell aus der Cholesky zerlegten Matrix bestimmt werden kann.
 
\begin_inset Formula 
\begin{align}
\bar{D}_{flndet}= & \left[\begin{array}{ccc}
\frac{2}{L_{1,1}} & \cdots & 0\\
\vdots & \ddots & \vdots\\
0 & \cdots & \frac{2}{L_{n,n}}
\end{array}\right]
\end{align}

\end_inset

Auffällig ist hierbei, das der Großteil des Jacobi Vektors aus 0 Einträgen
 besteht, mit dieser Information lässt sich Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:KettenregelCholesky"

\end_inset

 stark vereinfachen, da nur noch die Einträge 
\begin_inset Formula $\frac{\partial f_{lndet}}{\partial\mathbf{\mathbf{\mathbf{L_{i,j}}}}}\neq0\left|i=j\right.$
\end_inset

 sind:
\begin_inset Formula 
\begin{align}
\frac{\partial\left(f_{lndet}\left(f_{chol}\left(\mathbf{\mathbf{\mathbf{Cov}}}\left(h_{l}\right)\right)\right)\right)}{\partial h_{l}} & =\sum_{i}\sum_{k}\sum_{_{m<=k}}\frac{\partial f_{lndet}}{\partial\mathbf{\mathbf{\mathbf{L_{i,i}}}}}\frac{\partial\mathbf{\mathbf{\mathbf{L_{i,i}}}}}{\partial\mathbf{\mathbf{\mathbf{C_{k,m}}}}}\frac{\partial\mathbf{\mathbf{C_{k,m}}}}{\partial h_{l}}\label{eq:KettenregelCholeskyReduced}
\end{align}

\end_inset

Die Komplexität liegt somit nur noch bei 
\begin_inset Formula $\mathcal{O}\left(n^{3}\right)$
\end_inset

.
 
\end_layout

\begin_layout Standard
Als nächsten Schritt muss man sich nun überlegen, wie man den mittleren
 Teil der Kettenregel (
\begin_inset Formula $\frac{\partial\mathbf{\mathbf{\mathbf{L_{i,i}}}}}{\partial\mathbf{\mathbf{\mathbf{C_{k,m}}}}}$
\end_inset

) bestimmen kann.
 Hierfür gibt es prinzipiell zwei Möglichkeiten:
\end_layout

\begin_layout Enumerate
Man geht von den Werten 
\begin_inset Formula $\frac{\partial\mathbf{\mathbf{C_{k,m}}}}{\partial h_{l}}$
\end_inset

 aus und bestimmt ausgehend von diesen die Einträge von 
\begin_inset Formula $\frac{\partial\mathbf{\mathbf{\mathbf{L_{i,i}}}}}{\partial h_{l}}$
\end_inset

 über eine vorwärts differenzierte Cholesky Zerlegung
\end_layout

\begin_layout Enumerate
Man geht von den Werten 
\begin_inset Formula $\frac{\partial f_{lndet}}{\partial\mathbf{\mathbf{\mathbf{L_{i,i}}}}}$
\end_inset

 aus und bestimmt ausgehend von diesen die Einträge von 
\begin_inset Formula $\frac{\partial f_{lndet}}{\partial\mathbf{\mathbf{\mathbf{C_{k,m}}}}}$
\end_inset

über eine rückwärts differenzierte Cholesky Zerlegung
\end_layout

\begin_layout Standard
Grundsätzlich sollten beide Vorgehensweise vom numerischen Aufwand gleichwertig
 sein.
 Da man allerdings für jeden der Hyperparameter 
\begin_inset Formula $h_{l}$
\end_inset

 die Matrix 
\begin_inset Formula $\frac{\partial\mathbf{\mathbf{C_{k,m}}}}{\partial h_{l}}$
\end_inset

 bestimmen muss und damit wiederum 
\begin_inset Formula $\frac{\partial\mathbf{\mathbf{\mathbf{L_{i,i}}}}}{\partial\mathbf{\mathbf{\mathbf{C_{k,m}}}}}$
\end_inset

, muss man also die vorwärts differenzierte Cholesky Zerlegung 
\begin_inset Formula $o$
\end_inset

-mal aufrufen.
 In Fall 2 ist dies nicht so, denn die Berechnung ist unabhängig von der
 Anzahl der Hyperparameter.
 Aus diesem Grund verspricht der rückwärtsdifferenzierte Fall einen Vorteil
 bei der Bestimmung der partiellen Ableitungen der Hyperparameter.
\end_layout

\begin_layout Standard
Der numerische Aufwand für einen solchen rückwärtsdifferenzierten Cholesky
 Algorithmus liegt bei dem ungefähr doppelten Aufwand einer normalen Cholesky
 Zerlegung 
\begin_inset CommandInset citation
LatexCommand cite
key "Smith1995"

\end_inset

.
 Das ist immer noch deutlich schneller als eine Vor- und Rückwärtssubstitution.
 Der in 
\begin_inset CommandInset citation
LatexCommand cite
key "Smith1995"

\end_inset

 beschriebene Algorithmus ist allerdings nur schwer parallelisierbar und
 auch für SIMD Architekturen nur schlecht geeignet.
 In der hier entwickelten Matrix Klasse, wurde eine SIMD-beschleunigte Version
 des von 
\begin_inset CommandInset citation
LatexCommand cite
key "Smith1995"

\end_inset

 beschriebenen Algorithmus entwickelt.
 
\end_layout

\begin_layout Standard
In der Arbeit von 
\begin_inset CommandInset citation
LatexCommand cite
key "Murray2016,Sarkka2013"

\end_inset

 werden einige moderne Varianten präsentiert, welche es ermöglichen Standard
 Level 2-3 BLAS Routinen zu verwenden.
 Diese stellen die effizientesten Methoden dar und werden folgend auch verwendet.
\end_layout

\begin_layout Subsection
Vergleich zwischen der Invertierung und der Rückwärtsdifferenzierung
\end_layout

\begin_layout Standard
Bei dem hier vorgestelltem Algorithmus handelt es sich prinzipiell nicht
 um eine klassische Rückwärtsdifferenzierung wie z.B.
 in 
\begin_inset CommandInset citation
LatexCommand cite
key "toal2009adjoint"

\end_inset

.
 Diese differenzieren die gesamte Ableitung des Likelihoods rückwärts.
 Diese Algorithmen haben jedoch den Nachteil, dass der Quellcode deutlich
 komplexer und schwerer zu warten ist, insbesondere wenn man mehrere Korrelation
sfunktionen und Verfahren anbietet.
 In beiden Fällen ist es aber nicht direkt ersichtlich, dass die Rückwärtsdiffer
enzierte Methode die schneller ist.
 Die Vermutung ist allerdings, dass die Algortihmen der Rückwärtsdifferenzierung
 weniger Operationen benötigen und sich besser beschleunigen lassen.
 Ein direkter Vergleich der benötigten Operationen innerhalb der Algorithmen
 ist allerdings so gut wie unmöglich, da meist sehr stark optimierte Bibliotheke
n wie die Intel MKL oder ATLAS Bibliothek verwendet werden.
 Diese bedienen sich oft komplexer Algorithmen wie z.B.
 den Strassen Algorithmus, welcher eine Matrix Multiplikation mit einer
 Komplexität von 
\begin_inset Formula $\mathcal{O}\left(n^{log_{2}7}\right)$
\end_inset

 berechnen kann.
 Oft werden die Algorithmen je nach Matrix Größe umgeschaltet, sodass sich
 die echte Komplexität kaum noch bestimmen lässt.
 In der Regel wird diese auch nicht dokumentiert.
 Dennoch lässt sich davon ausgehen, dass diese Bibliotheken das aktuelle
 Maximum an Geschwindigkeit darstellen, sodass eine gute und auch realistische
 Vergleichbarkeit gewährleistet ist.
 Aus diesem Grund sollen in diesem Abschnitt die Unterschiede der Verfahren
 über Benchmarks ermittelt werden.
 
\end_layout

\begin_layout Standard
Betrachtet man den Teil der Berechnung zur Bestimmung der Ableitung des
 Likelihoods nach den Hyperparameter, in dem sich die beiden Verfahren untersche
iden, so handelt es sich prinzipiell nur um Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:lnDetCovRuckmodus"

\end_inset

.
 Die analytische Ableitung ist wie folgt bestimmt:
\begin_inset Formula 
\begin{equation}
\frac{\partial\left(ln\left(det\left(\mathbf{\mathbf{\mathbf{Cov}}}\left(h_{l}\right)\right)\right)\right)}{\partial h_{l}}=\textrm{Spur}\left(\mathbf{\mathbf{Cov}}^{-1}\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}\right)
\end{equation}

\end_inset

Für beide Verfahren gilt die gleiche Ausgangssituation: Die nach den Hyperparame
tern abgeleitete Kovarianzmatrix ist bekannt 
\begin_inset Formula $\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}$
\end_inset

 und auch die Cholesky-zerlegte Matrix 
\begin_inset Formula $\mathbf{L}$
\end_inset

 ist bekannt.
\end_layout

\begin_layout Paragraph
\noindent
Ablauf Vorwärtsdifferentiation 
\end_layout

\begin_layout Enumerate
Bestimmung der differenzierten Kovarianzmatrix 
\begin_inset Formula $\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}$
\end_inset

 für jeweils einen Hyperparameter 
\begin_inset Formula $h_{l}$
\end_inset


\end_layout

\begin_layout Enumerate
Bestimmung der Cholesky Zerlegung 
\begin_inset Formula $\mathbf{L}$
\end_inset

 
\end_layout

\begin_layout Enumerate
Bestimmung von 
\begin_inset Formula $\mathbf{\mathbf{Cov}}^{-1}$
\end_inset

, da die zerlegte Matrix bekannt ist, muss noch eine Vor- und Rückwärtssubstitut
ion durchgeführt werden diese benötigt relativ genau 
\begin_inset Formula $n^{3}$
\end_inset

 Operationen.
\end_layout

\begin_layout Enumerate
Die Bestimmung der quadratischen Form 
\begin_inset Formula $\left(\vec{y}_{s}-\overrightarrow{F}\right)^{T}\mathbf{\mathbf{\mathbf{Cov}}}^{-1}\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}\mathbf{Cov}^{-1}\left(\vec{y}_{s}-\overrightarrow{F}\right)$
\end_inset


\end_layout

\begin_layout Enumerate
Das Matrixprodukt 
\begin_inset Formula $\mathbf{\mathbf{Cov}}^{-1}\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}$
\end_inset

, wobei hiervon nur die Diagonale berechnet werden muss, daher liegt diese
 Berechnung bei ca.
 
\begin_inset Formula $n^{2}$
\end_inset

 Operationen.
 Durch die Spur kann man sparen, es gibt keine BLAS Routine dafür.
 
\end_layout

\begin_layout Paragraph
\noindent
Ablauf Rückwärtsdifferentiation 
\end_layout

\begin_layout Enumerate
Bestimmung der differenzierten Kovarianzmatrix 
\begin_inset Formula $\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}$
\end_inset

 für jeweils einen Hyperparameter 
\begin_inset Formula $h_{l}$
\end_inset


\end_layout

\begin_layout Enumerate
Bestimmung der Cholesky Zerlegung 
\begin_inset Formula $\mathbf{L}$
\end_inset

 
\end_layout

\begin_layout Enumerate
Die Bestimmung der Rückwärtsdifferenzierten Cholesky Zerlegung 
\begin_inset Formula $\frac{\partial\mathbf{\mathbf{\mathbf{L_{i,i}}}}}{\partial\mathbf{\mathbf{\mathbf{C_{k,m}}}}}$
\end_inset

 inlkusive Aufstellen der Seed Matrix 
\begin_inset Formula $\mathbf{\bar{L}}$
\end_inset

 (siehe 
\begin_inset Formula $\frac{\partial f_{lndet}}{\partial\mathbf{\mathbf{\mathbf{L_{i,i}}}}}$
\end_inset

) dieses benötigt 
\begin_inset Formula $n$
\end_inset

 Operationen
\end_layout

\begin_layout Enumerate
Die Bestimmung der quadratischen Form 
\begin_inset Formula $\left(\vec{y}_{s}-\overrightarrow{F}\right)^{T}\mathbf{\mathbf{\mathbf{Cov}}}^{-1}\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}\mathbf{Cov}^{-1}\left(\vec{y}_{s}-\overrightarrow{F}\right)$
\end_inset


\end_layout

\begin_layout Enumerate
Die Bestimmung des Produkts der aus Punkt 2 berechneten Matrix und den Einträgen
 der differenzierten 
\begin_inset Formula $\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}$
\end_inset

 
\begin_inset Formula $\sim\frac{n^{2}}{2}+\frac{n}{2}$
\end_inset


\end_layout

\begin_layout Paragraph
Benchmark
\end_layout

\begin_layout Standard
Folgend wird ein zeitlicher Vergleich über ein Benchmark angestellt.
 Als Benchmark dienten zufällig erzeugte Testdaten aus der ZDT3 Funktion
 (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:ZDT3"

\end_inset

) mit jeweils 8 Parametern.
 Es wurden jeweils 10 Kriging Iterationen durchgeführt und die Zeiten für
 die Erzeugung der partiellen Ableitungen des Likelihoods gemessen.
 Berechnet wurde der Testfall auf zwei Xeon E5 2640 v3 mit insgesamt 16
 Threads.
 Für alle Berechnungen wurde die Intel MKL Bibliothek verwendet.
 
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../images/SoftwareTechnUmsetzung/BackwardBenchPartDerTimeFull.eps
	scale 55

\end_inset


\begin_inset Graphics
	filename ../images/SoftwareTechnUmsetzung/BackwardBenchPartDerTimeStep2-3.eps
	scale 55

\end_inset


\begin_inset Graphics
	filename ../images/SoftwareTechnUmsetzung/BackwardBenchPartDerTimeStep5.eps
	scale 55

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Vergleich-der-Zeiten"

\end_inset

Vergleich der Zeiten der Berechnung der partiellen Ableitungen des Likelihood-Te
rms
\end_layout

\end_inset


\end_layout

\end_inset

 Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Vergleich-der-Zeiten"

\end_inset

 zeigt die benötigte Zeit für die Erzeugung der partiellen Ableitungen.
 Der Rückwärtsmodus war in diesem Fall ca.
 1.5x schneller als der Vorwärtsmodus.
 Die folgenden Abbildungen zeigen die Zeiten der verschiedenen Schritte
 im Vergleich.
 Die Zeiten der Schritte 1 und 4 sind identisch und werden daher nicht gezeigt,
 die Ergebnisse können aber im Anhang 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Rückwärtsdifferenzierung-des-LikelihoodBenchmark"

\end_inset

 gefunden werden.
 Unterschiede können in Schritt 2-3 und Schritt 5 gesehen werden, in beiden
 Fällen ist der Rückwärtsmodus schneller.
 
\end_layout

\begin_layout Subsection
Ableitung Likelihood: Verzicht auf Inverse - Approximation 
\begin_inset CommandInset label
LatexCommand label
name "subsec:SpurApprox"

\end_inset


\end_layout

\begin_layout Standard
Wie bereits beschrieben ist es bei der Bestimmung der partiellen Ableitungen
 nach den Hyperparametern des Likelihood Terms deutlich schwieriger auf
 die Invertierung zu verzichten.
 Dies liegt an der Bestimmung der Ableitung der Determinante nach den Hyperparam
etern.
 
\begin_inset Formula 
\begin{align*}
\frac{\partial L\left(\vec{h}\right)}{\partial h_{l}}= & -\textrm{Spur}\left(\mathbf{\mathbf{Cov}}^{-1}\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}\right)+\left(\left(\vec{y}_{s}-\overrightarrow{F}\right)^{T}\mathbf{\mathbf{\mathbf{Cov}}}^{-1}\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}\mathbf{\mathbf{Cov}}^{-1}\left(\vec{y}_{s}-\overrightarrow{F}\right)\right)
\end{align*}

\end_inset

Wie bereits Spur in Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Ableitung-LikelihoodRueckMode"

\end_inset

 beschrieben, liegt die Schwierigkeit in der Berechnung der Spur.
 Die Spur einer Matrix lässt sich laut 
\begin_inset CommandInset citation
LatexCommand cite
key "Avron2011,hutchinson1989stochastic,MarkGibbs1997"

\end_inset

 statistisch schätzen:
\begin_inset Formula 
\[
Spur\left(R\right)\approx E\left[\vec{d}^{T}R\vec{d}\right]
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Spur\left(R\right)\approx\frac{1}{N}\sum\vec{d}^{T}R\vec{d}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\vec{d}=\left[\begin{array}{c}
N\left(0,1\right)\\
\vdots\\
N\left(0,1\right)
\end{array}\right]
\]

\end_inset

Die Approximation benötigt leider einen sehr großen Zufallsvektor 
\begin_inset Formula $\vec{d}$
\end_inset

 um eine ausreichende Genauigkeit zu erhalten.
 Dies macht die Methode letztlich wieder ineffizient.
 Zudem bleibt immer eine Restunsicherheit in den partiellen Ableitungen
 die sich negativ auf das Training auswirken kann.
 
\end_layout

\begin_layout Subsection
Verwendung von GPUs 
\begin_inset CommandInset label
LatexCommand label
name "sec:Verwendung-von-GPGPU"

\end_inset


\end_layout

\begin_layout Standard
Die Verwendung von GPUs (Graphical Processing Unit) zur Beschleunigung von
 intensiven Rechenoperationen findet innerhalb der wissenschaftlichen Gemeinde
 immer größere Anwendung und Zuspruch (vgl.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Cook2012"

\end_inset


\series bold
)
\series default
.
 Meistens werden solche GPUs als Zusatzkarten für Rechner angeboten und
 verfügen oftmals über eigenen schnellen onboard-Speicher.
 Der Unterschied zwischen einer konventionellen CPU und einer GPU besteht
 hauptsächlich in der Architektur der Prozessoren.
 Während CPUs bis zu ca.
 20 (nach heutigem Stand) hochgetaktete Kerne besitzen und komplexe (bis
 zu 3-Schichtige) Cache Strukturen, so sind GPUs meist mit mehreren tausend
 niedrig getakteten Kernen ausgestattet.
 
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="6">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Jahr
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
SIMD Einheiten
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Cores
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
FMA Einheiten
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Gesamt
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Intel E7-8870
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2011
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
8
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
10
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
80
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Intel Plat.
 8180
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2017
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
16
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
28
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
896
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Nvidia P100
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2017
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3584
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:CoresCPUGPU"

\end_inset

Anzahl der Rechneneinheiten für verschiedene CPUs / GPUs
\end_layout

\end_inset


\end_layout

\end_inset

Auch die Cache Struktur fällt bei GPUs deutlich simpler aus.
 Weiterhin ist die sehr direkte Anbindung des Speichers auf der Platine
 der GPU selbst oftmals ein Vorteil.
 Durch immer größer werdende SIMD (Single Instruction Multiple Data) Einheiten
 in modernen CPUs (bspw.
 AVX512 mit 512 breiten Registern) verschwindet der Unterschied allerdings
 zusehends, wie die folgende Tabelle zeigt.
 
\end_layout

\begin_layout Standard
Tabelle 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:CoresCPUGPU"

\end_inset

 zeigt zwei verschiedene CPUs von Intel und eine aktuelle GPU von NVidia.
 Vergleicht man die realen Recheneinheiten auf den CPUs, so hat diese sich
 fast verzehnfacht.
 
\begin_inset Wrap figure
lines 0
placement o
overhang 0col%
width "50col%"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../images/SoftwareTechnUmsetzung/MotherboardSchaubild.png
	scale 20

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:BusSystem"

\end_inset

Typischer Aufbau eines Bus-Systems
\end_layout

\end_inset


\end_layout

\end_inset

Auch auf programmiertechnischer Seite verschwindet der Unterschied zwischen
 CPU und GPU.
 So ist der Aufwand eine einfache Matrixoperation (wie z.B.
 eine Matrixmultiplikation) zu programmieren, die die entsprechende Hardware
 vollständig ausnutzt, zu einer Expertenaufgabe geworden.
 Dieser Umstand gilt für CPUs und GPUs gleichermaßen.
 Aus diesem Grund bieten sowohl Intel als auch NVidia zahlreiche hardwareoptimie
rte Bibliotheken für alle Arten von Rechenoperationen an.
\end_layout

\begin_layout Standard
Allerdings gibt es Unterschiede zwischen GPU und CPU bei dem Transfer von
 Daten.
 Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:BusSystem"

\end_inset

 zeigt den vereinfachten Aufbau eines Bus-Systems wie es auf aktuellen Mainboard
s zu finden ist.
 
\end_layout

\begin_layout Standard
Es soll folgend der Ablauf einer Matrix-Zerlegung auf der GPU und CPU beschriebe
n werden:
\end_layout

\begin_layout Subparagraph
CPU:
\end_layout

\begin_layout Enumerate
CPU erzeugt und belegt Matrix A im RAM (typische Transferraten von 100GB/sec)
\end_layout

\begin_layout Enumerate
CPU zerlegt Matrix A im RAM 
\end_layout

\begin_layout Subparagraph
GPU:
\end_layout

\begin_layout Enumerate
CPU erzeugt und belegt Matrix A im RAM (typische Transferraten von 100GB/sec)
\end_layout

\begin_layout Enumerate
GPU kopiert Matrix A vom RAM in den GPU-RAM über den PCIe Bus (typische
 Transferraten von 15GB/sec)
\end_layout

\begin_layout Enumerate
GPU zerlegt Matrix A im GPU-RAM (typische Transferraten von 320GB/sec)
\end_layout

\begin_layout Enumerate
GPU kopiert Matrix A zurück in den RAM (typische Transferraten von 15GB/sec)
\end_layout

\begin_layout Standard
Wie man erkennt, kann der PCIe Bus mit 15GB/sec (Stand 2017) zum Flaschenhals
 der Operation werden.
 Die Beschleunigung der Rechnung auf der Karte selbst, muss den Overhead
 des Transfers überwiegen.
 Erst dann lohnt sich der Einsatz einer solchen GPU.
 
\end_layout

\begin_layout Standard
Ob der praktische Einsatz für ein Kriging-Verfahren wie es in AutoOpti verwendet
 wird sinnvoll ist, soll innerhalb dieses Abschnittes beleuchtet werden.
 In 
\begin_inset CommandInset citation
LatexCommand cite
key "Toal2016"

\end_inset

 wird die Verwendung von GPUs innerhalb eines Kriging-Verfahren bereits
 als gewinnbringend beschrieben.
 Innerhalb dieser Arbeit wurden allerdings nur kleine Matrizen betrachtet
 (n<1000), die verwendete Bibliothek nicht beschrieben, die Overhead-Anteile
 nicht beschrieben und auch die Fließkommagenauigkeit wurde nicht angegeben.
 Dies kann von Bedeutung sein, da eine höhere Genauigkeit (von 64Bit) bei
 einigen GPUs zu massiven Leistungseinbrüchen führt.
 Weiterhin stellt sich auch die Frage, ob es während einer Optimierung möglich
 und sinnvoll ist, mehrere Trainings auf einer GPU durchzuführen.
 Folgend sollen diese Fragestellungen betrachtet werden.
\end_layout

\begin_layout Paragraph
Umgesetzte Algorithmen 
\end_layout

\begin_layout Standard
Wie bereits erwähnt, ist es nicht sinnvoll alle Algorithmen als GPU-Version
 umzusetzen, da diese durch den Transfer letztlich langsamer wären.
 Aus diesem Grund sind in der 
\begin_inset Quotes gld
\end_inset


\shape italic
CudaMatrix
\shape default

\begin_inset Quotes grd
\end_inset

 Klasse (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Matrixoperationen"

\end_inset

 ), nur die zeitkritischen Algorithmen implementiert.
 Für alle anderen wird die 
\begin_inset Quotes gld
\end_inset


\shape italic
OpenMPMatrix
\shape default

\begin_inset Quotes grd
\end_inset

-Klasse verwendet.
 Die dort implementierten Algorithmen sind: 
\end_layout

\begin_layout Itemize
Cholesky Zerlegung
\end_layout

\begin_layout Itemize
Rückwärtsdifferenzierte Cholesky Zerlegung
\end_layout

\begin_layout Itemize
Matrix Multiplikation, Addition, Subtraktion
\end_layout

\begin_layout Itemize
Lösen eines Gleichungssystem mit zerlegter Matrix
\end_layout

\begin_layout Standard
Die genaue Umsetzung ist in 
\begin_inset CommandInset citation
LatexCommand cite
key "kueppers2016,kueppers2016b,Kueppers2016c"

\end_inset

 beschrieben.
 
\end_layout

\begin_layout Paragraph*
Fließkommagenauigkeit
\end_layout

\begin_layout Standard
Innerhalb eines Kriging Verfahrens ist es praktisch unerlässlich die numerischen
 Berechnung mit doppelter Fließkommagenauigkeit (64Bit) durchzuführen.
 Aus diesem Grund sollte die Leistung der einzelnen GPU-Architekturen berücksich
tigt werden.
 In Tabelle 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Vergleich-der-Rechenleistung"

\end_inset

 sind alle NVidia Architekturen der letzten Jahre gelistet.
\begin_inset Wrap table
lines 0
placement o
overhang 0col%
width "50col%"
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="6" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Architektur
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Jahr
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
DP/SP
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Fermi
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2010
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1/2x
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Kepler
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2012
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1/3x
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Maxwell
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2014
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1/32x
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Pascal
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2016
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1/2x
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Volta
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2017
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1/2x
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:Vergleich-der-Rechenleistung"

\end_inset

Vergleich der Rechenleistung verschiedener NVidia Architekturen bei Double
 Precision (64Bit) und Single Precision (32Bit)
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Auffällig ist hier die Maxwell Architektur die eine deutlich niedrigere
 Leistung bei doppelter Genauigkeit bringt.
 Die Unterschiede liegen meist in der Prozessorarchitektur begründet, so
 haben die Kepler GPUs der Tesla Reihe alle pro SP-Core einen zusätzlich
 DP-Core.
 Daher auch das Verhältnis von 1/3.
 Die Maxwell Architektur verzichtet hingegen auf jegliche DP-Einheiten und
 kann doppelte Genauigkeit nur 
\begin_inset Quotes gld
\end_inset

emulieren
\begin_inset Quotes grd
\end_inset

.
\end_layout

\begin_layout Paragraph
Wirtschaftliche Betrachtung
\end_layout

\begin_layout Standard
Neben der reinen Rechenleistung sollten auch wirtschaftliche Aspekte Berücksicht
igt werden.
 Insbesondere spielen der Straßenpreis und auch der Stromverbrauch eine
 sehr wichtige Rolle.
 In Anhang 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Wirtschaftliche-Betrachtung-CPUGPU"

\end_inset

 ist ein tabellarischer Vergleich zwischen verschiedenen GPUs und CPUs angestell
t worden, besonders wichtig sind dabei die Werte Watt/GFlop und GFlop/Euro.
 Hier ist schnell ersichtlich, dass in beiden Punkten der Einsatz von GPUs
 rentabel ist.
 Allerdings beruht der Vergleich auf der theoretischen Rechenleistung, welche
 nicht immer erreicht werden kann.
 Die oftmals vertretene Meinung, dass viele Algorithmen aufgrund der schlechten
 Parallelisierbarkeit besser auf CPUs ausführbar sind, stimmt nur noch bedingt
 (siehe Tabelle 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:CoresCPUGPU"

\end_inset

).
 
\end_layout

\begin_layout Standard
Der Energieverbrauch pro Rechenleistung ist mittlerweile ein sehr wichtiges
 Kriterium für die Auswahl einer geeigneten CPU/GPU für einen Supercomputer.
 Dies wird sehr schnell klar, wenn man sich die leistungsstärksten Supercomputer
 ansieht (Stand Juni 2018), da diese bereits mehrere Megawatt an Leistung
 benötigen:
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="7" columns="5">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Energiebedarf
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
CPUs/GPUs
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Rechenleistung
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Standort
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Summit
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
15000kW
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
IBM Power9+Nvidia V100
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
200000 TFlop
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
USA
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
TaihuLight
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
15379kW
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Sunway SW26010
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
93014 TFlop
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
China
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Tianhe-2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
17808 kW
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Intel E5-2692+Phi 31S1P
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
33862 TFlop
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
China
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Piz Daint
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2272kW
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Intel E5-2690+Nvidia P100
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
19590 TFlop
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Schweiz
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
...
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
...
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
...
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
...
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
...
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Hazel Hen
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3200kW
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Intel E5-2680
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
7420 TFlop
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Deutschland
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:Architektur-und-Energiebedarf"

\end_inset

Architektur und Energiebedarf der Supercomputer mit der höchsten theoretischen
 Rechenleistung (Stand Juni 2018)
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Wrap figure
lines 0
placement o
overhang 0col%
width "50col%"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../images/SoftwareTechnUmsetzung/GPUSupercomputerEntw.png
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Top500GPUAnteile"

\end_inset

Entwicklung der Beschleuniger-Anteile an Supercomputern (Quelle:
\begin_inset CommandInset citation
LatexCommand cite
key "top500"

\end_inset

)
\end_layout

\end_inset


\end_layout

\end_inset

Weiterhin ist erkennbar, dass der Anteil an GPUs stark zugenommen hat, was
 bei der benötigten Leistung nachvollziehbar ist.
 Vergleicht man die Spitzenmodelle von Nvidia (V100) mit dem Platinum 8180
 von Intel, so liegt der Energiebedarf bei 0.04Watt/GFlop (V100) im Vergleich
 zu 0.134 Watt/GFlop (Platinum 8180).
 Der in TaihuLight-Supercomputer stellt hier eine Ausnahme dar und verwendet
 die in China entwickelten SunWay Prozessoren, diese Entscheidung hatte
 allerdings politisch motivierte Hintergründe (siehe 
\begin_inset CommandInset citation
LatexCommand cite
key "USRegu2015"

\end_inset

).
 Die Supercomputer in Deutschland sind vergleichsweise ineffizient was Leistung
 und Verbrauch angeht, da meist keine Beschleunigerkarten verwendet werden.
 Der globale Trend zeigt allerdings eine deutliche Zunahme, wie Abbildung
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Top500GPUAnteile"

\end_inset

 zeigt.
\end_layout

\begin_layout Paragraph*
Benchmarks
\end_layout

\begin_layout Standard
Innerhalb dieses Abschnittes sollen einige Benchmark-Ergebnisse der entwickelten
 Kriging-Software gezeigt werden.
 Im ersten Teil geht es um die Ausnutzung der theoretischen Rechenleistung,
 damit soll die Frage geklärt werden, ob es möglich ist die voll Kapazität
 einer GPU innerhalb eines Kriging Verfahrens zu nutzen.
 Danach sollen die Overhead-Anteile in Abhängigkeit der Matrixgröße, für
 ein Training gezeigt werden.
 Als letzter Punkt soll dann die Nutzung mehrerer Trainings auf einer GPU
 gezeigt werden.
 
\end_layout

\begin_layout Subparagraph*
Vergleich der theoretischen und erreichten Rechenleistung für ein Training
\end_layout

\begin_layout Standard
Folgende Tabelle zeigt die theoretische und die real gemessene Rechenleistung
 für ein Training mit 10000-15000 Stützstellen und 20 Parametern für verschieden
e Hardware-Konfigurationen.
 Die Anzahl der Trainingsschritte sowie die Ergebnisse waren jeweils identisch.
 
\end_layout

\begin_layout Standard
Als Referenz wurde ein Rechner mit 2xIntel Xeon E5-2695v2 verwendet.
 Die GPU-Benchmarks wurden auf dem NVidia-PSG-Cluster ausgeführt
\begin_inset Foot
status open

\begin_layout Plain Layout
An dieser Stelle möchte ich mich persönlich bei NVidia bedanken, für die
 Möglichkeit die Benchmarks auf dem PSG-Cluster ausführen zu dürfen.
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="6" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Name
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Theoret.
 Beschleunigung
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Erreichte Beschleunigung
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2xIntel E5-2695v2 (Ref.)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1x
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1x
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2xIntel E5-2698v3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2.55x
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2.58x
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Nvidia K40
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3.11x
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3.6x
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2xNvidia K40
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
6.22x
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
6.21x
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Nvidia K80
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
6.3x
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5.32x
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:SollIstBenchmarksGPU"

\end_inset

Theoretische und erreichte Werte der Benchmarks 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Die Ergebnisse zeigen, dass bei nahezu allen Benchmarks die theoretische
 Beschleunigung erreicht wurde.
 Die einzige Ausnahme stellt die K80 dar, diese hat allerdings zwei Prozessoren
 auf einer Platine und stellt somit einen Sonderfall dar.
 Die theoretischen Werte liegen bei dieser Karte mit hoher Wahrscheinlich
 niedriger.
 
\end_layout

\begin_layout Standard
Grundsätzlich lässt sich aber sagen, dass die Rechenkapazität der GPUs für
 ein Kriging Verfahren sehr gut Nutzbar ist.
 
\end_layout

\begin_layout Subparagraph*
Overhead-Anteile bei der Berechnung
\end_layout

\begin_layout Standard
\begin_inset Wrap figure
lines 0
placement o
overhang 0col%
width "50col%"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../images/SoftwareTechnUmsetzung/GPUOverhead.png
	scale 20

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:OverheadGPU"

\end_inset

Overhead-Anteile bei einem Kriging-Training mit einer GPU (Nvidia K6000)
\end_layout

\end_inset


\end_layout

\end_inset

Wie bereits beschrieben, muss im Vergleich zu einer CPU, ein zusätzlicher
 Transfer durchgeführt werden und eine Initialisierung durchlaufen werden.
 Beides schmälert die Rechenleistung der GPU.
 Daher soll folgend ein Benchmark gezeigt werden, in dem die Anteile der
 Initialisierung und des Transfers im Vergleich zu der Rechenzeit ins Verhältnis
 gesetzt werden.
 Bei dem Beispiel handelt es sich um dasselbe wie in Tabelle 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:SollIstBenchmarksGPU"

\end_inset

 gezeigt.
 Allerdings wurde das Benchmark auf eine NVidia-Quadro-K6000 durchgeführt.
 
\end_layout

\begin_layout Standard
In Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:OverheadGPU"

\end_inset

 sind die Ergebnisse zu sehen.
 Bis zu einer Matrixgröße von 2000x2000 steigt der prozentuale Anteil des
 Transfers und liegt bei ca.
 15% der gesamten Zeit.
 Die Initialisierung benötigt immer eine konstante Zeit und daher nimmt
 der Anteil mit steigender Größe kontinuierlich ab.
 Erst ab einer Größe von 2000x2000 kann die GPU das volle Potential nutzen.
 Weitere Entwicklungen der Hardware (PCIe 4.0 und NVLink) werden diesen Wert
 mit der Zeit allerdings verkleinern.
\end_layout

\begin_layout Paragraph*
GPU Resourcenverteilung bei parallelen Trainings
\end_layout

\begin_layout Standard
Aufgrund der besonderen Beschaffenheit von GPUs, stellt sich die Frage,
 inwiefern diese Zusatzkarten Multiprozessfähig sind.
 Besonders wichtig ist hierbei der Punkt, wie die Karten damit umgehen,
 wenn mehrere Prozesse sich die Resource teilen.
 Also bspw.
 mehrere Trainings auf einer GPU gleichzeitig ausgeführt werden.
 Die Schwierigkeit liegt dabei in der Übertragung auf die GPU und auch in
 der Ausführung der unterschiedlichen Prozess auf einer Karte, da diese
 sehr stark auf einen Prozess ausgelegt sind, welcher den GPU-Speicher linear
 durchläuft und so die volle Bandbreite des Speichers nutzen kann.
\end_layout

\begin_layout Standard
Greifen mehrere Prozesse auf unterschiedliche Bereiche des GPU-Speichers
 zu, so kann die Performance der Karte stark darunter leiden.
 Letztlich hängt dies von der Lastaufteilung innerhalb der Karte ab, welche
 von 
\begin_inset Quotes gld
\end_inset

außen
\begin_inset Quotes grd
\end_inset

 schwer beeinflussbar ist.
 Aus diesem Grund wurde ein Benchmark ausgeführt (siehe Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:MultiTrainingsBenchmark"

\end_inset

), bei dem jeweils 2 und 4 gleichzeitige Trainings bei unterschiedlicher
 Matrixgröße getestet wurden.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "75col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename ../images/SoftwareTechnUmsetzung/GPUBenchmarks.png
	lyxscale 20
	scale 10
	BoundingBox 0bp 1550bp 3565bp 3028bp
	clip

\end_inset


\end_layout

\end_inset


\begin_inset space \hspace*{\fill}
\end_inset


\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "21col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:MultiTrainingsBenchmark"

\end_inset

Vergleich von mehreren Trainings gleichzeitig auf verschiedenen CPUs und
 GPUs
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Das Ergebnis zeigt, dass die Geschwindigkeit nahezu linear mit Anzahl der
 Trainings skaliert und sich damit die Rechenkapazität der Karten noch deutlich
 besser nutzen lassen.
 Jedoch kann der GPU-RAM eine Beschränkung darstellen, so wie es bei 4 gleichzei
tigen Trainings auf einer K40 bei 15000 Stützstellen zu sehen ist.
 
\end_layout

\begin_layout Standard
Weiterhin wurden noch Tests durchgeführt, wie gut sich zwei unterschiedliche
 starke GPUs mit mehreren Trainings bedienen lassen, die Ergebnisse sind
 in Anhang 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:GPU-Resourcenverteilung-ParalleleTrainigns"

\end_inset

 zu finden.
\end_layout

\begin_layout Paragraph*
Nvidia K40 / K6000 Bios
\end_layout

\begin_layout Standard
Für die Benchmarks standen über das NVidia-PSG Cluster K40 und K80 GPUs
 zur Verfügung.
 Danach war innerhalb des Instituts für Antriebstechnik jedoch nur noch
 eine NVidia Quadro K6000 vorhanden, grundsätzlich besitzen die GPUs dieselben
 Prozessoren (GK110) und RAM (GDDR5 384Bit ECC).
 Zwischen den GPUs konnte ein Leistungsunterschied von ca.
 30% festgestellt werden.
 Der Unterschied in den Karten ist rein durch das GPU-Bios festgelegt, und
 entsteht durch den sogenannten 
\begin_inset Quotes gld
\end_inset

PowerTable
\begin_inset Quotes grd
\end_inset

, in diesem sind die elektrischen-Leistungen für die verschiedenen Taktfrequenzb
ereiche der GPU festgelegt.
 Die Werte der maximalen Leistung der K6000 liegen deutlich unter der K40,
 daher ist des der Karte nicht gestattet die volle Taktfrequenz zu erreichen.
 Durch das NVFlash-Tool ist es möglich das Bios der GPU zu manipulieren.
 Praktisch erfolgt dies durch Download des Bios, dann Editierung mit einem
 Hex-Editor und Upload.
 Bei der K6000 wurde dies durchgeführt und die Leistungswerte entsprechend
 der K40 angepasst.
 So war es möglich weitere Benchmarks mit der K6000 auf K40 Niveau durchzuführen.
\end_layout

\begin_layout Section
Laufzeit-Analysesoftware für Krigingmodelle
\begin_inset CommandInset label
LatexCommand label
name "sec:Laufzeit-Analysesoftware-für-Kri"

\end_inset


\end_layout

\begin_layout Standard
Während einer Optimierung werden mehrere Ersatzmodelle trainiert, wobei
 das Training sehr häufig durchgeführt wird.
 Aus diesem Grund ist es von großer Bedeutung, die Ersatzmodelle während
 einer Optimierung stetig zu überwachen.
 Besonderer Wert sollte dabei auf folgende Punkte gelegt werden:
\end_layout

\begin_layout Itemize
Güte der einzelnen Ersatzmodelle 
\end_layout

\begin_layout Itemize
Trainingszeit
\end_layout

\begin_layout Itemize
Evtl.
 Fehler in den Daten oder in der Prozesskette
\end_layout

\begin_layout Standard
Um eine solche Überwachung übersichtlich zu gestalten, wurde im Rahmen dieser
 Arbeit eine Software entwickelt, welche den aktuellen Stand der Ersatzmodelle
 und die Entwicklung grafisch darstellt.
 Das Programm wurde in der Programmiersprache Python geschrieben und erzeugt
 nach Ausführung eine PDF Datei.
 Folgend sollen einige der wichtigsten grafischen Ausgaben gezeigt und deren
 Einsatz erläutert werden.
 Als Beispiel wird dafür das Mukoko Projekt verwendet, welches in Kapitel
 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Reale-Turbomaschinen-Optimierung"

\end_inset

 noch ausführlicher beschrieben wird.
\end_layout

\begin_layout Subsection*
Vorhersagefehler
\end_layout

\begin_layout Standard
\begin_inset Wrap figure
lines 13
placement o
overhang 0in
width "50col%"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../images/khonprediction.pdf
	scale 70
	BoundingBox 0bp 0bp 563bp 376bp
	clip

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:KhonFehlerVorhersage"

\end_inset

Exemplarische Ausgabe eines vorhergesagten Fehlers der maximalen mechanischen
 Dehnung eines Rotors.
 
\end_layout

\end_inset


\end_layout

\end_inset

Eine einfache Möglichkeit die Qualität der Ersatzmodelle zu bestimmen ist
 die Überprüfung der Differenz zwischen Vorhersage und realen Werten.
 Da der Optimierungsalgorithmus aber ein exploratives Vorgehen (siehe Kapitel
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:EVG"

\end_inset

) wählen kann, ist es möglich, dass dieser bewusst Vorhersagen mit hoher
 vorhergesagter Standardabweichung auswählt.
 Entsprechend sollte auch der Vorhersagefehler an solchen Stellen größer
 sein.
 Daher ist diese Art der Überprüfung sehr ungenau und macht prinzipiell
 nur über lange Zeiträume Sinn.
 Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:KhonFehlerVorhersage"

\end_inset

 zeigt den typischen Verlauf eines solchen Vorhersagefehlers.
 In blau dargestellt sind die Vorhersagen der Stützstellen und in rot die
 nachgerechneten Werte.
 Die angezeigten Fehlerbalken entsprechen der vorhergesagten Standardabweichung.
 Die X-Achse stellt die jeweilige Optimierungsiteration dar.
 Die grüne Kurve beschreibt die absolute Differenz zwischen Vorhersage und
 realem Wert.
 In dieser Abbildung ist erkennbar, dass zu anfang der Optimierung die vorherges
agte Standardabweichung zu hoch ist, da nahzu keiner der echten Werte innerhalb
 der Fehlerbalken liegt.
 Erst nach ca.
 40 Iterationen ist eine Besserung erkennbar.
\end_layout

\begin_layout Subsection*
Zeitlicher Verlauf des Likelihood-Werts
\end_layout

\begin_layout Standard
Der Verlauf des Likelihood-Werts ist eine sehr gute Möglichkeit das Training
 der Ersatzmodelle zu begutachten, sowie fehlerhafte Daten aufzudecken.
 In Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:KhonGobalConvergence"

\end_inset

 sind zwei verschiedene Plots unterschiedlicher Ersatzmodelle derselben
 Optimierung gezeigt.
 Auf der Ordinate ist der Likelihood-Wert aufgetragen, wobei ein möglichst
 kleiner Wert gut ist.
 Auf der Abszisse ist der Iterationsschritt der Optimierung dargestellt.
 Die roten Punkte stellen diejenigen Optimierungsschritt dar, in denen das
 Training noch nicht den 
\begin_inset Quotes gld
\end_inset


\shape italic
Restart
\shape default

\begin_inset Quotes grd
\end_inset

 Modus (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:UltraRestart"

\end_inset

) verwendet hat.
 Solange dieser Plot noch rote Punkte aufweist, kann davon ausgegangen werden,
 dass die Hyperparameter der Ersatzmodelle noch nicht optimal eingestellt
 sind.
 
\end_layout

\begin_layout Standard
Weiterhin lassen sich auch Aussagen über die Güte der Daten anhand des Kurvenver
laufs treffen.
 In Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:KhonGobalConvergence"

\end_inset

 rechts, ist ab Iteration 1000 ein Ausreißer im Verlauf des Likelihood-Plots
 zu sehen.
 Dieser Ausreißer wurde während der laufenden Optimierung bemerkt und es
 konnte ein Fehler in den Daten festgestellt werden.
 Dieser resultierte aus einer Prozesskettenänderung während der Laufzeit
 und führet zu fehlerhaften Daten.
 Der Fehler konnte während der Laufzeit behoben werden und die Optimierung
 mit wenig Zeitverlust fortgesetzt werden.
 Ohne diese grafische Darstellung wäre es in der damaligen Optimierung zu
 einem erheblichen Zeitverlust gekommen.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../images/SoftwareTechnUmsetzung/Mukoko/khon_global_convergence1.png
	scale 70

\end_inset


\begin_inset Graphics
	filename ../images/SoftwareTechnUmsetzung/Mukoko/khon_global_convergence12.png
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:KhonGobalConvergence"

\end_inset

Verlauf von zwei Ersatzmodellen der Mukoko Optimierung, wobei das rechte
 Ersatzmodell fehlerhafte Daten bekam
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection*
Hyperparameter auf Plausibilität überprüfen
\end_layout

\begin_layout Standard
\begin_inset Wrap figure
lines 0
placement o
overhang 0col%
width "50col%"
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../images/SoftwareTechnUmsetzung/Mukoko/matrix.png
	scale 30

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Hyperparameter-Matrix-aus-einer"

\end_inset

Hyperparameter-Matrix aus einer laufenden Optimierung
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset

Die eingestellten Hyperparameter von allen Ersatzmodellen während einer
 Optimierung zu überprüfen ist aufgrund der bloßen Anzahl bereits sehr schwierig.
 Betrachtet man bspw.
 die Mukoko Optimierung, so wurden 38 Ersatzmodelle verwendung und 158 Parameter
, was zu über 6000 Hyperparametern führt.
 Dennoch ist es zumindest möglich eine Plausibilitäts-Überprüfung durchzuführen.
 Hierfür müssen die Optimierungsparameter und auch die Ersatzmodelle sinnvoll
 numeriert werden.
 Bspw.
 sollten alle Parameter von einem Rotor in einer Reihe vorkommen oder die
 Aerodynamischen und Strukturmechanischen Ersatzmodelle jeweils in einer
 Gruppierung sein.
 Typischerweise wird eine solche Gruppierung naturgemäß von den Anwendern
 gewählt, da diese oft die übersichtlichste Darstellung bietet.
\end_layout

\begin_layout Standard
Versteht man die Hyperparameter eines Ersatzmodells als eine 
\begin_inset Quotes gld
\end_inset

Gewichtung
\begin_inset Quotes grd
\end_inset

 des Parameters, so kann man diese nach Größe einfärben.
 In dem gewählten Plot, stellt grün einen hohen Wert dar und rot einen sehr
 niedrigen.
 Damit lässt sich eine grafische Matrix erzeugen wie sie exemplarisch in
 Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Hyperparameter-Matrix-aus-einer"

\end_inset

 gezeigt wird.
 Innerhalb dieses Plots sind grüne und rote/gelbe Blöcke zu erkennen.
 Bspw.
 sieht man, dass die Statoren 1&2 für die Strukturmechanik keine Rolle zu
 spielen scheinen.
 Diese Information ist plausibel, da keine strukturmechanische Bewertung
 der Statoren durchgeführt wurde.
 Weiterhin kann man zwischen Rotor 1 und Rotor 2 alternierende grüne/rote
 Blöcke im Bereich der strukturmechnischen Ersatzmodelle erkennen.
 Auch diese Information ist plausibel, da die freien Variablen für Rotor
 1 natürlich nur einen sehr geringen Einfluss auf die strukturmechanischen
 Ergebnisse von Rotor 2 haben sollten.
 
\end_layout

\begin_layout Standard
Mithilfe dieser einfachen Informationen ist es zumindest grob möglich, die
 Plausibilität der Ersatzmodelle auf einfache Weise zu überprüfen.
 
\end_layout

\begin_layout Subparagraph*
Hyperparameter Co-Kriging 
\end_layout

\begin_layout Standard
Im Falle eines Co-Kriging Modells existieren mehrere Gütestufen und damit
 auch mehrere Hyperparametersätze.
 Für den gezeigten Matrix-Plot möchte man allerdings nur einen zusammengesetzten
 Satz sehen.
 Dieser soll den Einfluss eines Parameters auf die höchste Gütestufe grob
 abschätzen.
 Dabei sollen neben der eigentlichen Größe der Hyperparameter auch der Skalierun
gsfaktor und die Prozessvarianzen berücksichtigt werden.
 Im Folgenden soll eine Möglichkeit gezeigt werden, diese grafisch zusammenzufas
sen:
\end_layout

\begin_layout Standard
Angenommen alle Parameter außer dem betrachteten Parameter spielen keine
 Rolle, dann vereinfacht sich die Gauss-Korrelations-Formel für zwei Gütestufen
 (siehe Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:KovarianzfunktionenCoKrigingGauss"

\end_inset

) zu:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
cov_{1,1}\left(x_{1},x_{2}\right)=a^{2}\sigma_{2}^{2}e^{-e^{\theta_{2}}\left|x_{1}-x_{2}\right|^{2}}+\sigma_{diff}^{2}e^{-e^{\theta_{diff}}\left|x_{1}-x_{2}\right|^{2}}
\]

\end_inset


\end_layout

\begin_layout Standard
Weiterhin wird von einem mittlerem Abstand 
\begin_inset Formula $\left|x_{1}-x_{2}\right|=1$
\end_inset

 ausgegangen.
 Diese Annahme ist von der Größenordnung in der hier verwendeten Implementierung
 sinnvoll, da alle Koordinaten auf einen Erwartungswert von 0 und eine Standarda
bweichung von 1 normiert wurden.
 
\begin_inset Formula 
\[
cov\left(x_{1},x_{2}\right)=a^{2}\sigma_{l}^{2}e^{-e^{\theta_{l}}}+\sigma_{err}^{2}e^{-e^{\theta_{err}}}
\]

\end_inset


\end_layout

\begin_layout Standard
Die Gesamtvarianz des Modells liegt bei:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\sigma_{ges}^{2}=a^{2}\sigma_{l}^{2}+\sigma_{err}^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
Die Korrelation wird hier als sinnvolleres Maß als die Kovarianz angesehen,
 da der Wertebereich beschränkt ist.
 Die Korrelation ergibt sich wie folgt:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
corr_{ges}\left(x_{1},x_{2}\right)=\frac{cov\left(x_{1},x_{2}\right)}{\sigma_{ges}^{2}}=\frac{a^{2}\sigma_{l}^{2}e^{-e^{\theta_{l}}}+\sigma_{err}^{2}e^{-e^{\theta_{err}}}}{a^{2}\sigma_{l}^{2}+\sigma_{err}^{2}}
\]

\end_inset


\end_layout

\begin_layout Standard
Diese Formel stellt eine grobe Abschätzung für den Einfluss eines freien
 Parameters auf die gesamte Kovarianzfunktion dar und lässt sich grafisch
 auswerten.
 Es werden dabei der Skalierungsfaktor, die Varianzen und die Hyperparameter
 der Kovarianzfunktion berücksichtigt.
 Die Einteilung der Farben muss allerdings kalibriert werden, ist dann aber
 für viele Anwendungen gültig.
 
\end_layout

\begin_layout Paragraph*
Anteile der Differenz- und Low-Fidelity-Lovarianzfunktion 
\end_layout

\begin_layout Standard
Im Falle einer Multifidelity Optimierung ist oft von Interesse, wie stark
 die verschiedenen Gütestufen in das Co-Kriging Modell einfließen.
 Von Anwenderseite ist ein einfacher Prozentwert wünschenswert, da dieser
 einfach zu interpretieren ist.
 Eine Möglichkeit der Abschätzung eines solchen prozentualen Anteils ist
 es von einer vollen Korrelation auszugehen und die Anteile der Kovarianz
 hoher Güte im Verhältnis der Kovarianz niedriger Güte.
 Betrachtet man hierfür den Teil 
\begin_inset Formula $cov_{1,1}$
\end_inset

 und 
\begin_inset Formula $cov_{2,2}$
\end_inset

 von Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:KovarianzfunktionenCoKrigingGauss"

\end_inset

 und geht weiterhin von einer vollen Korrelation 
\begin_inset Formula $c_{2}\left(\vec{h}\right)=1$
\end_inset

, 
\begin_inset Formula $c_{diff}\left(\vec{h}\right)=1$
\end_inset

 aus und vernachlässigt den Rauschterm 
\begin_inset Formula $\lambda_{diff}$
\end_inset

, so ergibt sich:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
cov_{1,1}\left(\vec{h}=0\right)= & a^{2}\sigma_{2}^{2}+\sigma_{diff}^{2}\\
cov_{2,2}\left(\vec{h}=0\right)= & a^{2}\sigma_{2}^{2}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Setzt man die beiden Terme ins Verhältnis 
\begin_inset Formula $LF_{perc}=\frac{a^{2}\sigma_{2}^{2}}{a^{2}\sigma_{2}^{2}+\sigma_{diff}^{2}}$
\end_inset

 so erhält man eine einfache Abschätzung des Anteils der Kovarianzfunktion
 niedriger Güte 
\begin_inset Formula $cov_{2,2}$
\end_inset

 an der Kovarianz hoher Güte 
\begin_inset Formula $cov_{1,1}$
\end_inset

 bei voller Korrelation.
 Geht man bspw.
 von den Extremfällen aus:
\end_layout

\begin_layout Enumerate
Hohe und niedrige Güte unkorreliert
\end_layout

\begin_layout Enumerate
Hohe und niedrige Güte identisch
\end_layout

\begin_layout Standard
Ergeben sich folgende Werte:
\end_layout

\begin_layout Enumerate
Dieser Fall wird beim Training durch den Skalierungsfaktor gelöst, dieser
 wird auf Null gesetzt und damit eine vollständige Unkorreliertheit erreicht.
 Der Anteil der Kovarianzfunktion niedriger Güte wäre dann: 
\begin_inset Formula $LF_{perc}=\frac{0\sigma_{2}^{2}}{0\sigma_{2}^{2}+\sigma_{diff}^{2}}=0$
\end_inset

 
\end_layout

\begin_layout Enumerate
Sind beide Funktionen identisch, so wird die Differenzkovarianzfunktion
 nicht benötigt und im Training durch 
\begin_inset Formula $\sigma_{diff}^{2}=0$
\end_inset

 ausgeschaltet.
 Der Anteil der Kovarianzfunktion niedriger Güte wäre dann: 
\begin_inset Formula $LF_{perc}=\frac{a^{2}\sigma_{2}^{2}}{a^{2}\sigma_{2}^{2}+0}=1$
\end_inset


\end_layout

\begin_layout Standard
Die Gewichtung der beiden Kovarianzfunktionen durch die Hyperparameter 
\begin_inset Formula $\vec{\theta}\in\mathbb{R^{\textrm{k}}}$
\end_inset

 (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Kovarianz-parametrisiertes-Model"

\end_inset

) werden damit allerdings nicht dargestellt.
 Dennoch kann diese Art der Darstellung eine einfache und schnelle Methode
 sein, um einen Eindruck der Gewichtungen untereinander zu bekommen.
 In Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:ASME-Veröffentlichung:-Optimieru"

\end_inset

 wird ein erfolgreiches Beispiel aus einer Optimierung eines transsonischen
 Verdichters gezeigt.
 Bei einigen Ersatzmodellen dieser Optimierung war bekannt, dass einige
 Daten niedriger Güte keinen Korrelation zu den Daten hoher Güte aufweisen
 können.
 Dies konnte in der entsprechenden Grafik (siehe Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Anteile-der-Kovarianzfunktionen"

\end_inset

 - Ersatzmodell Nummer 9) erkannt werden.
 
\end_layout

\end_body
\end_document
