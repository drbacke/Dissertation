#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass dlrreport
\use_default_options true
\maintain_unincluded_children false
\language ngerman
\language_package default
\inputencoding utf8
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language german
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Chapter
Implementierung der DLR-Kriging-Verfahren 
\begin_inset CommandInset label
LatexCommand label
name "chap:Implementierung-der-DLR-Kriging-"

\end_inset


\end_layout

\begin_layout Standard
In diesem Kapitel wird die Implementierung der MultiFidelity-Verfahren (siehe
 Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Multifidelity-Optimierungsstrate"

\end_inset

 und 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Die-Kriging-Verfahren"

\end_inset

) in die AutoOpti-Software erläutert.
 Dabei werden im ersten Teil die verwendete Modellierung der Kovarianzfunktion
 und auch die Behandlung von verrauschten Funktionen beschrieben.
 Weiterhin wird eine mögliche Regularisierung der Kovarianzmatrix beschrieben.
 Darauffolgend wird das Training der Kriging-Modelle mithilfe verschiedener
 Minimierungsverfahren beschrieben.
 Das beschriebene RPROP-Minimierungsverfahren ist besonders gut für die
 Problemstellung geeignet.
 Weiterhin wird eine auf das Co-Kriging angepasste Version dieses Verfahrens
 aufgezeigt.
\end_layout

\begin_layout Standard
Nach Beschreibung des Trainings, wird ein Vergleich des hier entwickelten
 Kriging-Verfahrens zu anderen Verfahren angestellt.
 
\end_layout

\begin_layout Standard
Da die Verwendung eines Kriging-Verfahrens innerhalb einer größeren Optimierung
 numerisch sehr aufwendig ist, behandelt ein großer Abschnitt einige Möglichkeit
en die numerischer Effizienz zu steigern.
 Im Vergleich zu Standard-Implementierungen wie Sie z.B.
 in Matlab vorzufinden sind, konnte eine deutliche Effizienzsteigerung erreicht
 werden.
 Besonderes Augenmerk liegt hierbei auf einer sehr großen Anzahl an Stützstellen
 und sehr vielen Parametern.
\end_layout

\begin_layout Standard
Als letzter Punkt wird eine Analysesoftware vorgestellt, mit dieser ist
 es möglich während einer laufenden Optimierungen die Ersatzmodelle auf
 Plausibilität und Effizienz zu überprüfen und evtl.
 Fehler aufzudecken.
\end_layout

\begin_layout Section
Modellierung der Kovarianz- und Korrelationsfunktion 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Kovarianzmatrix"

\end_inset


\end_layout

\begin_layout Standard
In Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Die-Kriging-Verfahren"

\end_inset

 wurden die verschiedenen Kriging-Verfahren beschrieben.
 Innerhalb dieses Kapitels wurden die Begriffe der Kovarianzmatrix und des
 Kovarianzvektors verwendet.
 Um diese aufstellen zu können, ist eine Kovarianzfunktion in der Form 
\begin_inset Formula $cov\left(Z(\vec{x}_{1}),Z(\vec{x_{2}})\right)$
\end_inset

 nötig, wobei 
\begin_inset Formula $\vec{x}_{1},\vec{x}_{2}$
\end_inset

 die Orte von bekannten Stützstellen beschreiben.
 Da in der praktischen Anwendung der reale Zufallsprozess 
\begin_inset Formula $Z(\vec{x})$
\end_inset

 nicht bekannt ist und damit auch nicht die Kovarianzfunktion, bedient man
 sich parametrisierten Kovarianzmodellen in der Form 
\begin_inset Formula $cov\left(\vec{x}_{1},\vec{x_{2}}\right)$
\end_inset

.
 
\end_layout

\begin_layout Standard
Diese Funktionen müssen jedem möglichen Punktepaar eine Kovarianz zuordnen.
 Weiterhin muss die daraus resultierende Matrix positiv Definit und symmetrisch
 sein, was die Wahl einer geeigneten Funktion erschwert.
 Das folgende Beispiel zeigt eine beispielhafte Kovarianzmatrix 
\begin_inset Formula $\mathbf{\mathbf{Cov\in\mathbb{R^{\mathrm{n_{all}\times n_{all}}}}}}$
\end_inset

 für vier verschiedene Samples 
\begin_inset Formula $y_{i}\left(\vec{x}\right)$
\end_inset

 der jeweiligen Gütestufe 
\begin_inset Formula $i\in\left\{ 1,...,s\right\} $
\end_inset

 :
\begin_inset Formula 
\begin{equation}
\mathbf{Cov}=\left[\begin{array}{c|cccc}
 & y_{0}\left(\vec{x}_{1}\right) & y_{0}\left(\vec{x}_{2}\right) & y_{1}\left(\vec{x}_{3}\right) & y_{1}\left(\vec{x}_{4}\right)\\
\hline y_{0}\left(\vec{x}_{1}\right) & cov\left(\vec{x}_{1},\vec{x}_{1}\right) & cov\left(\vec{x}_{1},\vec{x}_{2}\right) & cov\left(\vec{x}_{1},\vec{x}_{3}\right) & cov\left(\vec{x}_{1},\vec{x}_{4}\right)\\
y_{0}\left(\vec{x}_{2}\right) & cov\left(\vec{x}_{2},\vec{x}_{1}\right) & cov\left(\vec{x}_{2},\vec{x}_{2}\right) & cov\left(\vec{x}_{2},\vec{x}_{3}\right) & cov\left(\vec{x}_{2},\vec{x}_{4}\right)\\
y_{1}\left(\vec{x}_{3}\right) & cov\left(\vec{x}_{3},\vec{x}_{1}\right) & cov\left(\vec{x}_{3},\vec{x}_{2}\right) & cov\left(\vec{x}_{3},\vec{x}_{3}\right) & cov\left(\vec{x}_{3},\vec{x}_{4}\right)\\
y_{1}\left(\vec{x}_{4}\right) & cov\left(\vec{x}_{4},\vec{x}_{1}\right) & cov\left(\vec{x}_{4},\vec{x}_{2}\right) & cov\left(\vec{x}_{4},\vec{x}_{3}\right) & cov\left(\vec{x}_{4},\vec{x}_{4}\right)
\end{array}\right]\label{eq:KovarianzmatrixBeispiel}
\end{equation}

\end_inset

Um ein solches Modell praktisch nutzbar zu machen, müssen drei verschiedene
 Problemstellungen behandelt werden:
\end_layout

\begin_layout Enumerate
Die Kovarianzfunktion darf nicht durch die absolute Lage im Raum 
\begin_inset Formula $\left(\vec{x}_{1},\vec{x_{2}}\right)$
\end_inset

, sondern muss durch den Verbindungsvektor 
\begin_inset Formula $\vec{h}=\vec{x}_{1}-\vec{x_{2}}$
\end_inset

 beschrieben werden
\end_layout

\begin_layout Enumerate
Es wird ein parametrisiertes Modell für die Kovarianzfunktion benötigt,
 welches zu einer positiv definiten und symmetrischen Matrix führt.
\end_layout

\begin_layout Enumerate
Die darin verwendeten Parameter, im Folgenden Hyperparameter genannt, müssen
 in einem gradientenbasierten Trainingsverfahren nutzbar sein.
\end_layout

\begin_layout Standard
Diese Problemstellungen werden in den folgenden drei Abschnitten behandelt.
\end_layout

\begin_layout Subsection
Ortsabhängigkeit Kovarianzfunktion 
\begin_inset CommandInset label
LatexCommand label
name "sec:Variogramm"

\end_inset


\end_layout

\begin_layout Standard
In diesem Abschnitt wird der Begriff des Variogramms und des Kovariogramms
 erklärt (siehe 
\begin_inset CommandInset citation
LatexCommand cite
key "matheron1963principles"

\end_inset

).
 Diese stellen die Basis für die Kovarianzmodellfunktionen dar und sind
 somit zentraler Bestandteil des Kriging Verfahrens.
 Sei 
\begin_inset Formula $Z\left(\vec{x}\right)$
\end_inset

 ein räumlicher Zufallsprozess, so ist das Variogramm 
\begin_inset Formula $2\gamma\left(\vec{x}_{1},\vec{x}_{2}\right)$
\end_inset

, 
\begin_inset Formula $\vec{x}_{1},\vec{x}_{2}\in\mathbb{R^{\textrm{k}}}$
\end_inset

 definiert über:
\begin_inset Formula 
\begin{align}
2\gamma\left(\vec{x}_{1},\vec{x}_{2}\right) & \coloneqq var\left[Z\left(\vec{x}_{1}\right)-Z\left(\vec{x}_{2}\right)\right]\\
 & =E\left[\left(\left(Z\left(\vec{x}_{1}\right)-Z\left(\vec{x}_{2}\right)\right)-E\left[Z\left(\vec{x}_{1}\right)-Z\left(\vec{x}_{2}\right)\right]\right)^{2}\right]\nonumber \\
 & =E\left[\left(\left(Z\left(\vec{x}_{1}\right)-E\left[Z\left(\vec{x}_{1}\right)\right]\right)-\left(Z\left(\vec{x}_{2}\right)-E\left[Z\left(\vec{x}_{2}\right)\right]\right)\right)^{2}\right]\nonumber 
\end{align}

\end_inset

Weiterhin wird das Kovariogramm wie folgt definiert:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
cov\left(\vec{x}_{1},\vec{x}_{2}\right)\coloneqq\frac{1}{2}var\left[Z\left(\vec{x_{1}}\right)\right]+\frac{1}{2}var\left[Z\left(\vec{x_{2}}\right)\right]-\gamma\left(\vec{x}_{1},\vec{x}_{2}\right)
\end{equation}

\end_inset

Einfacher formuliert beschreibt das Variogramm und auch das Kovariogramm
 die räumliche Abhängigkeit eines Punktes zu Nachbarpunkten.
 
\begin_inset Formula $\gamma\left(\vec{x}_{1},\vec{x}_{2}\right)$
\end_inset

 wird als Semivariogramm bezeichnet.
 Trifft man die Annahme, dass das Zufallsfeld schwach stationär ist, dann
 gilt (siehe 
\begin_inset CommandInset citation
LatexCommand cite
key "Ozkaya2014"

\end_inset

): 
\begin_inset Formula 
\begin{align}
E\left[Z\left(\vec{x}\right)\right] & =\mu,\forall\vec{x}\in\mathbb{R^{\textrm{k}}}\label{eq:OrtsAbhKovStationärE}
\end{align}

\end_inset

Weiterhin gilt dann, dass die Kovarianz nur noch abhängig von dem Verschiebevekt
or 
\begin_inset Formula $\vec{h}\in\mathbb{R^{\textrm{k}}};\vec{h}=\vec{x}_{1}-\vec{x}_{2}$
\end_inset

 ist:
\begin_inset Formula 
\begin{align}
cov\left(\vec{h}\right) & \coloneqq cov\left(\vec{x},\vec{x}+\vec{h}\right)\label{eq:OrtsAbhKovStationärcov}
\end{align}

\end_inset

Unter Berücksichtigung von Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:OrtsAbhKovStationärE"

\end_inset

 und Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:OrtsAbhKovStationärcov"

\end_inset

 folgt dann für die gesuchte Kovarianzfunktion: 
\begin_inset Formula 
\begin{equation}
cov\left(\vec{h}\right)=cov\left(\vec{0}\right)-2\gamma\left(\vec{h}\right)=\sigma^{2}-2\gamma\left(\vec{h}\right)\label{eq:KovariogrammGrundformel}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Wobei 
\begin_inset Formula $cov\left(\vec{0}\right)=\sigma^{2}$
\end_inset

 der stationären Varianz des Prozesses (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:MinimierungsverfahrenTraining"

\end_inset

) entspricht.
 Der Beweis für Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:KovariogrammGrundformel"

\end_inset

 ist in Anhang zu finden.
 Die Modellierung von 
\begin_inset Formula $\gamma\left(\vec{h}\right)$
\end_inset

 wird in Abschnitt 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Kovarianz-parametrisiertes-Model"

\end_inset

 behandelt.
 
\end_layout

\begin_layout Subsection
Kovarianz parametrisiertes Modell
\begin_inset CommandInset label
LatexCommand label
name "subsec:Kovarianz-parametrisiertes-Model"

\end_inset


\end_layout

\begin_layout Standard
Wie bereits beschrieben, wird für das Kriging Verfahren ein parametrisches
 Kovarianz-Modell benötigt.
 Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:KovariogrammGrundformel"

\end_inset

 stellt die Basis für ein solches Modell dar.
 Um diese Gleichung in einem realen Modell anwenden zu können, sollte man
 sich vorerst ein typisches Kovariogramm anschauen.
 In Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Beispielhaftes-VarioKovariogramm"

\end_inset

 wird ein solches Kovariogramm gezeigt.
 Der Einfachheit halber beschränkt sich das gezeigte Kovariogramm auf eine
 räumliche Dimension 
\begin_inset Formula $\vec{x},\vec{h}\in\mathbb{R^{\textrm{k}}};k=1$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Wrap figure
lines 16
placement o
overhang 0in
width "50col%"
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../images/KrigingKapitel/KoVariogramm.eps
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Beispielhaftes Kovariogramm
\begin_inset CommandInset label
LatexCommand label
name "fig:Beispielhaftes-VarioKovariogramm"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset

Auf der X-Achse ist die räumliche Distanz und auf der Y-Achse die Kovarianz
 
\begin_inset Formula $cov\left(\vec{h}\right)$
\end_inset

 aufgetragen, diese nimmt mit steigender Distanz in der Regel ab.
 
\end_layout

\begin_layout Standard
Empirisch ist oftmals zu beobachten, dass das Kovariogramm bei 
\begin_inset Formula $\vec{h}=0$
\end_inset

 springt.
 Dieser Wert 
\begin_inset Formula $\lambda\in\mathbb{R}$
\end_inset

 wird als 
\begin_inset Quotes gld
\end_inset

Nugget
\begin_inset Quotes grd
\end_inset

 bezeichnet und entspricht einem ortsunabhängigen Rauschen.
 Um dies zu modellieren, wird eine eine Sprungfunktion 
\begin_inset Formula $\delta$
\end_inset

 definiert:
\begin_inset Formula 
\[
\delta\left(\vec{h}\right)=\begin{cases}
1 & falls\,\vec{h}=\vec{0}\\
0 & sonst
\end{cases}
\]

\end_inset


\end_layout

\begin_layout Standard
Die Summe 
\begin_inset Formula $\sigma^{2}+\lambda$
\end_inset

 (auch 
\begin_inset Quotes gld
\end_inset

Sill
\begin_inset Quotes grd
\end_inset

 genannt) ist gleichzusetzen mit der Gesamtvarianz des stochastischen Prozesses
 selbst und der eingezeichnete Wert 
\begin_inset Formula $\sigma^{2}$
\end_inset

 wird als 
\begin_inset Quotes gld
\end_inset

partial Sill
\begin_inset Quotes grd
\end_inset

 bezeichnet.
 Damit lässt sich Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:KovariogrammGrundformel"

\end_inset

 umformuliert zu:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
cov\left(\vec{h}\right)=\sigma^{2}+\lambda\delta\left(\vec{h}\right)-2\gamma\left(\vec{h}\right)\label{eq:KovarianzmodellAllgemein}
\end{equation}

\end_inset


\end_layout

\begin_layout Paragraph*
Überleitung Modellfunktion
\end_layout

\begin_layout Standard
Die Bestimmung der Varianz 
\begin_inset Formula $\sigma^{2}$
\end_inset

 und des Nuggets 
\begin_inset Formula $\lambda$
\end_inset

 innerhalb des Kriging Modells, werden mithilfe eines Trainingsverfahrens
 geschätzt.
 Diese werden in Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:MinimierungsverfahrenTraining"

\end_inset

 beschrieben.
\end_layout

\begin_layout Standard
Für die Variogrammfunktion 
\begin_inset Formula $\gamma\left(\vec{h}\right)$
\end_inset

 muss allerdings noch ein geeignetes Modell gefunden werden.
 Eine Möglichkeit besteht in der Erzeugung eines empirischen Variogramms
 (siehe 
\begin_inset CommandInset citation
LatexCommand cite
key "Cressie1993"

\end_inset

), dieses Verfahren liefert für die Abstände bekannter Stützstellen den
 entsprechenden räumlichen Zusammenhang und ist als nicht parametrisches
 Verfahren einzuordnen.
 Diese Art von Verfahren benötigen aber eine sehr große Anzahl an Stützstellen,
 um plausible Variogramme zu liefern.
 Dafür benötigen diese keinerlei Annahmen über den Verlauf des Variogramms
 über der Distanz.
 
\end_layout

\begin_layout Standard
Typischerweise greift man aber auf parametrisierte Modellfunktionen zurück,
 welche an die vorhandenen Stützstellen bestmöglich angepasst werden.
 Für diese parametrisierten Modellfunktionen wird ein typischer Verlauf
 einer Variogrammfunktion angenommen und die Parameter so gewählt, dass
 die Funktion bestmöglich an die vorhanden Stützstellen angepasst wird.
 Dadurch kommt diese Art des Verfahrens mit weniger Stützstellen aus, als
 eine empirische Schätzung, ist dafür allerdings eingeschränkter was die
 Form der Funktion angeht.
 Diese Funktionen müssen allerdings positiv semidefinit sein (vgl.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Cressie1993,Krueger2013,Schmid2012"

\end_inset

).
 Da dieser Nachweis sehr schwierig ist, beschränkt man sich bekannte Modellfunkt
ionen für die der Nachweis bereits erbracht worden ist.
 Hier ist insbesondere ein Modell zu erwähnen 
\begin_inset CommandInset citation
LatexCommand cite
key "lophaven2002aspects,Sacks2007"

\end_inset

:
\begin_inset Formula 
\begin{align}
2\gamma\left(\vec{h}\right)= & \sigma^{2}\left(1-e^{-\frac{1}{2}\underset{l=1}{\overset{l<=k}{\sum}}\left(\theta_{l}\left|h_{l}\right|^{p}\right)}\right)\label{eq:ExpoKorrelationsfunktion}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Wobei 
\begin_inset Formula $\vec{\theta}\in\mathbb{R^{\textrm{k}}}$
\end_inset

 als Hyperparametervektor bezeichnet wird und jeder Eintrag 
\begin_inset Formula $\theta_{l}$
\end_inset

 eine Korrelationslänge für den entsprechenden Parameter 
\begin_inset Formula $l$
\end_inset

 darstellt.
 Die Wahl eines sinnvollen Hyperparametervektors ist Aufgabe des Trainingsverfah
rens (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:MinimierungsverfahrenTraining"

\end_inset

).
 In dem hier implementierten Kriging-Verfahren wird eine abgeänderte Modellfunkt
ion verwendet: 
\begin_inset Formula 
\begin{align}
2\gamma\left(\vec{h}\right)= & \sigma^{2}\left(1-e^{-\frac{1}{2}\underset{l=1}{\overset{l<=k}{\sum}}\left(e^{\theta_{l}}\left|h_{l}\right|^{p}\right)}\right)\label{eq:ExpoKorrelationsfunktion-1}
\end{align}

\end_inset

Die Benutzung der Exponentialfunktion 
\begin_inset Formula $e^{\theta_{l}}$
\end_inset

 dient der numerischen Stabilität des Trainingsverfahrens.
 Da die Hyperparameter nicht negativ werden dürfen und somit für Formulierung
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:ExpoKorrelationsfunktion"

\end_inset

 eine Nebenbedingung in der Form 
\begin_inset Formula $\theta_{l}>0\forall l$
\end_inset


\begin_inset Formula $\in\left\{ 1,...,k\right\} $
\end_inset

 notwendig wäre.
 Durch Verwendung der Exponentialfunktion ist dies nicht notwendig.
\end_layout

\begin_layout Standard
Für den Fall 
\begin_inset Formula $p=2$
\end_inset

 spricht man auch von einer Gauss'schen Korrelationsfunktion, welche in
 der hier beschriebenen Software auch als Standard gewählt wird.
 Der Vorteil dieser Korrelationsfunktion liegt in der schnellen Berechnung
 und damit in der schnellen Erzeugung der benötigten Kovarianzmatrix.
 
\end_layout

\begin_layout Standard
Neben diesen Korrelationsfunktionen wird häufig ein parametrisierter kubischer
 Spline verwendet, der interessierte Leser sei hierfür auf 
\begin_inset CommandInset citation
LatexCommand cite
key "lophaven2002aspects"

\end_inset

 verwiesen.
 Innerhalb der hier entwickelten Kriging-Software sind diese drei Korrelationsfu
nktionen implementiert und frei wählbar.
 
\end_layout

\begin_layout Standard
Setzt man bspw.
 die Kovarianzfunktion aus Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:ExpoKorrelationsfunktion"

\end_inset

 in Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:KovarianzmodellAllgemein"

\end_inset

 ein, dann folgt daraus die resultierende Kovarianzfunktion:
\begin_inset Formula 
\begin{align}
cov\left(\vec{h}\right) & =\sigma^{2}+\lambda\delta\left(\vec{h}\right)-\sigma^{2}\left(1-e^{-\frac{1}{2}\underset{l=1}{\overset{l<=k}{\sum}}\left(e^{\theta_{l}}\left|h_{l}\right|^{p}\right)}\right)\label{eq:ExpoKovarianzfunktion}\\
 & =\lambda\delta\left(\vec{h}\right)+\sigma^{2}e^{-\frac{1}{2}\underset{l=1}{\overset{l<=k}{\sum}}\left(e^{\theta_{l}}\left|h_{l}\right|^{p}\right)}
\end{align}

\end_inset

Die für das Trainingsverfahren notwendigen Ableitungen sehen für die gauss'sche
 Kovarianzfunktion wie folgt aus:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
\frac{\partial cov\left(\vec{h}\right)}{\partial\theta_{a}} & =-\frac{1}{2}\sigma^{2}e^{\theta_{a}}\left|h_{a}\right|^{2}\left(e^{-\frac{1}{2}\underset{l=1}{\overset{l<=k}{\sum}}\left(e^{\theta_{l}}\left|h_{l}\right|^{2}\right)}\right)\label{eq:AbleitungKorrGauss}\\
\frac{\partial cov\left(\vec{h}\right)}{\partial\sigma^{2}} & =e^{-\frac{1}{2}\underset{l=1}{\overset{l<=k}{\sum}}\left(e^{\theta_{l}}\left|h_{l}\right|^{2}\right)}\label{eq:AbleitungsKorrGauss2}
\end{align}

\end_inset


\end_layout

\begin_layout Subsubsection*
Kovarianzfunktion CO-Kriging
\begin_inset CommandInset label
LatexCommand label
name "subsec:Kovarianzfunktion-CO-Kriging"

\end_inset


\end_layout

\begin_layout Standard
Die Kovarianzfunktion für das CO-Kriging wird aus mehreren Kovarianzfunktionen
 zusammengesetzt, daher werden keine neuen Modelle benötigt.
 Es werden allerdings für jede Gütestufe ein zusätzlicher Hyperparametervektor
 
\begin_inset Formula $\vec{\theta}_{2},\vec{\theta}_{diff}$
\end_inset

 verwendet.
 Geht man von den Gleichungen 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:KovarianzFunktionenalleDrei"

\end_inset

 aus und setzt das entsprechende Kovarianzmodell aus Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:ExpoKovarianzfunktion"

\end_inset

 ein, wobei 
\begin_inset Formula $c_{2}\left(\vec{h}\right)=e^{-\frac{1}{2}\underset{l=1}{\overset{l<=k}{\sum}}\left(e^{\theta_{l,2}}\left|h_{l}\right|^{p}\right)}$
\end_inset

 und 
\begin_inset Formula $c_{diff}\left(\vec{h}\right)=e^{-\frac{1}{2}\underset{l=1}{\overset{l<=k}{\sum}}\left(e^{\theta_{l,diff}}\left|h_{l}\right|^{p}\right)}$
\end_inset

, so erhält man:
\begin_inset Formula 
\begin{align}
cov_{1,1}\left(\vec{x}_{1},\vec{x}_{2}\right)= & a^{2}\sigma_{2}^{2}c_{2}\left(\vec{h}\right)\nonumber \\
 & +\lambda_{diff}\delta\left(\vec{h}\right)+\sigma_{diff}^{2}c_{diff}\left(\vec{h}\right)\nonumber \\
cov_{1,2}\left(\vec{x}_{1},\vec{x}_{2}\right)= & a\sigma_{2}^{2}c_{2}\left(\vec{h}\right)\label{eq:KovarianzfunktionenCoKrigingGauss}\\
cov_{2,2}\left(\vec{x}_{1},\vec{x}_{2}\right)= & \lambda_{2}\delta\left(\vec{h}\right)+\sigma_{2}^{2}c_{2}\left(\vec{h}\right)\nonumber 
\end{align}

\end_inset


\end_layout

\begin_layout Subsection
Numerischen Grenzen für die Hyperparameter
\end_layout

\begin_layout Standard
Betrachtet man sich die Gleichung für die Korrelationen 
\begin_inset Formula $c\left(\vec{h}\right)=e^{-\frac{1}{2}\underset{l=1}{\overset{l<=k}{\sum}}\left(e^{\theta_{l}}\left|h_{l}\right|^{2}\right)}$
\end_inset

, so können die 
\begin_inset Formula $\theta_{l}$
\end_inset

 Werte sehr große oder kleine Werte annehmen.
 Diese Werte gehen dann in eine verkettete Exponentialfunktion ein.
 Der innere Teil der Exponentialfunktion 
\begin_inset Formula $e^{\theta_{l}}$
\end_inset

 kann sehr große oder sehr kleine Werte annehmen.
 Es sollten daher numerische Grenzen für die 
\begin_inset Formula $\theta_{l}$
\end_inset

 Werte gelten.
\end_layout

\begin_layout Standard
Um diese Werte zu bestimmen bietet sich ein einfacher numerischer Testfall
 an.
 Hierfür wurde ein kleines Testprogramm geschrieben, welches die Grenzwerte
 für 
\begin_inset Formula $c\left(\vec{h}\right)=e^{-\frac{1}{2}e^{\theta}}$
\end_inset

 bestimmt.
 Die gefundenen Grenzen lagen bei 
\begin_inset Formula $\theta\in\mathbb{R}|5<\theta_{l}<-34$
\end_inset

.
 
\end_layout

\begin_layout Section
Regularisierung und Behandlung verrauschter Funktionen
\begin_inset CommandInset label
LatexCommand label
name "sec:RegularisierungUndRauschen"

\end_inset


\end_layout

\begin_layout Standard
Zwei weitere wichtige Punkte der verschiedenen Kriging-Verfahren, sind die
 Berücksichtigungen von schlecht konditionierten Kovarianzmatrizen und der
 Umgang mit verrauschten Funktionen.
 Da die praktische Behandlung beider Problematiken sehr ähnlich ist, werden
 innerhalb dieses Kapitels beide Probleme gemeinsam beschrieben.
\end_layout

\begin_layout Subsection
Regularisierung
\begin_inset CommandInset label
LatexCommand label
name "subsec:Regularisierung"

\end_inset


\end_layout

\begin_layout Standard
Während des Trainings wird ein Satz Hyperparameter gesucht, welcher den
 Likelihood Wert (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:COKrigingTraining"

\end_inset

) maximiert.
 Dabei muss für jeden Satz an Hyperparametern die zugehörige Kovarianzmatrix
 aufgestellt werden.
 Bei diesem Prozess kann es passieren, dass die resultierende Matrix schlecht
 konditioniert ist und damit die verwendeten numerischen Verfahren instabil
 werden.
 Die Ursache einer schlecht konditionierten Matrix können sehr vielfältig
 sein und werden in 
\begin_inset CommandInset citation
LatexCommand cite
key "Davis1997"

\end_inset

 genauer beschrieben.
 In der Regel liegt es an schlecht verteilten Stützstellen oder an einer
 ungünstigen Initialisierung der Hyperparameter.
 Auch die Wahl der Kovarianzfunktion kann enormen Einfluss auf die numerische
 Stabilität haben.
 
\end_layout

\begin_layout Standard
Eine gebräuchliche Methode um die Konditionszahl zu verbessern, ist es die
 Hauptdiagonale der Kovarianzmatrix um einen Wert 
\begin_inset Formula $\lambda\in\mathbb{R}$
\end_inset

 (folgend Diagonalaufschlag) zu erhöhen.
 Dieses Vorgehen entspricht einer Tikhonov Regularisierung, wie sie häufig
 für Least Squares Verfahren eingesetzt wird (siehe 
\begin_inset CommandInset citation
LatexCommand cite
key "Sacks2007a,tikhonov2013numerical,hoerl2000"

\end_inset

).
 
\end_layout

\begin_layout Standard
Dieser Diagonalaufschlag sollte so klein wie möglich gehalten werden, da
 dessen Größe einen starken Einfluss auf die Vorhersagen hat.
 Das resultierende Verhalten wird im nächsten Abschnitt 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Approximation"

\end_inset

 behandelt.
 
\end_layout

\begin_layout Paragraph*
Ordinary Kriging
\begin_inset CommandInset label
LatexCommand label
name "par:Ordinary-Kriging"

\end_inset


\end_layout

\begin_layout Standard
Zur Bestimmung eines geeigneten Wertes, ist es sinnvoll die Konditionszahl
 
\begin_inset Formula $\kappa$
\end_inset

 der Kovarianzmatrix zu betrachten.
 Diese ist definiert als Quotient aus maximalem 
\begin_inset Formula $\Xi_{max}$
\end_inset

 und minimalem Eigenwert 
\begin_inset Formula $\Xi_{min}$
\end_inset

:
\begin_inset Formula 
\begin{align*}
\kappa & =\left|\frac{\Xi_{max}\left(\mathbf{Cov}\right)}{\Xi_{min}\left(\mathbf{Cov}\right)}\right|
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Geht man weiterhin von einer Ordinary-Kriging Kovarianzmatrix aus, so kann
 die Varianz 
\begin_inset Formula $\sigma^{2}$
\end_inset

 aus der Matrix ausgeklammert werden und die Korrelationsmatrix 
\begin_inset Formula $\mathbf{R}\in\mathbb{R}^{n\times n}$
\end_inset

 bleibt:
\begin_inset Formula 
\[
\mathbf{Cov}=\sigma^{2}\mathbf{R}
\]

\end_inset


\end_layout

\begin_layout Standard
Die Korrelationen innerhalb der Korrelationsmatrix 
\begin_inset Formula $\mathbf{R\in\mathbb{R}^{n\times n}}$
\end_inset

 können einen maximalen Wert von 1 annehmen.
 Daraus lässt sich der ungünstigste Fall 
\begin_inset Formula $\mathbf{\widetilde{R}}\in\mathbb{R}^{n\times n}$
\end_inset

 für die Konditionierung der Matrix ableiten, welcher einer reinen Einsmatrix
 entspricht.
\begin_inset Formula 
\begin{align}
\mathbf{Cov} & =\sigma^{2}\left[\begin{array}{ccc}
1 & ... & 1\\
... & ... & ...\\
1 & ... & 1
\end{array}\right]=\mathbf{\sigma^{2}\widetilde{R}}
\end{align}

\end_inset

Die minimalen und maximalen Eigenwerte der Einsmatrix sind für diesen Fall
 bekannt:
\begin_inset Formula 
\begin{align}
\Xi_{min}\left(\mathbf{Cov}\right) & =0\\
\Xi_{max}\left(\mathbf{Cov}\right) & =\sigma^{2}n
\end{align}

\end_inset

Dies würde einer unendlichen Konditionszahl entsprechen:
\begin_inset Formula 
\begin{align}
\kappa & =\infty
\end{align}

\end_inset

Addiert man nun den Diagonalaufschlag, bekommt man folgende Kovarianzmatrix:
 
\begin_inset Formula 
\begin{align}
\mathbf{\mathbf{Cov}} & =\left[\begin{array}{ccc}
\sigma^{2}+\lambda & ... & \sigma^{2}\\
... & ... & ...\\
\sigma^{2} & ... & \sigma^{2}+\lambda
\end{array}\right]\\
\mathbf{\mathbf{Cov}} & =\sigma^{2}\left[\begin{array}{ccc}
1+\frac{\lambda}{\sigma^{2}} & ... & 1\\
... & ... & ...\\
1 & ... & 1+\frac{\lambda}{\sigma^{2}}
\end{array}\right]
\end{align}

\end_inset

Daraus ergeben sich die folgenden maximalen und minimalen Eigenwerte:
\begin_inset Formula 
\begin{align}
\Xi_{min}\left(\mathbf{\mathbf{Cov}}\right) & =\lambda\\
\Xi_{max}\left(\mathbf{Cov}\right) & =\sigma^{2}\left(n+\frac{\lambda}{\sigma^{2}}\right)=\lambda+\sigma^{2}n
\end{align}

\end_inset

Und die entsprechende Konditionszahl verbessert sich zu:
\begin_inset Formula 
\begin{align}
\kappa & =\left|\frac{\lambda+\sigma^{2}n}{\lambda}\right|
\end{align}

\end_inset

Da die Matrix positiv definit sein muss und damit nur positive Eigenwerte
 hat, kann der Betrag vernachlässigt werden.
 Wählt man nun für die Konditionszahl eine obere Grenze, erhält man eine
 Untergrenze für den Diagonalaufschlag:
\begin_inset Formula 
\begin{align}
\kappa_{max} & >\frac{\lambda+\sigma^{2}n}{\lambda}\\
\lambda & >\frac{\sigma^{2}n}{\left(\kappa_{max}-1\right)}
\end{align}

\end_inset


\end_layout

\begin_layout Paragraph*
CO-Kriging
\end_layout

\begin_layout Standard
Im Falle des CO-Krigings ist, bedingt durch die unterschiedlichen Gütestufen,
 die Kovarianzmatrix partitioniert.
 
\end_layout

\begin_layout Standard
Der Ansatz aus dem Ordinary-Kriging ist mit dieser partitionierten Matrix
 nicht mehr möglich, dennoch ist es möglich den maximalen Eigenwert 
\begin_inset Formula $\Xi_{max}\left(\mathbf{Cov}\right)$
\end_inset

 der Matrix zu schätzen.
 Für eine diagonalisierbare Matrix gilt allgemein, dass die Summe der Eigenwerte
 
\begin_inset Formula $\Xi_{i},i\in\left\{ 1,...,n_{all}\right\} $
\end_inset

 der Spur der Matrix entspricht:
\begin_inset Formula 
\begin{align}
\sum_{i=1}^{n_{all}}\Xi_{i} & =spur\left(\mathbf{Cov}\right)\label{eq:SpurEqSummeEigenwerte}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Geht man von zusammengesetzten Kovarianzfunktion wie sie in den Gleichungen
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:KovarianzfunktionenCoKrigingGauss"

\end_inset

 gezeigt wurde aus, so ergibt sich die Spur als Summe der Diagonaleinträge
 wie folgt:
\begin_inset Formula 
\begin{align}
spur\left(\mathbf{Cov}\right) & =\sum_{i=1}^{n_{1}}\left(a^{2}\sigma_{2}^{2}c_{2}\left(\vec{0}\right)+\sigma_{diff}^{2}c_{diff}\left(\vec{0}\right)+\lambda_{diff}\right)+\sum_{i=1}^{n_{2}}\left(\sigma_{2}^{2}c_{2}\left(\vec{0}\right)+\lambda_{2}\right)
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Da die Korrelationen der Diagonalen den Wert Eins besitzen,
\begin_inset Formula $c_{2}\left(\vec{0}\right)=1$
\end_inset

 und 
\begin_inset Formula $c_{diff}\left(\vec{0}\right)=1$
\end_inset

, gilt für die Spur der Matrix:
\begin_inset Formula 
\begin{align}
spur\left(\mathbf{Cov}\right) & =\sum_{i=1}^{n_{1}}\left(a^{2}\sigma_{2}^{2}1+\sigma_{diff}^{2}1+\lambda_{diff}\right)+\sum_{i=1}^{n_{2}}\left(\sigma_{2}^{2}1+\lambda_{2}\right)\\
 & =n_{1}\left(a^{2}\sigma_{2}^{2}+\sigma_{diff}^{2}+\lambda_{diff}\right)+n_{2}\left(\sigma_{2}^{2}+\lambda_{2}\right)
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Übertragen auf Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:SpurEqSummeEigenwerte"

\end_inset

 folgt:
\begin_inset Formula 
\begin{align}
\sum_{i=1}^{n_{all}}\Xi_{i} & =n_{1}\left(a^{2}\sigma_{2}^{2}+\sigma_{diff}^{2}+\lambda_{diff}\right)+n_{2}\left(\sigma_{2}^{2}+\lambda_{2}\right)\geq n_{1}\lambda_{diff}+n_{2}\lambda_{2}\label{eq:EigenwertBedSpur}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Geht man weiterhin von nur einem Regularisierungsterm 
\begin_inset Formula $\lambda_{diff}=\lambda_{2}=\lambda$
\end_inset

 für alle Gütestufen aus, gilt für den maximalen und minimalen Eigenwert
 
\begin_inset Formula $\Xi_{max},\Xi_{min}$
\end_inset

: 
\begin_inset Formula 
\begin{align}
\Xi_{max} & \leq n_{1}\left(a^{2}\sigma_{2}^{2}+\sigma_{diff}^{2}+\lambda\right)+n_{2}\left(\sigma_{2}^{2}+\lambda\right)\\
\Xi_{min} & \geq\lambda;falls\,\Xi_{i}=\Xi_{min}\forall i\label{eq:EigenwertMinGrLambda}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:EigenwertMinGrLambda"

\end_inset

 folgt aus 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:EigenwertBedSpur"

\end_inset

 Für die Konditionszahl 
\begin_inset Formula $\kappa$
\end_inset

 lässt sich so eine obere Grenze bestimmen:
\begin_inset Formula 
\begin{align}
\kappa & \leq\frac{n_{1}\left(a^{2}\sigma_{2}^{2}+\sigma_{diff}^{2}+\lambda\right)+n_{2}\left(\sigma_{2}^{2}+\lambda\right)}{\lambda}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Legt man nun für die Konditionszahl einen maximalen Wert 
\begin_inset Formula $\kappa_{max}$
\end_inset

 fest, ergibt sich als Schätzung für den Diagonalaufschlag:
\begin_inset Formula 
\begin{align}
\lambda_{min} & \geq\frac{n_{1}a^{2}\sigma_{2}^{2}+n_{1}\sigma_{diff}^{2}+n_{2}\sigma_{2}^{2}}{\left(\kappa_{max}-\left(n_{2}+n_{1}\right)\right)}\label{eq:DiagonalSchätzungCoKriging}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Die Werte 
\begin_inset Formula $\sigma_{2}^{2},\sigma_{diff}^{2},a$
\end_inset

 werden während des Trainings oftmals verändert, dadurch ändert sich natürlich
 auch die untere Grenze des Diagonalaufschlags 
\begin_inset Formula $\lambda_{min}$
\end_inset

 (siehe Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:DiagonalSchätzungCoKriging"

\end_inset

) permanent.
 Prinzipiell sind zwei Lösungen möglich:
\end_layout

\begin_layout Enumerate
Die untere Grenze für 
\begin_inset Formula $\lambda_{min}$
\end_inset

 in jedem Trainingsschritt neu bestimmen und bei Unterschreitung auf den
 Grenzwert setzen.
\end_layout

\begin_layout Enumerate
Die untere Grenze für 
\begin_inset Formula $\lambda_{min}$
\end_inset

 nur beim Start des Trainings bestimmen.
 
\end_layout

\begin_layout Standard
Die erste Lösung kann dazu führen, dass sich der Grenzwert 
\begin_inset Formula $\lambda_{min}$
\end_inset

 während des Training ändert und der aktuelle Wert 
\begin_inset Formula $\lambda<\lambda_{min}$
\end_inset

 die Grenze unterschreitet.
 Da der Diagonalaufschlag dann bei Unterschreitung der Grenze abhängig von
 den Variablen 
\begin_inset Formula $\sigma_{2}^{2},\sigma_{diff}^{2},a$
\end_inset

 wird, muss dies bei der Ableitung des Likelihoods (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:COKrigingTraining"

\end_inset

) Berücksichtigung finden.
 
\end_layout

\begin_layout Standard
Aus diesem Grund wird die zweite Variante gewählt, also die untere Grenze
 nur initial eingestellt und dann nicht mehr verändert.
 Es sei denn es treten numerische Probleme während des Trainings auf, dann
 wird in der Software eine entsprechende Exception geworfen und in der Software
 abgefangen.
 Daraufhin wird der letzte Iterationsschritt wiederholt und der Diagonalaufschla
g so lange erhöht, bis die numerischen Probleme verschwinden.
 Gelingt selbst dies nicht, wird ein Fehler ausgegeben und abgebrochen.
 
\end_layout

\begin_layout Standard
Ein geeigneter Wert für die obere Grenze der Konditionszahl liegt erfahrungsgemä
ß bei 
\begin_inset Formula $\sim10^{9}$
\end_inset

, dieser Wert kann im Einzelfall natürlich angepasst werden.
 
\end_layout

\begin_layout Standard

\size larger
\color red
Literaturstelle !!!
\end_layout

\begin_layout Subsection
Behandlung verrauschter Funktionen
\begin_inset CommandInset label
LatexCommand label
name "subsec:Approximation"

\end_inset


\end_layout

\begin_layout Standard
Bei Vernachlässigung des Diagonalaufschlags 
\begin_inset Formula $\lambda$
\end_inset

, ist das bisher beschriebene Kriging-Verfahren rein interpolierend.
 In einigen Fällen ist allerdings ein approximierendes Verhalten gewünscht.
 Ein solches Verhalten entspricht dem in Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Variogramm"

\end_inset

 beschriebenen 
\begin_inset Quotes gld
\end_inset

Nugget-Effekt
\begin_inset Quotes grd
\end_inset

.
 Die praktische Umsetzung innerhalb des Kriging Verfahrens ist letztlich
 dieselbe wie bei dem in Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Regularisierung"

\end_inset

 beschriebenen Regularisierungsterm.
 Der hauptsächliche Unterschied besteht in der Größenordnung des Diagonalaufschl
ags 
\begin_inset Formula $\lambda$
\end_inset

 und in dessen Bedeutung.
 Da es sich bei dem Diagonalaufschlag in diesem Fall um eine Varianz handelt
 die einem zufälligen Rauschen entspricht, siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Kovarianz-parametrisiertes-Model"

\end_inset

.
 Zudem ist der Diagonalaufschlag für diesen Fall als Hyperparameter zu behandeln
 und muss daher mit trainiert werden.
 Die Umsetzung soll folgend gezeigt werden.
 
\end_layout

\begin_layout Standard
Die Bildung der Kovarianzfunktion ist in Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Kovarianzfunktion-CO-Kriging"

\end_inset

 beschrieben.
 Um den Rauschterm innerhalb eines gradientenbasierten Trainingsverfahrens
 (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:MinimierungsverfahrenTraining"

\end_inset

) zu verwenden, müssen noch die Ableitungen der Kovarianzfunktionen nach
 den Rauschtermen gebildet werden.
 Im Fall des Co-Krigings mit den zwei Rauschtermen 
\begin_inset Formula $\lambda_{diff},\lambda_{2}\in\mathbb{R}$
\end_inset

 sehen die partiellen Ableitungen wie folgt aus: 
\begin_inset Formula 
\begin{align}
\frac{cov\left(Z_{1}\left(\vec{x}_{1}\right),Z_{1}\left(\vec{x}_{2}\right)\right)}{\partial\lambda_{diff}}= & 1\nonumber \\
\frac{cov\left(Z_{1}\left(\vec{x}_{1}\right),Z_{1}\left(\vec{x}_{2}\right)\right)}{\partial\lambda_{2}}= & 0\\
\frac{cov\left(Z_{1}\left(\vec{x}_{1}\right),Z_{2}\left(\vec{x}_{2}\right)\right)}{\partial\lambda_{diff}}=\frac{cov\left(Z_{1}\left(\vec{x}_{1}\right),Z_{2}\left(\vec{x}_{2}\right)\right)}{\partial\lambda_{2}}= & 0\label{eq:KovarianzfunktionenCoKrigingAbleitungDiag}\\
\frac{cov\left(Z_{2}\left(\vec{x}_{1}\right),Z_{2}\left(\vec{x}_{2}\right)\right)}{\partial\lambda_{diff}}= & 0\nonumber \\
\frac{cov\left(Z_{2}\left(\vec{x}_{1}\right),Z_{2}\left(\vec{x}_{2}\right)\right)}{\partial\lambda_{2}}= & 1
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Mit diesen Ableitungen ist das Maximum Likelihood Verfahren (siehe Kapitel
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:COKrigingTraining"

\end_inset

 und Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:MinimierungsverfahrenTraining"

\end_inset

) direkt anwendbar.
 
\end_layout

\begin_layout Paragraph*
Rauschterm Beispiel
\end_layout

\begin_layout Standard
In Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Kriging_RauschFunktion"

\end_inset

 wird ein einfaches Beispiel gezeigt, es soll die Wirkung von unterschiedlichen
 Rauschtermen auf die Vorhersage beispielhaft erläutert werden.
 Es handelt sich um eine konstante Null-Funktion mit einem normalverteilten
 Rauschen, welche den Erwartungswert Null und die Standardabweichung Eins
 besitzt: 
\begin_inset Formula $f\left(x\right)=\mathcal{N}\left(0,1\right)$
\end_inset

.
 Jeder eingezeichnete Punkt entspricht einer Stützstelle, wobei jede Stützstelle
 an einem anderen Ort ist.
 Mit Hilfe dieser Stützstellen wird dann ein Ordinary-Kriging trainiert
 und dann für den entsprechenden Wertebereich Vorhersagen
\begin_inset Wrap figure
lines 17
placement o
overhang 0in
width "50col%"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../images/KrigingKapitel/KonstantenRauschFunktion.eps
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Kriging_RauschFunktion"

\end_inset

Konstante Funktion mit normalverteiltem Rauschen
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset

 getroffen.
 Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:RauschenBeispiel"

\end_inset

 zeigt zwei mögliche Vorhersagen, beide werden durch den Likelihood Term
 gleichermaßen gut bewertet.
\end_layout

\begin_layout Standard
Die schwarze Linie entspricht dem vorhergesagten Erwartungswert und die
 Fehlerbalken der vorhergesagten Standardabweichung.
 Auf dem linken Bild zeigt das trainierte Kriging eine approximierendes
 Verhalten und auf dem rechten Bild ein interpolierendes Verhalten.
 Auf dem rechten Bild wird jeder der Stützstellen exakt wiedergegeben und
 die vorhersagte Standardabweichung ist an diesen Stellen Null.
 Der Diagonalaufschlag ist bei dieser Lösung ebenfalls Null.
\end_layout

\begin_layout Standard
Auf dem linken Bild hat der Diagonalaufschlag den Wert Eins, was genau der
 Varianz des Rauschterms entspricht.
 Im Extrapolationsbereich zeigen die verschiedenen Vorhersagen exakt dieselben
 Ergebnisse.
 Diese Doppeldeutigkeit kann auf die Einstellungen der Hyperparameter zurückgefü
hrt werden, die wesentlichen Hyperparameter sind die Prozessvarianz 
\begin_inset Formula $\sigma^{2}$
\end_inset

, der Diagonalaufschlag 
\begin_inset Formula $\lambda$
\end_inset

 und die Korrelationslänge 
\begin_inset Formula $\theta$
\end_inset

.
 Tabelle 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:KrigingRauschBspEinstellungn"

\end_inset

 zeigt die Einstellungen der beiden Lösungen.
 Für das Training der beiden Kriging-Modelle wurde der Diagonalaufschlag
 
\begin_inset Formula $\lambda$
\end_inset

 vorher festgelegt und die anderen Größen durch das Training automatisch
 bestimmt.
 
\end_layout

\begin_layout Standard
\begin_inset Wrap table
lines 9
placement o
overhang 0in
width "50col%"
status open

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Interpolierend
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Approximierend
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\sigma^{2}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\lambda$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\theta$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $e^{15}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $e^{-50}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:KrigingRauschBspEinstellungn"

\end_inset

Einstellungen der verschiedenen Kriging-Lösungen
\end_layout

\end_inset


\end_layout

\end_inset

Die interpolierenden Variante besitzt eine Varianz von 
\begin_inset Formula $\sigma^{2}=1$
\end_inset

.
 Diese Varianz entspricht dann dem 
\begin_inset Quotes gld
\end_inset

Sill
\begin_inset Quotes grd
\end_inset

 aus Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Variogramm"

\end_inset

, also der Varianz bei großem Abstand zu einem bekannten Punkt.
 Der Abstand wird durch die Korrelationslänge 
\begin_inset Formula $\theta$
\end_inset

 beeinflusst.
 Wobei ein großer 
\begin_inset Formula $\theta$
\end_inset

 Wert auf einen räumlich sehr kleinen Einfluss deutet.
 Diese Lösung würde also einem sehr steilen Variogramm entsprechen, welches
 bei kleinstem Abstand sofort auf den 
\begin_inset Quotes gld
\end_inset

Sill
\begin_inset Quotes grd
\end_inset

 springt.
 Das Variogramm wird qualitativ in dem rechten Diagramm der Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:VarioApproxInter"

\end_inset

 dargestellt.
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "75col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename ../images/KrigingKapitel/semiSteep.eps
	scale 70
	clip

\end_inset


\end_layout

\end_inset


\begin_inset space \hspace*{\fill}
\end_inset


\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "24col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:VarioApproxInter"

\end_inset

Qualitatives Variogramm für das interpolierende und approximierende Kriging
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Die approximierende Variante hat eine sehr kleine Korrelationslänge 
\begin_inset Formula $\theta=e^{-50}$
\end_inset

 und eine Varianz von 
\begin_inset Formula $\sigma^{2}=0$
\end_inset

, was einer konstanten Funktion ohne Unsicherheit entspricht.
 Durch den Rauschterm 
\begin_inset Formula $\lambda=1$
\end_inset

 wird dem Modell eine grundlegende Unsicherheit aufaddiert, welche dem 
\begin_inset Quotes gld
\end_inset

Nugget
\begin_inset Quotes grd
\end_inset

 entspricht.
 Das entsprechende Variogramm wäre unabhängig von der Distanz und entspricht
 dem linken Diagramm in Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:VarioApproxInter"

\end_inset

.
 
\end_layout

\begin_layout Standard
Die beiden gezeigt Lösungen haben denselben Likelihood Wert, werden vom
 Trainingsverfahren also als gleichwertig angesehen.
 Welche Lösung letztlich vom Training gewählt wird, hängt hauptsächlich
 von der gewählten Initialisierung ab.
 In Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Initialisierung-der-Hyperparamet"

\end_inset

 werden verschiedene Möglichkeiten der Initialisierung beschrieben.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "75col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename ../images/KrigingKapitel/KonstantenRauschFunktionPunkte.eps
	scale 40

\end_inset


\end_layout

\end_inset


\begin_inset space \hspace*{\fill}
\end_inset


\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "24col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:RauschenBeispiel"

\end_inset

Normalverteiltes Rauschen und zwei mögliche Kriging Modelle.
 Die Fehlerbalken stellen die vorhergesagte Standardabweichung dar
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:RauschBeiespielDiagonalaufschlagVarianz"

\end_inset

 zeigt für verschiedene Diagonalaufschläge den resultierenden Likelihood-Wert,
 wobei hier ein kleiner Likelihood ein besseres Ergebnis darstellt.
 Das Ergebnis zeigt, dass der Likelihood-Wert für einem Diagonalaufschlag
 im Bereich von 
\begin_inset Formula $\lambda>0\land\lambda<1$
\end_inset

 konstant und minimal bleibt.
 Darüber wird der Likelihood-Wert dann deutlich größer.
 Um das Verhalten zu verstehen, wird in Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:RauschBeispielVarianzDiag"

\end_inset

 die eingestellte Varianz 
\begin_inset Formula $\sigma^{2}$
\end_inset

 und der Diagonalaufschlag für den Bereich des optimalen Likelihood-Wertes
 gezeigt.
 Das Ergebnis ist auch hier plausibel, denn in der Summe ergeben die beiden
 Werte immer den Wert 
\begin_inset Formula $\sigma^{2}+\lambda=1$
\end_inset

, was dann wiederum der Varianz des Erzeugungsprozesses entspricht.
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../images/KrigingKapitel/DiagonalLikelihood.eps
	scale 60

\end_inset


\begin_inset Graphics
	filename ../images/KrigingKapitel/DiagonalVarianz.eps
	scale 60

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:RauschBeiespielDiagonalaufschlagVarianz"

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "fig:RauschBeispielVarianzDiag"

\end_inset

 (a) Diagonalaufschlag und Varianz und resultierender Likelihood Wert (b)
 Bereich des optimalen Likelihood-Wertes und Entwicklung des Diagonalaufschlag
 und der Varianz
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Das hier gezeigte Verhalten entspricht also den Erwartungen.
 Allerdings kann dies bei einer geringeren Datenlage oder einer komplexeren
 Funktion dazu führen, dass der Diagonalaufschlag deutlich überschätzt wird.
 Die praktische Erfahrung zeigt auch genau ein solches Verhalten.
 Aus diesem Grund sollte das Training des Diagonalaufschlags als nur optionale
 Funktion des Trainings verfügbar sein.
 
\end_layout

\begin_layout Subsection
Softwaretechnische Umsetzung von Approximation und Regularisierung 
\end_layout

\begin_layout Standard
In den Kapiteln 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Regularisierung"

\end_inset

 und 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Approximation"

\end_inset

 wird ein Diagonalaufschlag verwendet, um eine Regularisierung der Matrix
 zu erreichen und auch um ein approximierendes Verhalten herbeizuführen.
 Praktische Unterschiede ergeben sich nur in der Größe der Werte und in
 der Bestimmung während des Trainings.
 Auf der einen Seite steht der Regularisierungsterm, welcher für die numerische
 Stabilität sorgen soll.
 Dieser soll die Vorhersage möglichst nicht beeinflussen und muss daher
 sehr klein gewählt werden.
 Zudem ist dieser nicht als Hyperparameter anzusehen und daher keine zu
 trainierende Größe.
 Auf der anderen Seite steht der Rauschterm, welcher für ein approximierende
 Verhalten sorgen soll.
 Dieser Parameter wird auch innerhalb des Trainingsverfahrens geschätzt
 und ist als Hyperparameter einzustufen.
 Um nicht für den Regularisierungsterm und den Rauschterm jeweils einen
 eigenen Wert zu verwenden, ist es möglich den Regularisierungsterm als
 minimale Grenze anzunehmen.
 Der Rauschterm kann dann wie beschrieben trainiert werden, besitzt dann
 allerdings eine untere Schranke, die sich wie in Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Regularisierung"

\end_inset

 beschrieben festlegen lässt.
 
\end_layout

\begin_layout Section
Training
\begin_inset CommandInset label
LatexCommand label
name "chap:MinimierungsverfahrenTraining"

\end_inset


\end_layout

\begin_layout Standard
In diesem Kapitel wird das Trainingsverfahren für alle Kriging-Modelle beschrieb
en.
 Dafür wird im ersten Teil das Maximum-Likelihood Verfahren vorgestellt,
 dieses liefert ein Maß für die Güte des Modells unter Berücksichtigung
 der eingestellten Hyperparameter.
 
\end_layout

\begin_layout Standard
Ziel des Trainingsverfahrens ist es, die optimalen Hyperparameter zu finden
 die diesen Term maximieren.
 Zu diesem Zweck werden diverse numerische Minimierungsverfahren und auch
 mögliche Initialisierungsverfahren vorgestellt.
 
\end_layout

\begin_layout Standard
Da einige der Minimierungsverfahren bereits vor der Entwicklung des hier
 vorgestellten Programms vorhanden waren, diese allerdings noch in der Programmi
ersprache C entwickelt wurden, musste eine flexible Software-Schnittstelle
 entwickelt werden.
 Hierfür wurde ein spezielles Klassenmodell unter Benutzung von Boost-Funktionso
bjekten entwickelt, welches am Ende des Kapitels kurz beschrieben wird.
 
\end_layout

\begin_layout Subsection
Maximum Likelihood für alle Kriging Verfahren
\begin_inset CommandInset label
LatexCommand label
name "sec:COKrigingTraining"

\end_inset


\end_layout

\begin_layout Standard
Um ein Kriging-Modell vollständig aufzustellen, müssen sinnvolle Werte für
 die benötigten Hyperparameter der Kovarianz-Modellfunktion (siehe Kapitel
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Kovarianzmatrix"

\end_inset

) gefunden werden.
 Für diesen Zweck wird sehr häufig die Maximum-Likelihood-Methode angewandt,
 welche in diesem Abschnitt erläutert wird.
 
\end_layout

\begin_layout Standard
Die Maximum-Likelihood-Methode ist ein Schätzverfahren in der Statistik,
 um (Hyper)parameter einer angenommenen Verteilungsfunktion bei gegebenen
 Realisierungen zu schätzen.
 Es werden Werte für Hyperparameter gewählt, gemäß derer die Realisierung
 der bereits bekannten Daten am plausibelsten erscheint.
 
\end_layout

\begin_layout Standard
Um diesen Ansatz bei einem Verfahren wie dem Kriging anzuwenden, werden
 die bekannten Funktionswerte als Realisierung einer multivariaten Normalverteil
ung 
\begin_inset Formula $\mathcal{N}\left(\vec{F},\mathbf{Cov}\mathrm{(\vec{h})}\right)$
\end_inset

 angenommen.
 Wobei 
\begin_inset Formula $\mathbf{Cov}\mathrm{(\vec{h})}\mathbf{\mathbb{\in R^{\mathrm{n_{all}\times n_{all}}}}}$
\end_inset

 die jeweilige Kovarianzmatrix in Abhängigkeit der Hyperparameter 
\begin_inset Formula $\vec{h}\in\mathbb{R}{}^{o}$
\end_inset

 und 
\begin_inset Formula $\vec{y}_{s}$
\end_inset

 den Vektor aller bekannten Stützstellen und 
\begin_inset Formula $\vec{F}$
\end_inset

 den Vektor mit den jeweiligen stationären Erwartungswerten darstellt (siehe
 Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:FVektor"

\end_inset

).
 Daraus ergibt sich die folgende Dichtefunktion der multivariaten Normalverteilu
ng 
\begin_inset Formula $\mathcal{N}\left(\vec{F},\mathbf{Cov}\mathrm{(\vec{h})}\right)$
\end_inset

, diese wird oft auch als Likelihood-Funktion bezeichnet:
\begin_inset Formula 
\begin{align}
\mathcal{N}= & \frac{1}{\left(2\pi\right)^{\frac{n}{2}}\det\left(\mathbf{Cov}\mathrm{(\vec{h})}\right)^{\frac{1}{2}}}e^{-\frac{1}{2}\left(\vec{y}_{s}-\vec{F}\right)^{T}\mathbf{\mathbf{Cov}\mathrm{(\vec{h})}{}^{\textrm{-1}}}\left(\vec{y}_{s}-\vec{F}\right)}\label{eq:LikelihoodMultivariateNorm}
\end{align}

\end_inset


\shape italic
Es gilt: Die Hyperparameter 
\begin_inset Formula $\vec{h}$
\end_inset

 sind dann am plausibelsten, wenn der Dichtefunktionswert der Verteilung
 
\begin_inset Formula $\mathcal{N}\left(\vec{F},\mathbf{Cov}(\vec{h})\right)$
\end_inset

 maximal wird.
 
\end_layout

\begin_layout Standard
Das Training muss also die folgende Maximierungsaufgabe lösen:
\begin_inset Formula 
\begin{equation}
\max_{h_{1},...,h_{o}}\left(\frac{1}{\left(2\pi\right)^{\frac{n}{2}}\det\left(\mathbf{Cov}\mathrm{(\vec{h})}\right)^{\frac{1}{2}}}e^{-\frac{1}{2}\left(\vec{y}_{s}-\vec{F}\right)^{T}\mathbf{\mathbf{Cov}\mathrm{(\vec{h})}{}^{\textrm{-1}}}\left(\vec{y}_{s}-\vec{F}\right)}\right)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Numerisch ist diese Formulierung ungünstig, da die Exponentialfunktion im
 Zähler sehr kleine Werte annehmen kann und die Determinante im Nenner sehr
 große.
 Eine gebräuchliche Lösung ist die Verwendung der logarithmierten Dichtefunktion
 (vgl.
 
\begin_inset CommandInset citation
LatexCommand cite
key "viertl2013einfuhrung"

\end_inset

):
\begin_inset Formula 
\begin{align}
\log(\mathcal{N})= & \log(1)-\frac{n}{2}\log(2\pi)-\frac{1}{2}\log\left(\det(\mathbf{\mathbf{Cov}})\right)-\frac{1}{2}\left(\vec{y}_{s}-\overrightarrow{F}\right)^{T}\mathbf{\mathbf{Cov}}^{-1}\left(\vec{y}_{s}-\overrightarrow{F}\right)\label{eq:LogLikelihoodZwischen}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Da der Logarithmus eine streng monoton wachsende Funktion ist, ist jedes
 Minimum der logarithmierten Dichtefunktion (Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:LikelihoodMultivariateNorm"

\end_inset

) auch ein Minimum der Dichtefunktion (Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:LikelihoodMultivariateNorm"

\end_inset

) selbst.
 Ebenso ist jedes Maximum der logarithmierten Dichtefunktion auch ein Maximum
 der Dichtefunktion.
 
\end_layout

\begin_layout Standard
Die Konstanten können ignoriert werden, da diese für das Maximum keine Rolle
 spielen, daraus folgt: 
\begin_inset Formula 
\begin{align}
\log(\mathcal{N})= & -\log\left(\det(\mathbf{\mathbf{Cov}})\right)-\left(\vec{y}_{s}-\overrightarrow{F}\right)^{T}\mathbf{\mathbf{Cov}}^{-1}\left(\vec{y}_{s}-\overrightarrow{F}\right)\label{eq:LogLikelihood}
\end{align}

\end_inset

Die Ableitung nach einem beliebigen Hyperparameter 
\begin_inset Formula $h_{l}$
\end_inset

 sieht dann wie folgt aus, die vollständige Herleitung ist in Anhang 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Differentiation-der-Likelihood-Funktion"

\end_inset

 zu finden:
\begin_inset Formula 
\begin{align}
\frac{\partial L\left(\vec{h}\right)}{\partial h_{l}}= & -\textrm{Spur}\left(\mathbf{\mathbf{Cov}}^{-1}\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}\right)+\left(\left(\vec{y}_{s}-\overrightarrow{F}\right)^{T}\mathbf{\mathbf{\mathbf{Cov}}}^{-1}\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}\mathbf{\mathbf{Cov}}^{-1}\left(\vec{y}_{s}-\overrightarrow{F}\right)\right)\label{eq:AbleitungLogLikelihood}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
\noindent
Damit ist es nun möglich die unbekannten Hyperparameter mit einem geeigneten
 Minimierungsverfahren zu bestimmen.
 Einige in dieser Arbeit verwendete Minimierungsverfahren werden in Kapitel
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Minimierungsverfahren"

\end_inset

 beschrieben.
 
\end_layout

\begin_layout Standard
Um eine Vorstellung von der Form einer solchen Likelihood-Funktion für das
 CO-Kriging Verfahren zu bekommen, wird in Anhang 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:AnhangLikelihoodCOKrigingBsp"

\end_inset

 ein einfaches Beispiel in Abhängigkeit verschiedener Hyperparameter gezeigt.
 Die Form der Funktion spielt auch für das gewählte Trainingsverfahren eine
 wesentliche Rolle.
\end_layout

\begin_layout Subsection
Likelihood Schätzer Erwartungswerte und Varianz 
\begin_inset CommandInset label
LatexCommand label
name "subsec:CoKrigingAnalytische-Bestimmung-derErwwartzungswerte"

\end_inset


\end_layout

\begin_layout Standard
Die Maximierung der Likelihood-Funktion in Abhängigkeit der Erwartungswerte
 
\begin_inset Formula $\overrightarrow{F}\in\mathbb{R^{\mathrm{n_{all}}}}$
\end_inset

 ist analytisch lösbar.
 Im Folgenden soll die Lösung dafür gezeigt werden.
 Die Anzahl der Gütestufen wird mit 
\begin_inset Formula $s$
\end_inset

 gekennzeichnet, die Anzahl der Stützstellen einer Gütestufe 
\begin_inset Formula $k\in\left\{ 1,...,s\right\} $
\end_inset

 wird mit 
\begin_inset Formula $n_{k}$
\end_inset

 bezeichnet und 
\begin_inset Formula $n_{all}$
\end_inset

 bezeichnet die Anzahl der Stützstellen aller Gütestufen.
 Das Maximum der mehrdimensionalen Normalverteilung nach dem Maximum Likelihood
 Ansatz bezüglich des Vektors 
\begin_inset Formula $\overrightarrow{F}\in\mathbb{R^{\mathrm{n_{all}}}}$
\end_inset

 sieht wie folgt aus:
\end_layout

\begin_layout Paragraph
\begin_inset Formula 
\[
MLE\left(\overrightarrow{F}\right)=max\left(\frac{1}{\left(2\pi\right)^{\frac{n}{2}}|\mathbf{Cov}|^{\frac{1}{2}}}e^{-\frac{1}{2}\left(\overrightarrow{y}-\overrightarrow{F}\right)^{T}\mathbf{Cov}^{-1}\left(\overrightarrow{y}-\overrightarrow{F}\right)}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Führt man eine Matrix 
\begin_inset Formula $\mathbf{G}\in\mathbb{R^{\mathrm{n_{all}\times s}}}$
\end_inset

 ein in der Form:
\begin_inset Formula 
\begin{align}
\mathbf{G}= & \overset{s\,Einträge}{\underset{\overbrace{Spalte\,k}}{\overbrace{\left[\begin{array}{ccccc}
1 & \cdots & 0 & \cdots & 0\\
\vdots &  & \vdots &  & \vdots\\
1 & \cdots & 0 & \cdots & 0\\
\vdots &  & \vdots &  & \vdots\\
0 & \cdots & 1 & \cdots & 0\\
\vdots &  & \vdots &  & \vdots\\
0 & \cdots & 1 & \cdots & 0\\
\vdots &  & \vdots &  & \vdots\\
0 & \cdots & 0 & \cdots & 1\\
\vdots &  & \vdots &  & \vdots\\
0 & \cdots & 0 & \cdots & 1
\end{array}\right]}}}\begin{array}{c}
\left\} \begin{array}{c}
\\
n_{1}\,Eintr\ddot{a}ge\\
\\
\end{array}\right.\\
\vdots\\
\left\} \begin{array}{c}
\\
n_{k}\,Eintr\ddot{a}ge\\
\\
\end{array}\right.\\
\vdots\\
\left\} \begin{array}{c}
\\
n_{s}\,Eintr\ddot{a}ge\\
\\
\end{array}\right.
\end{array}
\end{align}

\end_inset

Und einen Vektor 
\begin_inset Formula $\vec{\tilde{F}}\in\mathbb{R^{\mathrm{s\times1}}}$
\end_inset

, so gilt folgende Beziehung:
\begin_inset Formula 
\begin{align*}
\vec{F} & =\mathbf{G}\vec{\tilde{F}}
\end{align*}

\end_inset

Daraus folgt:
\begin_inset Formula 
\begin{align*}
MLE\left(\vec{\tilde{F}}\right) & =max\left(\frac{1}{\left(2\pi\right)^{\frac{n}{2}}|\mathbf{Cov}|^{\frac{1}{2}}}e^{-\frac{1}{2}\left(\overrightarrow{y}-\mathbf{G}\vec{\tilde{F}}\right)^{T}\mathbf{Cov}^{-1}\left(\overrightarrow{y}-\mathbf{G}\vec{\tilde{F}}\right)}\right)
\end{align*}

\end_inset

Mit dieser Gleichung lässt sich der gesuchte Erwartungswertvektor 
\begin_inset Formula $\vec{\tilde{F}}$
\end_inset

 des Kriging Prozesses innerhalb des Trainings analytisch bestimmen.
 Die Lösung sieht wie folgt aus, wobei der komplette Lösungsweg in Anhang
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Likelihood-Schätzer-Erwartungswe"

\end_inset

 zu finden ist:
\begin_inset Formula 
\begin{align*}
\left(\overrightarrow{y}^{T}\mathbf{Cov}^{-1}\mathbf{G}\right)\left(\mathbf{G}^{T}\mathbf{Cov}^{-1}\mathbf{G}\right)^{-1} & =\vec{\tilde{F}}^{T}
\end{align*}

\end_inset


\end_layout

\begin_layout Paragraph*
Varianz
\end_layout

\begin_layout Standard
Die direkte analytische Bestimmung der Varianz im Falle des Co-Kriging Verfahren
s ist mit der hier gewählten Formulierung nicht möglich.
 Es ist allerdings eine iterative Bestimmung möglich, diese Art der Bestimmung
 wird in Anhang 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Iterative-VarianzbestimmungTraining"

\end_inset

 beschrieben und bringt allerdings viele numerische Probleme mit sich und
 wurde aus diesem Grund nicht verwendet.
 Innerhalb dieses Verfahrens wurden die Varianzen als zusätzlicher Hyperparamete
r innerhalb des Trainings freigegeben und werden dann über das Training
 bestimmt.
 Die Ableitung des Likelihood-Terms aus Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:AbleitungLogLikelihood"

\end_inset

 besitzt auch für die Varianz Gültigkeit.
\end_layout

\begin_layout Subsection
Initialisierung der Hyperparameter für alle Kriging Modelle 
\begin_inset CommandInset label
LatexCommand label
name "sec:Initialisierung-der-Hyperparamet"

\end_inset


\end_layout

\begin_layout Standard
Um das Training starten zu können, ist eine geeignete Initialisierung der
 Hyperparameter von großer Bedeutung.
 Diese kann die Konvergenz und auch die Stabilität der Minimierung stark
 beeinflussen.
 Innerhalb dieser Arbeit wurden mehrere Ansätze entwickelt, um eine geeignete
 Initialisierung zu finden.
 
\end_layout

\begin_layout Subsubsection*
Allgemeine Vorbemerkungen und Definitionen
\end_layout

\begin_layout Paragraph*
Normalisierung der Daten
\end_layout

\begin_layout Standard
Die innerhalb dieser Arbeit entwickelte Software nimmt intern eine Normalisierun
g der Daten vor.
 Dabei werden die Funktionswerte 
\begin_inset Formula $\overrightarrow{y}_{s}\in\mathbb{R^{\mathrm{n_{all}}}}$
\end_inset

 als auch die Parameter 
\begin_inset Formula $\vec{x}\in\mathbb{R^{\mathrm{k}}}$
\end_inset

 standardnormalverteilt normalisiert.
\begin_inset Formula 
\begin{align}
E[\overrightarrow{y}_{s}]=0\nonumber \\
var[\overrightarrow{y}_{s}]=1\label{eq:NormalisierungYs}\\
\begin{array}{c}
E[x_{i}]=0\\
var[x_{i}]=1
\end{array} & \forall x_{i},i\in\{1,...,k\}
\end{align}

\end_inset

Ändert sich jedoch die Datenbasis für das Training und damit auch die Normalisie
rungskonstanten, so müssen die Hyperparameter renormalisiert werden, in
 Anhang 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Renormalisierung-der-Hyperparame"

\end_inset

 wird eine solche Renormalisierung beschrieben.
 
\end_layout

\begin_layout Paragraph
Aufteilung der Hyperparameter in Klassen
\end_layout

\begin_layout Standard
\begin_inset Wrap table
lines 0
placement o
overhang 0col%
width "50col%"
status open

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Zeichen
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Anzahl 
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Korrelationsl.
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\vec{\theta}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $s$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Varianzen
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\sigma^{2}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $s$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Diagonalauf.
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\lambda$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $s$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Skalierung
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $a$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $s-1$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:Kategorien-von-Hyperparametern"

\end_inset

Kategorien von Hyperparametern bei 
\begin_inset Formula $s$
\end_inset

 Gütestufen
\end_layout

\end_inset


\end_layout

\end_inset

Die in den vorhergehenden Kapiteln 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Die-Kriging-Verfahren"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Kovarianzmatrix"

\end_inset

 und 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:RegularisierungUndRauschen"

\end_inset

 beschriebenen Hyperparameter lassen sich in Kategorien aufteilen, diese
 sind in Tabelle 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Kategorien-von-Hyperparametern"

\end_inset

 aufgelistet.
 
\end_layout

\begin_layout Standard
Diese Einteilung ist für die Initialisierung sehr wichtig, da jede dieser
 Gruppen anders initialisiert werden muss.
 Für die Diagonalaufschläge 
\begin_inset Formula $\lambda$
\end_inset

 wird das in Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Regularisierung"

\end_inset

 beschriebene Verfahren verwendet und wird daher innerhalb dieses Abschnittes
 nicht weiter beschrieben.
 
\end_layout

\begin_layout Subsubsection*
Abschätzung konstanter Hyperparameter 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Const"

\end_inset


\end_layout

\begin_layout Standard
Eine einfache und schnelle Methode eine Initialisierung für die Hyperparameter
 zu wählen, ist in 
\begin_inset CommandInset citation
LatexCommand cite
key "schmitz2013"

\end_inset

 beschrieben.
 Dafür wird für die Hyperparameter nur ein konstanter Wert verwendet und
 obere und untere Grenzen 
\begin_inset Formula $\theta_{min},\theta_{max}\in\mathbb{R}$
\end_inset

 bestimmt.
 
\begin_inset Formula 
\begin{align}
\theta & =\theta_{i}\forall i\in\{1,...,o\}\\
\theta_{min} & \leq\theta\leq\theta_{max}\nonumber 
\end{align}

\end_inset

Danach werden zwischen diesen Grenzen einige Werte ausprobiert und der Likelihoo
d Term berechnet und letztlich der Satz mit dem besten Likelihood-Term verwendet.
 
\end_layout

\begin_layout Standard
Zur Bestimmung der minimalen und maximalen Grenze wird das in 
\begin_inset CommandInset citation
LatexCommand cite
key "schmitz2013"

\end_inset

 beschriebene Verfahren verwendet:
\begin_inset Formula 
\begin{align}
\log\left(-\frac{\log\left(0.99\right)}{k}\right) & =\theta_{min}\label{eq:ConstThetaSchatzung-1}\\
\log\left(-\log\left(0.01\right)\right) & =\theta_{max}\label{eq:ConstThetaSchatzung-1-1}
\end{align}

\end_inset


\end_layout

\begin_layout Subsubsection*
Zufällige Initialisierung der Hyperparameter
\begin_inset CommandInset label
LatexCommand label
name "subsec:RandomInit"

\end_inset


\end_layout

\begin_layout Standard
Eine weitere Möglichkeit zur Initialisierung der Hyperparameter, liegt in
 der zufälligen Erzeugung von Parametersätzen.
 Hierfür werden eine gewisse Anzahl an zufälligen Hyperparametersätzen erzeugt
 und mit der Likelihood-Funktion bewertet.
 Die Grenzen für die Korrelationslängen sind dieselben wie in Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Const"

\end_inset

.
 
\end_layout

\begin_layout Standard
Die Skalierungsfaktoren werden innerhalb folgender Grenzen variiert:
\begin_inset Formula 
\begin{align}
0.75 & \leq a\leq1.5
\end{align}

\end_inset

Die zufällige Variation wird mit einer Gleichverteilung realisiert.
 Letztlich wir dann der Parametersatz gewählt, welcher die die beste Likelihood
 Funktion aufweist.
 Die Wahrscheinlichkeit einen sinnvollen Parametersatz zu finden, ist bei
 diesem Verfahren allerdings sehr klein.
 
\end_layout

\begin_layout Subsubsection*
Zufällige Initialisierung der Hyperparameter mit Vererbung
\begin_inset CommandInset label
LatexCommand label
name "subsec:RandomInit2"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Wrap table
lines 0
placement O
overhang 0in
width "52col%"
status open

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Zeichen
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\sigma_{search}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Korrelationsl.
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\vec{\theta}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.05\left|\theta_{max}-\theta_{min}\right|$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Varianzen
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\sigma^{2}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.25$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Skalierung
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $a$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0.1$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:Kategorien-von-Hyperparametern-1"

\end_inset

Kategorien von Hyperparametern und die verwendete Suchbreite
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Um das zufällige Initialisierungsverfahren zu beschleunigen, kann nur ein
 Wert für die Korrelationslängen einer Gütestufe 
\begin_inset Formula $k\in\{1,...,s\}$
\end_inset

 angenommen werden:
\begin_inset Formula 
\begin{equation}
\theta_{k}=\theta_{i,k}\forall i\in\{1,...,o\}
\end{equation}

\end_inset

Nachdem ein erster erfolgreicher Parametersatz 
\begin_inset Formula $\theta_{k,best}$
\end_inset

 gefunden wurde, wird ausgehend von diesem Satz normalverteilt variiert.
 Dadurch kann eine schnellere Konvergenz erreicht werden.
\begin_inset Formula 
\begin{equation}
\theta_{k}=\mathcal{N}(\theta_{k,best},\sigma_{search})
\end{equation}

\end_inset

Die Standardabweichung 
\begin_inset Formula $\sigma_{search}$
\end_inset

 der Normalverteilung gibt in diesem Fall die Suchbreite an, je größer der
 Wert, desto weiträumiger wird gesucht.
 Der Skalierungsfaktor 
\begin_inset Formula $a$
\end_inset

 und die Prozessvarianzen werden auf die selbe Art und Weise variiert.
 Tabelle 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Kategorien-von-Hyperparametern-1"

\end_inset

 stellt die Suchweiten dar, wobei diese auf Erfahrungswerten beruhen.
 Der Skalierungsfaktor und auch die Prozessvarianz werden bei der Initialisierun
g mit 
\begin_inset Formula $\sigma^{2}=1;a=1$
\end_inset

 belegt.
 Die Initialisierung der Prozessvarianz folgt aufgrund der Normalisierung
 aus Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:NormalisierungYs"

\end_inset

.
\end_layout

\begin_layout Subsubsection*
Initialisierung auf Basis bereits vorhandener Kriging Modelle
\begin_inset CommandInset label
LatexCommand label
name "subsec:UltraRestart"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Wrap figure
lines 31
placement o
overhang 0in
width "45col%"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../images/UltraRestart/Vergleich.png
	lyxscale 15
	scale 15

\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Graphics
	filename ../images/UltraRestart/VergleichTrainingsZeit.png
	lyxscale 15
	scale 15

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:RestartRandomLikelihood"

\end_inset

Vergleich verschiedener Initialisierungsverfahren und deren Auswirkung auf
 eine Testoptimierung
\end_layout

\end_inset


\end_layout

\end_inset

Das Kriging Modell wird in der Regel innerhalb einer Optimierung verwendet.
 Dies bedeutet im Normalfall, dass mehrfach trainiert wird und so die Hyperparam
eter neu bestimmt werden.
 Grundsätzlich wäre es sinnvoll die Hyperparameter aus den letzten trainierten
 Modellen zur Initialisierung zu verwenden.
 Als einfacher Ansatz wäre es z.B.
 möglich die Hyperparameter aus dem letzten Training zu Initialisierung
 zu verwenden.
 Diese Art der Wiederverwendung von alten Trainings ist für das Kriging
 Verfahren ohne Probleme möglich.
 
\end_layout

\begin_layout Standard
Bei der Wiederverwendung alter Hyperparametersätz müssen jedoch zwei Problemstel
lungen beachtet werden:
\end_layout

\begin_layout Enumerate
Das letzte Modell befindet sich in einem lokalen Minimum der Likelihood
 Funktion
\end_layout

\begin_layout Enumerate
Die Hyperparameter der Kovarianz Funktion(en) sind noch nicht richtig eingestell
t
\end_layout

\begin_layout Standard
Im ersten Fall besteht die Gefahr, dass das Training durch die ungünstige
 Initialisierung in einem lokalen Minimum bleibt und so nicht die optimalen
 Hyperparameter findet.
 Das wiederum führt zu schlechten Vorhersagen.
 Im Extremfall kann es sogar passieren, dass das lokale Minimum während
 der gesamten Optimierung nicht mehr verlassen wird.
 
\end_layout

\begin_layout Standard
Der zweite Fall ist insbesondere am Anfang der Optimierung interessant,
 denn am Anfang hat man in der Regel nur wenig Samples zur Verfügung und
 damit ist es dem Kriging Training noch nicht möglich die richtigen Hyperparamet
er für die Kovarianzfunktion zu schätzen.
 Diese Fälle treten erfahrungsgemäß leider sehr häufig auf, deshalb sollte
 man auf diese Art der Initialisierung verzichten.
\end_layout

\begin_layout Standard
Eine rein zufällige Initialisierung hat allerdings den Nachteil, dass die
 Trainingszeit enorm steigt und die Modelle im Laufe der Optimierung sehr
 unterschiedlich ausfallen können.
 Eineandere Möglichkeit der Initialisierung ist eine Mischform zwischen
 zufälliger Initialisierung und der Verwendung alter Modelle.
 In diesem Fall soll ein Kriterium darüber entscheiden, ob ein altes Kriging
 Modell verwendet werden soll oder eine zufällige Initialisierung durchgeführt
 werden soll.
 Zudem ist es sinnvoll nicht nur das letzte Kriging Modell zu betrachten,
 sondern noch weitere Modelle die während der Optimierung entstanden sind.
 Dies macht insbesondere Sinn, da das Ausprobieren eines vorhandenen Hyperparame
ter Satz im Vergleich zum Training nur einen Bruchteil der Zeit benötigt
 und man so einzelne 
\begin_inset Quotes eld
\end_inset

Ausreißer
\begin_inset Quotes erd
\end_inset

 in den Modellen nicht den weiteren Optimierungsverlauf gefährden.
 Der in AutoOpti verwendete Algorithmus sieht wie folgt aus:
\begin_inset listings
lstparams "numbers=left,basicstyle={\scriptsize},tabsize=4"
inline false
status open

\begin_layout Plain Layout

vector<string> krigingFiles = getLastKrigingFiles(20);
\end_layout

\begin_layout Plain Layout

if(krigingFiles.size() < 20){
\end_layout

\begin_layout Plain Layout

	initType = random;
\end_layout

\begin_layout Plain Layout

	end()
\end_layout

\begin_layout Plain Layout

} 			
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

for(i=0; i < krigingFiles.size() ; i++){
\end_layout

\begin_layout Plain Layout

	oldLikelihood = getLikelihood(krigingFiles[i])
\end_layout

\begin_layout Plain Layout

	newLikelihood = calculateLikelihood(krigingFiles[i])
\end_layout

\begin_layout Plain Layout

	if( (newLikelihood < bestLikelihood) 
\end_layout

\begin_layout Plain Layout

	and (newLikelihood < oldLikelihood) 
\end_layout

\begin_layout Plain Layout

	and (newLikelihood < -numberSamples/4.0) ){
\end_layout

\begin_layout Plain Layout

			bestLikelihood =newLikelihood
\end_layout

\begin_layout Plain Layout

			bestKrigingFile = krigingFiles[i]
\end_layout

\begin_layout Plain Layout

	}
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

if(bestKrigingFile==None) initType = random;
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Der Algorithmus startet mit dem Speichern der Dateinamen der letzten 20
 Kriging Modelle aus der laufenden Optimierung (Zeile 2).
 Sind noch keine 20 Kriging Modelle erzeugt worden, soll die Initialisierung
 zufällig erfolgen (Zeile 3-6).
 In der darauffolgenden for Schleife erfolgt nun die Bewertung der einzelnen
 Kriging Modelle.
 Für die Bewertung muss zuerst der alte Likelihood Wert ausgelesen werden,
 dies geschieht in Zeile 10.
 Im nächsten Schritt muss der Likelihood mit der aktuellen Datenbasis neu
 berechnet werden, in der Regel sind an dieser Stelle einige Member zur
 Datenbasis hinzugekommen.
 Dieser Schritt ist numerisch auch der aufwendigste, allerdings muss keine
 Invertierung 
\begin_inset Formula $\mathcal{O\left(\mathrm{n^{3}}\right)}$
\end_inset

 durchgeführt werden, sondern jeweils nur ein Gleichungssystem gelöst werden
 
\begin_inset Formula $\mathcal{O\left(\mathrm{n^{2}}\right)}$
\end_inset

.
 In der darauffolgenden If Abfrage geht es zum einen darum das beste Modell
 der 20 eingelesenen Kriging Modelle zu finden.
 Hierfür wird einfach der kleinste Likelihood verwendet (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Likelihood"

\end_inset

).
 Zudem ist eine weitere Bedingung, dass der neu berechnete Likelihood kleiner
 sein muss, als der bereits eingelesene aus dem vorhergehenden Modell.
 Die Überlegung hierbei ist, dass wenn ein neues Sample eingefügt wird und
 dieses nicht in die angenommene Verteilung passt, die Hyperparameter vollständi
g neu eingestellt werden müssen.
 Im umgekehrten Fall, sollte der Likelihood kleiner werden, da dieser linear
 mit der Sample Anzahl sinkt.
 Als letzte Bedingung ist eine absolute Grenze für den Likelihood Wert angegeben
, diese basiert rein auf Erfahrungswerten und soll sicherstellen, dass grundsätz
lich zu schlechte Modelle zufällig initialisiert werden.
 Dies ist meistens am Anfang einer Optimierung der Fall, wenn noch nicht
 genügend Daten vorhanden sind, um die Kovarianzfunktion ausreichend gut
 zu schätzen.
 In diesem Fall ist eine zufällige Initialisierung ebenfalls günstiger.
 Dieses Verfahren wird in der hier vorgestellten Implementierung als Standard
 verwendet und hat sich erfahrungsgemäß als sehr stabil und schnell erwiesen.
 Folgende Abbildung zeigt das Verfahren in Anwendung einer Testoptimierung,
 auf der Ordinate ist der erreichte Likelihoodterm (kleiner ist besser)
 und auf der Abzisse der Optimierungsschritt.
 
\end_layout

\begin_layout Subsection
Minimierungsverfahren 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Minimierungsverfahren"

\end_inset


\end_layout

\begin_layout Standard
Innerhalb des Kriging Modells wurden zwei verschiedene mehrdimensionale
 Minimierungsverfahren eingesetzt.
 Beide Verfahren waren bereits in einer institutseigenen Software Bibliothek
 verfügbar.
 
\end_layout

\begin_layout Subsection*
Minimierungsverfahren angelehnt an Resilient Backpropagation (RPROP)
\begin_inset CommandInset label
LatexCommand label
name "subsec:RPROP"

\end_inset


\end_layout

\begin_layout Standard
Das erste hier verwendete Minimierungsverfahren ist angelehnt an ein Trainingsve
rfahren für Neuronale Netzwerke, genannt RPROP (Resilient Backpropagation)
 
\begin_inset CommandInset citation
LatexCommand cite
key "riedmiller1993direct,NNSchiffmann"

\end_inset

 und ist ein Verfahren erster Ordnung.
 Besonderheit des Verfahrens ist, dass es nur das Vorzeichen der partiellen
 Ableitungen verwendet und nicht den Wert selbst.
 
\end_layout

\begin_layout Standard
Die Änderung der Hyperparameter 
\begin_inset Formula $\theta_{i}$
\end_inset

 für den nächsten Iterationsschritt 
\begin_inset Formula $t+1$
\end_inset

 ergibt sich aus der Schrittweite 
\begin_inset Formula $\gamma_{i}$
\end_inset

.
 Diese wird für jeden Hyperparameter einzeln bestimmt und in jeder Iteration
 geändert.
 Die Änderung hängt nur von dem Vorzeichen der entsprechenden partiellen
 Ableitung 
\begin_inset Formula $\frac{\partial f}{\partial\theta_{i}}$
\end_inset

 zum Zeitpunkt t der zu minimierenden Funktion 
\begin_inset Formula $f$
\end_inset

 ab.
\begin_inset Formula 
\begin{align*}
\theta_{i}^{t+1} & =\theta_{i}^{t}-\gamma_{i}^{t}\textrm{sgn}\left(\left(\frac{\partial f}{\partial\theta_{i}}\right)^{t}\right)
\end{align*}

\end_inset

Die Schrittweite wird in jedem Iterationsschritt für jeden Hyperparameter
 einzeln angepasst.
 Dies wird über zwei Multiplikatoren erzielt 
\begin_inset Formula $\eta^{+}=\left\{ \eta^{+}\in\mathbb{R}|1<\eta^{+}\right\} $
\end_inset

 und 
\begin_inset Formula $\eta^{-}=\left\{ \eta^{-}\in\mathbb{R}|1>\eta^{-}\right\} $
\end_inset

.
 Ist die entsprechende partielle Ableitung aus dem letzten Schritt multipliziert
 mit dem jetzigen Schritt größer als Null, wird die Schrittweite erhöht,
 indem die Schrittweite 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\lang english

\begin_inset Formula $\gamma_{i}^{t}$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
\lang ngerman
 multipliziert wird mit 
\begin_inset Formula $\eta^{+}$
\end_inset

.
 Wenn die partielle Ableitung aus dem letzten Schritt multipliziert mit
 dem jetzigen Schritt kleiner als Null ist, dann wird die Schrittweite verkleine
rt durch Multiplikation mit 
\begin_inset Formula $\eta^{-}$
\end_inset

.
 Für die Schrittweite wird zudem eine Unter- und Obergrenze (
\begin_inset Formula $\gamma_{min},\gamma_{max}$
\end_inset

) festgelegt.
 
\begin_inset Formula 
\begin{align*}
\gamma_{i}^{t+1} & =\begin{cases}
\min\left(\gamma_{i}^{t}\eta^{+},\gamma_{max}\right) & wenn\left(\frac{\partial f}{\partial\theta_{i}}\right)^{t}\left(\frac{\partial f}{\partial\theta_{i}}\right)^{t-1}>0\\
\max\left(\gamma_{i}^{t}\eta^{-},\gamma_{min}\right) & wenn\left(\frac{\partial f}{\partial\theta_{i}}\right)^{t}\left(\frac{\partial f}{\partial\theta_{i}}\right)^{t-1}<0\\
\gamma_{i}^{t} & sonst
\end{cases}
\end{align*}

\end_inset

Bei sehr flachen Bereichen der zu minimierenden Funktion, wo die partiellen
 Ableitungen nur sehr klein sind, würden andere Gradientenverfahren nur
 sehr langsam bis gar nicht mehr vorwärts kommen.
 Da dieses Verfahren allerdings die Größe der Gradienten überhaupt nicht
 berücksichtigt, kann dies nicht passieren.
 Das ist bei der Likelihood Funktion von besonderem Vorteil, da diese bereits
 durch Ihre Definition sehr viele flache Gebiete aufweist.
 
\end_layout

\begin_layout Subsection*
Erweiterung des RPROP-Verfahrens an sehr viele Hyperparameter
\begin_inset CommandInset label
LatexCommand label
name "subsec:RPROP2"

\end_inset


\end_layout

\begin_layout Standard
Ein sehr großes Problem bei dem RPROP Verfahren ist, dass es relativ viele
 Iterationen benötigt bis es konvergiert.
 In jedem Iterationsschritt muss zum einen der Dichtefunktionswert der Likelihoo
d Funktion berechnet werden und zum anderen die partiellen Ableitungen nach
 den Hyperparametern.
 Die Berechnung der Likelihood Funktion sowie die Berechnung einer partiellen
 Ableitung ist von der Komplexität 
\begin_inset Formula $\mathcal{O}\left(n^{2}\right)$
\end_inset

.
 Es müssen allerdings 
\begin_inset Formula $o$
\end_inset

 partielle Ableitungen gebildet werden, was bei einer großen Anzahl an Hyperpara
metern zu einem hohem numerischen Aufwand führt.
 Man kann sich innerhalb des RPROP-Verfahrens den Umstand zunutze machen,
 dass die Bestimmung des Dichtefunktionswerts bei einer hohen Anzahl an
 Hyperparametern vergleichsweise günstig ist.
 Besonders im Co-Kriging ist dieser Punkt wichtig, da die Anzahl der Hyperparame
ter erheblich größer ist, als bei einem Ordinary-Kriging.
 Folgend soll erläutert werden, wie sich dieser Umstand nutzen lässt:
\end_layout

\begin_layout Standard
Die Lernraten 
\begin_inset Formula $\eta^{+},\eta^{-}$
\end_inset

 sind im RPROP Verfahren konstant, insbesondere bei den anfänglichen Iterationss
chritten führt dies zu einem relativ langsamen Anpassen der Deltas 
\begin_inset Formula $\gamma_{i}^{t}$
\end_inset

.
 Es wäre daher wünschenswert die Lernraten ebenfalls anzupassen und dadurch
 eine schnellere Anpassung der Deltas 
\begin_inset Formula $\gamma_{i}^{t}$
\end_inset

 zu erreichen.
 Eine gute Möglichkeit ist es verschiedene Lernraten auszuprobieren, dadurch
 müssen zwar mehr Dichtefunktionsauswertungen gemacht werden, im Gegenzug
 werden aber weniger Iterationen benötigt und damit auch weniger Berechnungen
 der partiellen Ableitungen.
 Der folgende Pseudo Programmcode zeigt die Umsetzung des neuen Verfahrens:
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "basicstyle={\scriptsize},tabsize=4"
inline false
status open

\begin_layout Plain Layout

density = RPROPDensity(eta_plus, eta_minus)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

// Teste kleinere und größere Lernraten für eta_plus
\end_layout

\begin_layout Plain Layout

for(eta_plusFact=0.9; eta_plusFact<=1.1; eta_plusFact+=0.2){
\end_layout

\begin_layout Plain Layout

	newEtaPlus = eta_plus*eta_plusFact
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

	if(newEtaPlus<1.2)newEtaPlus=1.2
\end_layout

\begin_layout Plain Layout

	if(newEtaPlus>2.0)newEtaPlus=2.0
\end_layout

\begin_layout Plain Layout

	if(eta_plus==newEtaPlus)continue
\end_layout

\begin_layout Plain Layout

		
\end_layout

\begin_layout Plain Layout

	newDensity = RPROPDensity(newEtaPlus, eta_minus)
\end_layout

\begin_layout Plain Layout

	if(newDensity<density)eta_plus=newEtaPlus
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

// Teste kleinere und größere Lernraten für eta_minus
\end_layout

\begin_layout Plain Layout

for(eta_minusFact=0.9; eta_minusFact<=1.1; eta_minusFact+=0.2){
\end_layout

\begin_layout Plain Layout

	newEtaMinus = eta_minus*eta_minusFact
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

	if(newEtaMinus<0.4)newEtaMinus=0.4
\end_layout

\begin_layout Plain Layout

	if(newEtaMinus>0.7)newEtaMinus=0.7
\end_layout

\begin_layout Plain Layout

	if(eta_minus==newEtaMinus)continue
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

	newDensity = RPROPDensity(eta_plus, newEtaMinus)
\end_layout

\begin_layout Plain Layout

	if(newDensity<density)eta_minus=newEtaMinus
\end_layout

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
In einem Iterationsschritt, wird dann zuerst der Dichtefunktionswert  mit
 den bisherigen Lernraten 
\begin_inset Formula $\eta^{+},\eta^{-}$
\end_inset

 berechnet.
\end_layout

\begin_layout Standard
Danach wird dann 
\begin_inset Formula $\eta^{+}$
\end_inset

 leicht erhöht und auch verringert und der Dichtefunktionswert bestimmt.
 Sollte sich das neue 
\begin_inset Formula $\eta^{+}$
\end_inset

 nicht geändert haben, so wird sich die Berechnung der Dichtefunktion gespart.
 Gewählt wird die Lernrate mit dem geringsten Dichtefunktionswert.
 Für die Lernrate 
\begin_inset Formula $\eta^{-}$
\end_inset

 gilt im Prinzip dasselbe.
 
\end_layout

\begin_layout Standard
\begin_inset Wrap table
lines 0
placement o
overhang 0in
width "45col%"
status open

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
RPROP
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
RPROP2
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Zeit
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
346.3s
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
186s
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Mittl.
 Fehler
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.0201
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.0149
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Iterationen
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
781
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
398
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:Ergebnisse-beider-Verfahren"

\end_inset

Ergebnisse beider Verfahren im direkten Vergleich.
 Die Ergebnisse stellen den Mittelwert der 10 durchgeführten Trainings dar.
\end_layout

\end_inset


\end_layout

\end_inset

Für diese Art der Lernratenregelung sind maximal 4 neue Dichtefunktionsauswertun
gen notwendig, im Gegenzug hat man allerdings eine deutliche Verringerung
 der Iterationsanzahl und muss somit deutlich weniger partielle Ableitungen
 bestimmen.
 Diese sollte insbesondere für das CO-Kriging von großem Vorteil sein.
\end_layout

\begin_layout Standard
Um das Verfahren zu validieren, wurde eine Datenbasis aus einer aktuellen
 Optimierung für einen gegenläufigen Rotor verwendet (
\begin_inset CommandInset citation
LatexCommand cite
key "Lengyel-Kampmann2015"

\end_inset

).
 Es gab ca.
 113 freie Parameter und für das CO-Kriging somit 228 Hyperparameter (130*2
 und 2x die Prozessvarianzen der Kovarianzfunktionen) und die Datenbasis
 enthielt zu diesem Zeitpunkt 373 Member.
 Das CO-Kriging wurde mit zufälligen Hyperparametern initialisiert und 10x
 mit dem RPROP Verfahren trainiert und 10x mit dem neuen RPROP2 Verfahren.
 Die Vorhersagen der fertig trainierten Ersatzmodelle wurden dann anhand
 einer Testdatenbasis validiert und ein mittlerer Vorhersagefehler bestimmt.
 Tabelle 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Ergebnisse-beider-Verfahren"

\end_inset

 zeigt die Ergebnisse beider Verfahren.
\end_layout

\begin_layout Standard
\begin_inset Wrap figure
lines 0
placement o
overhang 0in
width "45col%"
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../images/RPROP2/Vergleich.png
	scale 17

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:RPROP_2_Verlauf"

\end_inset

Konvergenzverlauf der beiden Verfahren anhand eines Beispiels
\end_layout

\end_inset


\end_layout

\end_inset

Man kann sehen, dass das RPROP Verfahren in diesem Beispiel die 1.86 fache
 Zeit benötigt um Konvergenz zu erreichen.
 Dies wird hauptsächlich durch die deutlich geringere Iterationsanzahl erreicht.
 Die mittleren Fehler sind in etwa vergleichbar, die etwas geringeren Fehler
 beim RPROP2 sind mit hoher Wahrscheinlichkeit zufälliger Natur.
 Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:RPROP_2_Verlauf"

\end_inset

 zeigt nochmal den gemittelten Trainingsverlauf beider Verfahren.
 Die rote und schwarze Kurve stellt den mittleren Dichtefunktionswert über
 den Iterationsschritten dar.
 Die Fehlerbalken sind die Standardabweichungen der verschiedenen Trainings.
 Auch hier lässt sich gut erkennen, dass das RPROP2 Verfahren eine deutlich
 schnelleren Konvergenzverlauf hat, insbesondere am Anfang.
 Dies wird durch die schneller eingestellten Deltas erreicht.
 
\end_layout

\begin_layout Standard
Bei einem Verfahren wie dem Co-Kriging wo grundsätzlich eine hohe Anzahl
 an Hyperparametern zu erwarten ist, ist es sinnvoll ein solches Verfahren
 einzusetzen.
\end_layout

\begin_layout Subsection*
Quasi Newton
\begin_inset CommandInset label
LatexCommand label
name "subsec:Quasi-Newton"

\end_inset


\end_layout

\begin_layout Standard
Das zweite implementierte Minimierungsverfahren ist ein Verfahren höherer
 Ordnung namens Quasi Newton.
 Basis für diese Art der mehrdimensionalen Minimierung ist eine Taylor Approxima
tion zweiten Grades, wobei 
\begin_inset Formula $t$
\end_inset

 der Iterationsschritt ist und 
\begin_inset Formula $\mathbf{H}$
\end_inset

 die Hesse Matrix: 
\begin_inset Formula 
\begin{align*}
f\left(\vec{\theta}\right) & \approx f\left(\vec{\theta}_{t}\right)+\left(\vec{\theta}-\vec{\theta}_{t}\right)^{T}\nabla f\left(\vec{\theta}_{k}\right)+\frac{1}{2}\left(\vec{\theta}-\vec{\theta}_{t}\right)^{T}\mathbf{H}\left(\vec{\theta}_{t}\right)\left(\vec{\theta}-\vec{\theta}_{t}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Die entsprechende Ableitung dieser Funktion muss im Minimum oder Maximum
 der Funktion Null ergeben:
\begin_inset Formula 
\begin{align*}
\nabla f\left(\vec{\theta}\right) & \approx\nabla f\left(\vec{\theta}_{t}\right)+\mathbf{H}\left(\vec{\theta}_{t}\right)\left(\vec{\theta}-\vec{\theta}_{t}\right)=0
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Besonderheit bei der Quasi Newton Methode ist, dass die Hesse Matrix 
\begin_inset Formula $\mathbf{H}$
\end_inset

, nicht direkt berechnet werden muss, sondern sukzessive über die Gradienten
 angenähert wird.
 Vorteil des Verfahrens ist, dass es deutlich schneller konvergiert als
 das bereits vorgestellte Verfahren erster Ordnung.
 Allerdings ist es weniger robust und kann in flachen Gebieten der Funktion
 langsam bis gar nicht konvergieren.
 Die exakte Umsetzung des Algorithmus und weitere Details können in 
\begin_inset CommandInset citation
LatexCommand cite
key "press2007numerical,gill1981practical,gill2007numerical"

\end_inset

 gefunden werden.
 Die Erfahrung zeigt allerdings, dass die Verwendung des RPROP-Verfahrens
 erhebliche Vorteile bringt, da das Quasi-Newton Verfahren zu lokalen Minima
 tendiert und somit zu schlechteren Ersatzmodellen führt.
 
\end_layout

\begin_layout Subsection*
Vergleich QuasiNewton / RPROP / RPROP2 und Initialisierungsverfahren
\end_layout

\begin_layout Standard
In diesem Kapitel soll ein direkter Vergleich zwischen den verschiedenen
 Optimierungsverfahren angestellt werden.
 Hierfür wurde ein Testfall aus der Fanstufenoptimierung (siehe Kapitel
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:CRISP-Testfall"

\end_inset

) zusammengestellt.
 
\begin_inset Wrap table
lines 7
placement o
overhang 0in
width "50col%"
status open

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="2" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
RPROP
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
RPROP2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
QN
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
53.5s
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
42.83
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
12.7s
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:Mittlere-Trainingszeit-für"

\end_inset

Mittlere Trainingszeit für alle durchgeführten Trainings.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Trainingsfunktion: 
\begin_inset Formula $\dot{m}_{OP1}$
\end_inset

 (Massenstrom Betriebspunkt 1)
\end_layout

\begin_layout Itemize
Stützstellen (niedrige / hohe Güte): 300 / 500
\end_layout

\begin_layout Itemize
Testdatenbasis: 400 Stützstellen hoher Güte
\end_layout

\begin_layout Itemize
Maximal 1000 Trainingsiterationen
\end_layout

\begin_layout Itemize
20 Threads auf zwei Intel(R) Xeon(R) CPU E5-2650 v3
\end_layout

\begin_layout Itemize
Pro Testfall 10 aufeinanderfolgende Trainings
\end_layout

\begin_layout Itemize
Das Initialisierungsverfahren, ist das 
\begin_inset Quotes gld
\end_inset

Initialisierung auf Basis vorhandener Kriging Modelle
\begin_inset Quotes grd
\end_inset

 aus Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:UltraRestart"

\end_inset

.
 Das Verfahren nutzt 5 bereits trainierte Kriging Modelle
\end_layout

\begin_layout Standard
Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Ergebnisse-des-Testfalls."

\end_inset

 zeigt die Ergebnisse der 3 verschiedenen Testfälle.
 Aufgetragen ist jeweils der Wert des Likelihood-Terms, die Trainingszeit
 und der Testfehler.
 Nach 5 Iterationen startet die Initialisierung aus Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:UltraRestart"

\end_inset

, da ab diesem Zeitpunkt genügend alte Kriging-Modelle vorhanden sind.
 Dieser Übergang wird mit einer gestrichelten Linie gekennzeichnet.
 
\end_layout

\begin_layout Standard
Der Testfehler ist bei allen Verfahren auf einem ähnlich gutem Niveau (der
 Mittelwert des Massenstroms liegt bei 514 kg/s).
 Das RPROP2 Verfahren zeigt insgesamt den besten Testfehler.
 Das Quasi-Newton Verfahren zeigt bei Iteration 4 einen starken kurzfristigen
 Anstieg des Testfehlers.
 Bei diesem Training wurde der Skalierungsfaktor 
\begin_inset Formula $a$
\end_inset

 (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:COKrigingKovarianzmodell"

\end_inset

) falsch eingeschätzt und die Ergebnisse dadurch verzerrt.
 Der genaue Trainingsverlauf (hier nicht dargestellt) lässt auf ein lokales
 Minimum in der Likelihood Funktion schließen.
 Zu diesem Zeitpunkt war noch die zufällige Initialsierung aktiviert.
 Nachdem die 
\begin_inset Quotes gld
\end_inset

Initialsierung auf Basis vorhandener Kriging Modelle
\begin_inset Quotes grd
\end_inset

 aktiviert wurde, blieb der Testfehler bei allen Verfahren nahezu konstant.
 Der Anstieg des Testfehlers beim Quasi-Newton Verfahren lässt deshalb auf
 eine schlechte Initialsierung als Ursache schließen.
\end_layout

\begin_layout Standard
Die Verläufe des Likelihood-Terms ähneln sich bei den RPROP Verfahren sehr
 stark, beide Verfahren finden bereits in der Phase zufälliger Initialisierung
 direkt den optimalen Likelihood-Term.
 Das Quasi-Newton Verfahren ist in dieser Phase noch sehr instabil.
 
\end_layout

\begin_layout Standard
Die Trainingszeiten zwischen den Verfahren variieren in der 
\begin_inset Quotes gld
\end_inset

zufälligen
\begin_inset Quotes grd
\end_inset

 Phase noch sehr stark, in Tabelle 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Mittlere-Trainingszeit-für"

\end_inset

 werden die mittleren Trainingszeiten aufgelistet.
 Das RPROP2 Verfahren bietet einen Zeitersparnis von ca.
 20% gegenüber dem RPROP Verfahren und das QuasiNewton Verfahren einen Zeiterspa
rnis von ca.
 74% gegenüber dem RPROP Verfahren.
 Nach der 
\begin_inset Quotes gld
\end_inset

zufälligen
\begin_inset Quotes grd
\end_inset

 Phase sind die Trainingszeiten zwischen den Verfahren allerdings nahezu
 identisch.
 
\end_layout

\begin_layout Paragraph*
Fazit
\end_layout

\begin_layout Standard
Dieses Testbeispiel zeigt zum einen die Robustheit der beiden RPROP-Verfahren
 gegenüber dem Quasi-Newton Verfahren und zum anderen den enormen Nutzen
 des in dieser Arbeit entwickelten Intialisierungsverfahrens.
 Das Initialisierungsverfahren verbessert zum einen die Trainingszeit erheblich
 und zum anderen sorgt es auch für ein deutlich besseren Likelihood-Verlauf
 in allen Verfahren.
 
\end_layout

\begin_layout Standard
Aufgrund dieser Ergebnisse wird als Standardverfahren innerhalb der hier
 entwickelten Co-Kriging Software die 
\begin_inset Quotes gld
\end_inset

Initialisierung auf Basis vorhandener Kriging Modelle
\begin_inset Quotes grd
\end_inset

 und das RPROP2 Verfahren gewählt.
 Für den Ordinary- und Gradient-Enhanced-Modus der Kriging-Software wird
 allerdings das RPROP-Verfahren verwendet, da dieses bei einer geringeren
 Anzahl von Hyperparametern zeitlich besser abschneidet.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../images/SoftwareTechnUmsetzung/RandomRestartVergleich.eps
	scale 60

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Ergebnisse-des-Testfalls."

\end_inset

Ergebnisse des Testfalls.
 Dargestellt sind die Ergebnisse des Likelihoods, der Trainingszeit und
 des Testfehlers über den Trainingsiterationen.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Umsetzung der Entscheidungsfunktion
\begin_inset CommandInset label
LatexCommand label
name "sec:Umsetzung-der-Entscheidungsfunkt"

\end_inset


\end_layout

\begin_layout Standard
Die Berechnung der in dieser Arbeit entwickelten Entscheidungsfunktion (siehe
 Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Entscheidungsfunktion"

\end_inset

) benötigt die Berechnung einiger Variablen, deren numerische Bestimmung
 von zentraler Bedeutung ist, was die Effizienz und Stabilität des Verfahrens
 angeht.
\end_layout

\begin_layout Standard
Insbesondere sind hierbei die bedingten Varianzen 
\begin_inset Formula $\sigma_{hl}^{2}\left(\vec{x}\right),\sigma_{hh}^{2}\left(\vec{x}\right)$
\end_inset

 und die verschiedenen Zeiten 
\begin_inset Formula $T=\frac{t_{train}+t_{opti}+t_{prh}}{t_{train}+t_{opti}+t_{prl}}$
\end_inset

 von Bedeutung.
 Wie die genaue Berechnung innerhalb der hier entwickelten Software funktioniert
, soll in diesem Abschnitt erläutert werden.
\end_layout

\begin_layout Paragraph*
Bedingten Varianzen
\end_layout

\begin_layout Standard
Eine Möglichkeit die bedingten Varianzen abzuschätzen ist es, Vorhersagen
 niedriger Güte mit dem Ersatzmodell zu treffen und mit diesen Vorhersagen
 das Ersatzmodell neu zu trainieren und wieder neue Vorhersagen zu treffen.
 Diese Vorgehensweise ist softwaretechnisch allerdings sehr aufwendig und
 fehleranfällig.
\end_layout

\begin_layout Standard
Eine einfachere Möglichkeit ist es die Varianz 
\begin_inset Formula $\sigma_{hl}^{2}\left(\vec{x}\right)=\sigma_{h}^{2}\left(\vec{x}\right)\mid y_{l}\left(\vec{x}\right)$
\end_inset

 mithilfe einer bedingten Normalverteilung zu berechnen.
 Hierfür ist die bedingte Kovarianz 
\begin_inset Formula $\left.cov\left(Z_{l}\left(\vec{x}\right),Z_{h}\left(\vec{x}\right)\right)\right|\vec{y},\vec{w}$
\end_inset

 (siehe Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:KovarianzPredictor"

\end_inset

) zwischen den verschiedenen Gütestufen 
\begin_inset Formula $h,l$
\end_inset

 an dem Ort 
\begin_inset Formula $\vec{x}\in\mathbb{R}^{k}$
\end_inset

 unter der Bedingung aller bekannten Daten 
\begin_inset Formula $\vec{y}$
\end_inset

 und Gewichte 
\begin_inset Formula $\vec{w}$
\end_inset

 (genaue Definition siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Co-Kriging"

\end_inset

).
 So gilt für 
\begin_inset Formula $\sigma_{h}^{2}\left(\vec{x}\right)$
\end_inset

 bei Annahme einer Multivariaten Normalverteilung und unter der Kenntnis
 einer Stützstelle niedriger Güte 
\begin_inset Formula $y_{l}\left(\vec{x}\right)$
\end_inset

 folgender Zusammenhang:
\begin_inset Formula 
\begin{equation}
\sigma_{h}^{2}\left(\vec{x}\right)\mid y_{l}\left(\vec{x}\right)=\sigma_{h}^{2}\left(\vec{x}\right)-\frac{\left(cov\left(Z_{l}\left(\vec{x}\right),Z_{h}\left(\vec{x}\right)\right)|w,y_{all}\right)^{2}}{\sigma_{l}^{2}\left(\vec{x}\right)}\label{eq:BedingteNormalVertilung}
\end{equation}

\end_inset


\end_layout

\begin_layout Paragraph*
Berechnung der Zeiten
\end_layout

\begin_layout Standard
Grundlegend gibt es für die Entscheidungsfunktion drei verschiedene Zeiten,
 welche berechnet werden müssen.
 
\end_layout

\begin_layout Enumerate
Die Trainingszeit 
\begin_inset Formula $t_{train}$
\end_inset

 
\end_layout

\begin_layout Enumerate
Die Zeit für die Optimierung auf dem Ersatzmodell 
\begin_inset Formula $t_{opti}$
\end_inset


\end_layout

\begin_layout Enumerate
Die Prozesskettenzeit 
\begin_inset Formula $t_{pr}$
\end_inset

, wobei es für jede Gütestufe eine einzelne Zeit gibt.
\end_layout

\begin_layout Standard
Die Zeiten zu bestimmen ist kein großes Problem, da diese innerhalb der
 Optimierung gemessen und gespeichert werden.
 So hat man zumindest die vergangenen Zeiten und kann damit Schätzungen
 anstellen.
 Da diese Zeiten innerhalb der Optimierung sehr stark schwanken können und
 weiterhin einen sehr erheblichen Anteil in der Entscheidungsfunktion besitzen,
 ist es sinnvoll einen Mittelwert aus den vergangenen Zeiten zu bilden.
 Allerdings stellt sich dabei die Frage, wie viele vergangene Zeiten in
 das Mittel aufgenommen werden sollen.
 Hierbei sollte unterschieden werden: 
\end_layout

\begin_layout Standard
Die Prozesskettenzeit 
\begin_inset Formula $t_{pr}$
\end_inset

 ändert sich während einer laufenden Optimierung in der Regel nur unwesentlich,
 da die Prozesskette sich während der Optimierung nicht ändert.
 Bei CFD-Optimierungn ist oftmals eine kleine Reduktion der Prozesskettenzeit
 zum Ende einer Optimierung zu beobachten, da die Member sich dem Optimum
 nähern und somit schneller konvergieren.
 Allerdings ist dies nicht immer der Fall und die zeitliche Differenz nicht
 ausschlaggebend.
 Aus diesem Grund wird in der hier entwickelten Software, das Mittel aus
 allen bereits gemessenen Prozesskettenzeiten 
\begin_inset Formula $t_{pr,i},i\in\{1,...,n\}$
\end_inset

, wobei 
\begin_inset Formula $n$
\end_inset

 die Anzahl aller bisher berechneten Member der betrachteten Gütestufe angibt.
 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
t_{pr}=\frac{1}{n}\stackrel[i=1]{i\leq n}{\sum}t_{pr,i}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Die Trainingszeit 
\begin_inset Formula $t_{train}$
\end_inset

, sowie die Zeit für die Optimierung auf dem Ersatzmodell 
\begin_inset Formula $t_{opti}$
\end_inset

 ändern sich im Verlauf der Optimierung stetig.
 Typischerweise wachsen diese mit steigender Stützstellenanzahl an.
 Verwendet man bswp.
 eine Restart Methode wie die in dieser Arbeit entwickelte (siehe Kapitel
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:UltraRestart"

\end_inset

), dann kann die Trainingszeit schlagartig fallen.
 Aufgrund dieser starken zeitlichen Schwankungen ist es sinnvoller, für
 den Mittelwert der Zeit nur eine kleine Anzahl 
\begin_inset Formula $m$
\end_inset

 an bereits gemessenen Zeiten zu verwenden: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
t_{train} & =\frac{1}{m}\stackrel[i=1]{i\leq m}{\sum}t_{train,(n-i)}\\
t_{opti} & =\frac{1}{m}\stackrel[i=1]{i\leq m}{\sum}t_{opti,(n-i)}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Standardeinstellung in der hier entwickelten Software ist eine Anzahl von
 
\begin_inset Formula $m=15$
\end_inset

, diese hat sich für die meisten Anwendungen als günstig erwiesen.
 
\end_layout

\begin_layout Paragraph*
Minimale Menge an Membern hoher Güte 
\begin_inset CommandInset label
LatexCommand label
name "par:Minimale-Menge-an"

\end_inset


\end_layout

\begin_layout Standard
Es kann vorkommen, dass die HF und LF Funktionen so stark korreliert sind,
 dass die Entscheidungsunktion sich nur noch für die Prozessketten niedriger
 Güte entscheidet.
 Grundlegend ist dieses Verhalten auch sinnvoll und erwünscht.
 Jedoch interessiert den Anwender letztendlich das Ergebnis hoher Güte.
 Aus diesem Grund wird der Volume-Gain-Term im Raum hoher Güte berechnet.
 Um es kurz zu beschreiben: 
\shape italic
Mit einem Member niedriger Güte kann kein Volumenzugewinn erreicht werden,
 es wird nur das Ersatzmodell verbessert.
 
\end_layout

\begin_layout Standard
Aus diesem Grund ist es sinnvoll eine Mindestrate von Membern hoher Güte
 vorzugeben.
 In der hier entwickelten Software wird dafür ein prozentualer Anteil hoher
 Güte (HFProzent Soll) vorgegeben.
 Wird dieser Anteil unterschritten, so soll ein Member hoher Güte erzwungen
 werden.
 Um die Entscheidungsfunktion aber nicht vollständig zu umgehen, soll bei
 besonders aussichtsreichen Membern weiterhin möglich sein, einen Member
 niedriger Güte zu berechnen.
 
\end_layout

\begin_layout Standard
Algorithmus 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:Vorgabe-eines-minimalen"

\end_inset

 beschreibt den Ablauf dieser Auswahl.
 Die Grundidee ist es, die Grenze für das Entscheidungskriterium (KriteriumGrenz
e) auf einen höheren Wert zu setzen und damit die Wahrscheinlichkeit für
 die Wahl eines Members hoher Güte zu erhöhen.
 Dafür werden als erstes die aktuellen Anteile hoher Güte bestimmt (HFProzentIst
) und dann das Maximum der letzten 10 berechneten Entscheidungskriterien
 (Kriterium10Max) bestimmt.
 Die neue Grenze für das Kriterium wird dann so entschieden:
\end_layout

\begin_layout Itemize
Ist die Differenz zwischen Soll und Ist HF Prozentsatz größer als 0% aber
 kleiner als 5% 
\end_layout

\begin_deeper
\begin_layout Itemize
Setze das Kriterium auf das Maximum der letzten 10.
 Die Wahrscheinlichkeit für einen HF Member ist also sehr hoch, bekommt
 das Entscheidungskriterium aber einen Member welcher einen höheren Wert
 als die letzten 10 hatte, so kann trotzdem nochmal ein LF Member erzeugt
 werden.
 Die soll verhindern, dass besonders gute LF Member verworfen werden.
\end_layout

\end_deeper
\begin_layout Itemize
Ist die Differenz zwischen Soll und Ist HF Prozentsatz größer als 5% 
\end_layout

\begin_deeper
\begin_layout Itemize
Erzwinge einen HF Member#
\end_layout

\end_deeper
\begin_layout Standard
Dieser Algorithus sorgt im Normalfall für eine gleichmäßige Berechnung von
 Membern hoher Güte.
 Bei einem besonders aussichtsreichen Member niedriger Güte, kann dieser
 aber noch vorgezogen werden.
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "float"
inline false
status open

\begin_layout Plain Layout

HFProzentSoll   	= holeUserInput()
\end_layout

\begin_layout Plain Layout

HFProzentIst        = holeAktuellenHFAnteilInProzent()
\end_layout

\begin_layout Plain Layout

Kriterium10 		= holeLetze10EntscheidungsKriterien()
\end_layout

\begin_layout Plain Layout

Kriterium10Max 	 = Maximum(Kriterium10)
\end_layout

\begin_layout Plain Layout

KriteriumAktuell	= Entscheidungsfunktion()
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

KriteriumGrenze = Kriterium10Max
\end_layout

\begin_layout Plain Layout

Wenn  (HFProzentIst > HFProzentSoll) oder (Kriterium10Max < 1.0) 
\end_layout

\begin_layout Plain Layout

	KriteriumGrenze = 1.0
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

Wenn (HFProzentSoll-HFProzentIst>0.05)
\end_layout

\begin_layout Plain Layout

	KriteriumGrenze = inf	
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "alg:Vorgabe-eines-minimalen"

\end_inset

Vorgabe eines minimalen Anteils Member hoher Güte
\end_layout

\begin_layout Paragraph
Umschalten auf HF bei einem sehr guten Ersatzmodell
\begin_inset CommandInset label
LatexCommand label
name "par:Umschalten-auf-HF"

\end_inset


\end_layout

\begin_layout Standard
Die Vorhersagefehler der Ersatzmodelle gehen bei ausreichender Anzahl an
 Stützstellen nahezu gegen 0.
 Dieser Zustand kann für einzelne Ersatzmodelle vorkommen, wenn eine sehr
 hohe Anzahl an Stützstellen erreicht wurde oder wenn die zu lernende Funktion
 besonders einfach ist.
 Trifft zusätzlich der Umstand ein, dass die Korrelation zwischen hoher
 und niedriger Güte extrem hoch ist, so könnte es passieren, dass die Entscheidu
ngsfunktion sich zu oft für die Prozesskette niedriger Güte entscheidet.
 
\end_layout

\begin_layout Standard
Um die Problematik zu verdeutlichen soll ein Gedankenexperiment helfen:
 Angenommen es soll eine Funktion optimiert werden, welche von dem Ersatzmodell
 bereits nach der Initialisierungsphase perfekt gelernt wurde.
 Zusätzlich sind die niedrige und hohe Gütestufe nahezu vollständig korreliert,
 die niedriger Gütestufen ist aber deutlich schneller.
 Der Optimierungsalgorithmus wäre also in der Lage, das Optimum sofort finden
 zu können.
 Typischerweise möchte der Anwender aber das hochwertigste Ergebnis, da
 dieses das Vertrauenswürdigste darstellt.
 Die Entscheidungsfunktion sollte also bei ausreichender Genauigkeit eher
 zu Entscheidungen hoher Güte tendieren.
\end_layout

\begin_layout Standard
Um ein solches Verhalten automatisiert zu verwirklichen wird vor dem eigentliche
n Aufruf der Entscheidungsfunktion der Quotient aus vorhersagter Standardabweich
ung 
\begin_inset Formula $\sigma_{h}\left(\vec{x}\right)$
\end_inset

 und der globalen Standardabweichung aller bekannten Stützstellen 
\begin_inset Formula $\sigma_{h,all}$
\end_inset

 ins Verhältnis gesetzt: 
\begin_inset Formula $\frac{\sigma_{h}\left(\vec{x}\right)}{\sigma_{h,all}}$
\end_inset

 
\end_layout

\begin_layout Standard
Für diesen Fall wurde die Standardabweichung gegenüber der Varianz bevorzugt,
 da diese in der Größenordnung der Funktion selbst liegt und somit für den
 Anwender einfacher zu interpretieren ist.
\end_layout

\begin_layout Standard
Der Anwender hat nun die Möglichkeit eine Grenze für dieses Verhältnis anzugeben.
 Wird diese Unterschritten, so wird diese Funktion nicht für die Entscheidung
 berücksichtigt und erhöht somit nicht den Wert des Entscheidungskriteriums.
 Werden dadurch bspw.
 alle Funktionen nicht berücksichtigt, so würde das Kriterium Null werden
 und sich zugunsten der hochwertigeren Prozesskette entscheiden.
\end_layout

\begin_layout Standard
Typische Werte sind 1%, allerdings ist dieser Wert sehr Anwendungs- und
 Anwender-spezifisch.
 Der Anwender hat so auch die Möglichkeit die Optimierung frühzeitig in
 Richtung hoher Güte zu bringen, indem er diesen Wert erhöht.
 
\end_layout

\begin_layout Section

\color magenta
WEG ? ODer am Ende oder Anfang ????
\color inherit
CO-Kriging - Vergleich zu anderen Verfahren 
\begin_inset CommandInset label
LatexCommand label
name "sec:VergleicheCoKrigingAndere"

\end_inset


\end_layout

\begin_layout Subsection
Unterschiede im mathematischen Modell und Trainingsverfahren
\end_layout

\begin_layout Standard
Die Co-Kriging Theorie für die in dieser Arbeit entwickelte Co-Kriging Software,
 entspricht in vielen Punkten der einschlägigen Literatur.
 In einigen Punkten gibt es allerdings Unterschiede, welche Auswirkungen
 auf das 
\end_layout

\begin_layout Itemize
Diagonalaufschlag Behandlung ist anders als bei anderen, wird außen als
 ganze Varianz addiert in der Kov Matrix.
 Dadurch ist es möglich dass Low Fid.
 komplett verreuscht ist und keinen Inhalt hat.
 bei der Formulierung (corr+diag)*sigma ist das nicht möglich
\end_layout

\begin_layout Standard
In diesem Abschnitt sollen Unterschiede und Gemeinsamkeiten zu einigen anderen
 Co-Kriging Verfahren aus der einschlägigen Literatur herausgestellt werden.
 Eine grundlegende Arbeit in diesem Bereich stellt die Veröffentlichung
 von 
\begin_inset CommandInset citation
LatexCommand cite
key "Kennedy2000"

\end_inset

 dar.
 Das dort beschriebene Modell ist dem in dieser Arbeit in sehr vielen Punkten
 ähnlich.
 Beispielsweise ist das Kovarianzmodell dasselbe wie in Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:COKrigingKovarianzmodell"

\end_inset

 beschrieben.
 Damit gleichen sich der Aufbau der Kovarianzmatrix 
\begin_inset Formula $\mathbf{Cov}\in\mathbb{R^{\mathrm{n_{all}}\times\textrm{n_{all}}}}$
\end_inset

 und außerdem ähnelt die analytische Bestimmung des Erwartungswertvektors
 
\begin_inset Formula $\overrightarrow{F}\in\mathbb{R^{\mathrm{n_{all}}}}$
\end_inset

 der Bestimmung aus Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:CoKrigingAnalytische-Bestimmung-derErwwartzungswerte"

\end_inset

.
 Allerdings beinhaltet der Erwartungswertvektor bei 
\begin_inset CommandInset citation
LatexCommand cite
key "Kennedy2000"

\end_inset

 die Erwartungswerte der höchsten Gütestufe und die der Differenzfunktion
 (vgl.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Kennedy2000"

\end_inset

 Gleichung 4 und 5).
 In der hier verwendeten Formulierung entspricht der Differenzerwartungswert
 dem Erwartungswert der niedrigen Gütestufe selbst.
 Dieser Unterschied ist aber nur unwesentlich, da das Ergebnis davon unberührt
 bleibt.
 
\end_layout

\begin_layout Standard
Größere Unterschiede zeigen sich im Trainingsverfahren und zwar gilt bei
 
\begin_inset CommandInset citation
LatexCommand cite
key "Kennedy2000"

\end_inset

 die Bedingung, dass an jeder Stützstelle hoher Güte auch eine Stützstelle
 niedriger Güte bekannt sein muss.
 Dies resultiert aus der Annahme, dass die Daten und damit auch die Hyperparamet
er niedrigerer Güte, unabhängig von den Daten hoher Güte trainierbar sind.
 
\end_layout

\begin_layout Standard
Durch diese Annahme kann man die Hyperparameter für die Gütestufen hierarchisch
 (Bottom-Top) bestimmen.
 Das Training der Hyperparameter wird dadurch vereinfacht und auch der numerisch
e Aufwand sinkt dadurch, da man zwei unabhängige Trainings durchführt mit
 jeweils einer Kovarianzmatrix der Größe des jeweiligen Datensatzes.
 Als Beispiel müssten bei einer Anzahl von 
\begin_inset Formula $n_{high}$
\end_inset

 High-Fidelity und 
\begin_inset Formula $n_{low}$
\end_inset

 Low-Fidelity Stützstellen jeweils ein Training mit den Kovarianzmatrizen
 
\begin_inset Formula $\mathbf{Cov_{high}}\in\mathbb{R^{\mathrm{n_{high}\times n_{high}}}}$
\end_inset

 und 
\begin_inset Formula $\mathbf{Cov_{low}}\in\mathbb{R^{\mathrm{n_{low}\times n_{low}}}}$
\end_inset

 durchgeführt werden.
 Die Komplexität liegt dann bei etwa 
\begin_inset Formula $\mathcal{O}\left(n_{high}^{3}\right)+\mathcal{O}\left(n_{low}^{3}\right)$
\end_inset

.
 
\end_layout

\begin_layout Standard
In dem hier beschrieben Verfahren werden alle Hyperparameter gleichzeitig
 trainiert, wodurch die Stützstellen der unterschiedlichen Gütestufen beliebig
 verteilt sein können.
 Es muss also nicht an jedem Punkt hoher Güte auch ein Punkt niedriger Güte
 vorhanden sein.
 Der numerische Aufwand steigt dadurch allerdings, da die gesamte Kovarianzmatri
x zerlegt werden muss und auch alle Hyperparameter gleichzeitig trainiert
 werden.
 Die Komplexität liegt dann bei 
\begin_inset Formula $\mathcal{O}\left(\left(n_{high}+n_{low}\right)^{3}\right)$
\end_inset

.
 Dennoch wird dies als zeitlicher Vorteil erachtet, da der Zeitaufwand für
 die Bestimmung der zusätzlichen Stützstellen deutlich größer ist als der
 zusätzliche Trainingsaufwand, insbesondere bei Turbomaschinenanwendungen.
 
\end_layout

\begin_layout Standard
Weiterhin wird auch der mögliche Lösungsraum für die Hyperparameter größer.
 Der Grund liegt darin, dass man den Raum der Hyperparameter (wobei 
\begin_inset Formula $o$
\end_inset

 die Anzahl der Hyperparameter angibt) von 
\begin_inset Formula $\mathbb{R^{\mathrm{o_{high}+o_{low}}}}$
\end_inset

 auf die beiden Räume 
\begin_inset Formula $\mathbb{R^{\mathrm{o_{high}}}}$
\end_inset

 und 
\begin_inset Formula $\mathbb{R^{\mathrm{o_{high}}}}$
\end_inset

 auftrennt und damit mögliche Lösungen für die Hyperparameter ausschließt.
\end_layout

\begin_layout Standard
Aufbauend auf der Arbeit von 
\begin_inset CommandInset citation
LatexCommand cite
key "Kennedy2000"

\end_inset

, schlägt 
\begin_inset CommandInset citation
LatexCommand cite
key "forrester2007multi"

\end_inset

 ein weiteres Modell vor.
 In diesem wird ein Ordinary-Kriging auf die Daten niedrigerer Güte aufgestellt
 und die Vorhersagen aus dem Modell dazu verwendet, die Differenz-Kovarianzfunkt
ion und damit das resultierende Co-Kriging Modell aufzustellen.
 Grundlegend ist dies zwar eine praktikable Lösung, allerdings wird damit
 die Bedingung von 
\begin_inset CommandInset citation
LatexCommand cite
key "Kennedy2000"

\end_inset

 
\begin_inset Formula $p\left(z|\phi\right)=p\left(z_{high}|z_{low},\rho,\beta_{high},\sigma_{high}^{2}\right)p\left(z_{low}|\beta_{low},\sigma_{low}^{2}\right)$
\end_inset

 (vgl.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Kennedy2000"

\end_inset

 Gleichung 8) verletzt.
 Diese besagt, das die Schätzung der Parameter der Verteilungsfunktion hoher
 Güte 
\begin_inset Formula $\rho,\beta_{high},\sigma_{high}^{2}$
\end_inset

 unabhängig von den Parametern niedrigerer Güte 
\begin_inset Formula $\beta_{low},\sigma_{low}^{2}$
\end_inset

 erfolgen kann.
 Da die Daten niedrigerer Güte dann aber aus einer Kriging-Vorhersage stammen,
 sind 
\begin_inset Formula $z_{low},\rho,\beta_{high},\sigma_{high}^{2}$
\end_inset

 nicht mehr unabhängig von 
\begin_inset Formula $\beta_{low},\sigma_{low}^{2}$
\end_inset

.
 Weiterhin sind diese Vorhersagen mit einer Unsicherheit behaftet, stellen
 also selbst Verteilungen dar.
 Inwiefern dieser Umstand beachtet werden sollte, wurde hier allerdings
 nicht mehr weiter untersucht.
 
\end_layout

\begin_layout Standard
Eine weitere Herangehensweise kann in 
\begin_inset CommandInset citation
LatexCommand cite
key "han2012alternative"

\end_inset

 gefunden werden.
 In dieser Arbeit wird ein Co-Kriging-Modell mit drei unabhängigen Kovarianzfunk
tionen beschrieben.
 Die bedeutet, dass drei verschiedene Hyperparametersätze gleichzeitig trainiert
 werden.
 Dies führt allerdings zu erheblichen numerischen Problemen.
 Der Grund liegt darin, dass die positive Definitheit der Kovarianzmatrix
 nicht mehr gesichert ist.
 Praktisch ist das Verfahren damit nicht anwendbar.
 Um dieses Problem zu umgehen, wurde in 
\begin_inset CommandInset citation
LatexCommand cite
key "han2009improving"

\end_inset

 vorgeschlagen, für alle drei Kovarianzfunktionen denselben Hyperparametersatz
 zu verwenden.
 Verglichen mit einem Ordinary-Kriging welches alle Fidelity Samples beinhaltet,
 besteht der Unterschied dann nur noch in einer eigenen globalen Varianz
 und einem eigenen globalen Erwartungswert für die verschiedenen Fidelities.
 Damit könnte nur noch eine für das gesamte Modell gültige konstante Verschiebun
g zwischen den Gütestufen dargestellt werden.
 Dies stellt jedoch eine erhebliche Vereinfachung des Co-Kriging Modells
 dar und für industrielle Anwendungen nicht ausreichend ist.
\end_layout

\begin_layout Section
Softwaretechnische Umsetzung 
\begin_inset CommandInset label
LatexCommand label
name "sec:Numerische-Effizienz-steigern"

\end_inset


\end_layout

\begin_layout Standard
Innerhalb dieses Abschnittes sollen die wichtigsten softwaretechnischen
 Entwicklungen, welche im Rahmen dieser Arbeit entstanden sind, vorgestellt
 werden.
 Hierzu zählen z.B.
 der Modulare Aufbau der Software, der es ermöglicht verschiedene Verfahren
 wie Supporting-Vector-Machines und alle Kriging-Verfahren innerhalb einer
 Software unterzubringen und so Redundanzen zu vermeiden.
 
\end_layout

\begin_layout Standard
Weiterhin wurden zahlreiche Anstrengungen unternommen um die Software möglichst
 effizient zu gestalten.
 Hierzu zählt eine eigen entwickelte Matrix-Klasse, welche zahlreiche Architektu
ren abdeckt wie z.B.
 GPUs, Intel MKL Bibkiotheken und OpenMP mit AVX/SSE Beschleunigung.
 Dadurch ist es möglich, die Software sehr flexibel auf unterschiedlichen
 Systemen einzusetzen und die vorhandene Prozessorarchitektur effizient
 zu nutzen.
 Weiterhin wurde eine Netzwerkbibliothek entwickelt, welche es ermöglicht
 zahlreiche numerische Operationen asynchron auf mehrere Rechner zu verteilen,
 unabhängig von der Architektur.
 Das System ist zudem stark ausfallsicher: Fällt ein Server aus, übernimmt
 ein anderer dessen Aufgaben.
 
\end_layout

\begin_layout Standard
Neben diesen beschriebenen Maßnahmen werden noch einige andere Entwicklungen
 beschrieben, die den Einsatz der Kriging-Software für den Bereich des Turbomasc
hinendesigns im industriellen Umfeld nutzbar macht.
 
\end_layout

\begin_layout Subsection
Softwarearchitektur und Laufzeitumgebung
\end_layout

\begin_layout Standard
Das gesamte Verfahren ist objektorientiert und nutzt zahlreiche Interfaces,
 dies ermöglicht eine sehr große Flexibilität und Modularität in der Software
 und drückt sich durch die folgenden Punkte aus:
\end_layout

\begin_layout Itemize
Objektorientiert eigen entwickelte Matrix-Klassen welche mehrere Rechenarchitekt
uren unterstützt 
\end_layout

\begin_deeper
\begin_layout Itemize
Nvidia basierte GPU Beschleunigung 
\end_layout

\begin_layout Itemize
Intel MKL Beschleunigung
\end_layout

\begin_layout Itemize
Eigene OpenMP/SSE beschleunigten Umsetzung
\end_layout

\end_deeper
\begin_layout Itemize
Alle Kriging Verfahren (Co-Kriging, Ordinary Kriging und Gradient Enhanced
 Kriging) sind in einem modularen Softwarepaket zusammengefasst
\end_layout

\begin_layout Itemize
Starke Erweiterbarkeit, SVM und Klassifikatoren in demselben Code in anderen
 Studentischen Arbeiten (Link)
\end_layout

\begin_layout Standard
Alle Verfahren sind in einem C++ Code untergebracht.
 Die in der Literatur vorgestellten Ansätze (siehe ...) sind oft einfache Matlab
 Umsetzungen, welche oftmals Schwächen in der Performance und Benutzerfreundlich
keit aufweisen.
 
\end_layout

\begin_layout Standard
Weitherhin bietet die hier entwickelte Software eine sehr hohe Performance
 und ist spezielle ausgelegt für eine große Anzahl an Stützstellen und eine
 hohe Anzahl an Parametern.
 Hierfür wurden einige Softwaremodule und Techniken umgesetzt:
\end_layout

\begin_layout Standard
Die wichtigsten Klassen sind:
\end_layout

\begin_layout Itemize
Point: Beinhaltet Koordinaten, Funktionswerte, Gütestufe, partielle Ableitungen
 und Indices einer Stützstelle
\end_layout

\begin_layout Itemize
Trainer: Vereint und steuert die unterschiedlichen Minimierungsverfahren,
 Initialisierungsverfahren und die Konfiguration 
\end_layout

\begin_layout Itemize
MinimizerInterface: Schnittstelle, welche die Methoden für eine Minimierungsklas
se vorgibt und damit die verschiedenen Minimierungsverfahren ermöglicht.
 
\end_layout

\begin_layout Itemize
Gröbsten Klassen zeigen: DensityFunction und deren Spezialisierungen, Point,
 MinimizerInterface, AUtoOptiInterface
\end_layout

\begin_layout Paragraph*
Implementierung unterschiedlicher Verfahren in einem Softwarepaket
\end_layout

\begin_layout Standard
\begin_inset Wrap figure
lines 0
placement o
overhang 0col%
width "50col%"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename /home/schm_ad/Diss/images/SoftwareTechnUmsetzung/UML/Density.eps
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Vereinfachtes UML Diagramm der verschiedenen Verfahren innerhalb der Kriging-Sof
tware und deren Anbindung an das Server Interface
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Paragraph*
Schnittstellen zwischen AutoOpti und der KrigingSoftware
\end_layout

\begin_layout Standard
Kriging und NN Interface, Interface bezieht sich in diesem Fall auf die
 Schnittstelle zwischen den verschiedenen Programmen und ist nicht, wie
 im sonst üblich, im Sinne einer objektorientierten Interface Programmierung
 gemeint.
 Das Kriging-Interface stellt hier auch die Schnittstellen zwischen den
 Programmiersprachen C und C++ dar, da AutoOpti in C geschrieben wurde und
 das gesamte Kriging in C++.
 Es finden dort zahlreiche Übersetzungen von C-Strukturen in C++-Objekte
 usw.
 statt.
 
\end_layout

\begin_layout Standard
\begin_inset Wrap figure
lines 0
placement o
overhang 0col%
width "50col%"
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename /home/schm_ad/Diss/images/SoftwareTechnUmsetzung/UML/AutoOptiInterface.eps
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Vereinfachtes UML Diagramm der Kopplungsklasse zwischen AutoOpti (verwendet
 die Klasse MetaModel) und dem Kriging bzw.
 den Neuronalen Netzwerken.
 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Paragraph*
Minimierungsverfahren
\end_layout

\begin_layout Standard
Einige Bibliotheken in C geschrieben, dafür mit Boost Function gearbeitet.
 kurz beschreiben
\end_layout

\begin_layout Standard
\begin_inset Wrap figure
lines 0
placement o
overhang 0col%
width "50col%"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename /home/schm_ad/Diss/images/SoftwareTechnUmsetzung/UML/MinimizerInterface.eps

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Matrixoperationen
\begin_inset CommandInset label
LatexCommand label
name "subsec:Matrixoperationen"

\end_inset


\end_layout

\begin_layout Standard
Für die Vorhersage (siehe Gleichungen 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Erwartungswert"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Varianz-des-Schätzfehlers"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Kovarianz-zwischen-zwei"

\end_inset

) wie auch das Training (siehe Gleichungen 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:AbleitungLogLikelihood"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:LogLikelihood"

\end_inset

) eines Kriging-Modells sind viele komplexe Matrixoperationen notwendig.
 Die Laufzeiten von Vorhersage und Training hängen hauptsächlich von diesen
 Matrixoperationen ab.
 
\begin_inset Wrap figure
lines 0
placement o
overhang 0in
width "55col%"
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename ../images/Fabian/uml_net_matrix_implementations.eps
	scale 40

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
UML Diagramm der Matrix Klassen und deren Anbindung an das SaveableOnServer
 Interface
\begin_inset CommandInset label
LatexCommand label
name "fig:MatrixKlasseUML"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

Weiterhin werden diese Modelle innerhalb verschiedenster Hardware-Architekturen
 verwendet, bspw.
 AMD/Intel CPUs und NVidia GPUs.
 Für jede dieser Hardwarearchitekturen gibt es verschiedene Implementierungen
 der benötigten Matrix Operationen.
 Jede dieser Implementierungen sind stark auf die jeweilige Architektur
 optimiert und bringen enorme Geschwindigkeitsvorteile.
 Eine einheitliche Softwareschnittstelle existiert hierfür leider nicht.
 Aus diesem Grund wurde ein einheitliches Matrix-Interface entwickelt (siehe
 Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:MatrixKlasseUML"

\end_inset

), alle Spezialisierungen müssen dieses Interface einbinden und bieten somit
 dieselben Methoden an.
 
\end_layout

\begin_layout Standard
Zur Berechnung der Matrix-Operationen wurden drei verschiedene Klassen entwickel
t, welche jeweils das Interface 
\shape italic
Matrix
\shape default
 und 
\shape italic
SaveableOnServer
\shape default
 einbinden.
 Die Klasse 
\shape italic
OpenMPMatrix
\shape default
 beeinhaltet eine SSE-beschleunigte und Thread-parallelisierte Implementierung
 der Matrix Operationen, jedoch keine CPU-spezifischen Optimierungen.
 
\end_layout

\begin_layout Standard
Die Klasse 
\shape italic
MKLMatrix 
\shape default
bietet alle Optimierungen der Intel-MKL 
\begin_inset CommandInset citation
LatexCommand cite
key "INTEL"

\end_inset

 Bibliothek und ist somit nur für Intel-CPUs brauchbar.
 Die Klasse 
\shape italic
CudaMatrix 
\shape default
bietet die Möglichkeit der Nutzung von Nvidia-GPUs 
\begin_inset CommandInset citation
LatexCommand cite
key "Cuda2018"

\end_inset

 zur Beschleunigung der Matrix Operationen.
 Nähere Informationen zu der genauen Implementierung der Klassen sind in
 
\begin_inset CommandInset citation
LatexCommand cite
key "kueppers2016,kueppers2016b,Kueppers2016c"

\end_inset

.
 Weiterhin wird die praktische Verwendung von GPUs für die Beschleunigung
 der Ersatzmodelle innerhalb einer Optimierungen in Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Verwendung-von-GPGPU"

\end_inset

 diskutiert.
 
\end_layout

\begin_layout Standard

\size larger
\color orange
Mehr schreiben !!! Ein paar Benchmarks/Implementierung genauert
\end_layout

\begin_layout Standard

\size larger
\color orange
Kenntlich machen was von mir und von Fabian ist
\end_layout

\begin_layout Standard

\size larger
\color orange
SaveAbleOnServer erklären
\end_layout

\begin_layout Standard

\size larger
\color orange
Wie werden die Größen gespeichert, im Array selbst, für die Serialisierung
 später
\end_layout

\begin_layout Subsection
Verteiltes Rechnen 
\begin_inset CommandInset label
LatexCommand label
name "chap:Verteiltes-Rechnen-1"

\end_inset

 
\end_layout

\begin_layout Standard
Im Rahmen dieser Arbeit und der Arbeit von 
\begin_inset CommandInset citation
LatexCommand cite
key "kueppers2016,kueppers2016b"

\end_inset

, wurde eine umfangreiche Bibliothek entwickelt, welche es ermöglicht vielen
 von den für das Kriging benötigten komplexen Matrix-Operationen asynchron
 auf mehrere Rechner zu verteilen.
 Die Rechner können dabei unterschiedliche Architektur besitzen, bspw.
 ist eine gleichzeitige Nutzung von Servern mit GPUs und konventionellen
 CPUs möglich.
 
\end_layout

\begin_layout Standard
Die hauptsächliche Entwicklung der Bibliothek fand im Rahmen dieser Arbeit
 statt.
 Innerhalb der Bachelorarbeit 
\begin_inset CommandInset citation
LatexCommand cite
key "kueppers2016,kueppers2016b"

\end_inset

 wurde diese Bibliothek um weitere Matrixoperationen erweitert, der Scheduler
 überarbeitet und die Fehlertoleranz erhöht.
 
\end_layout

\begin_layout Standard
Serialisierung und Deserialisierung über Interface geregelt.
 Die Einbindung des Interfaces stellt sicher, dass die Klasse über alle
 Methoden verfügt, die benötigt werden um diese über das Netzwerk zu verschicken.
 
\end_layout

\begin_layout Standard
Damit ist es aber auch möglich komplette Objekte über das Netzwerk zu verschicke
n.
\end_layout

\begin_layout Standard
Der Server wartet praktisch auf Befehle und kann über ein eigenes Protokoll
 angesteuert werden.
 
\end_layout

\begin_layout Standard
FABIAN / Meinen Teil kenntlich machen
\end_layout

\begin_layout Standard
Für das Training der Kriging-Modelle innerhalb einer Optimierung müssen
 diverse Matrixoperationen durchgeführt werden und diese können je nach
 Problemgröße sehr aufwendig werden.
 Besonders bei einer Multifidelity-Optimierung oder einer gradientenunterstützte
-Optimierung kann das Training zum Flaschenhals der ganzen Optimierung werden.
 Prinzipiell sind hier zwei Fälle zu unterscheiden:
\end_layout

\begin_layout Enumerate
Multifidelity-Optimierung mit Nutzung eines Co-Kriging: Anzahl an zu trainierend
en Hyperparameter ist sehr hoch (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:COKrigingKovarianzmodell"

\end_inset

).
\end_layout

\begin_layout Enumerate
Gradientenunterstützte Optimierung mit Nutzung eines Gradient-Enhanced-Kriging
 (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Gradient-Enhanced-Kriging"

\end_inset

): Die Kovarianzmatrix kann sehr groß werden, durch die zusätzlichen partiellen
 Ableitungen.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
Der Ablauf der Berechnung einer Matrix-Multiplikation würde wie folgt ablaufen:
\end_layout

\begin_layout Enumerate
Die Server-Software müssen auf den entsprechenden Rechnern gestartet werden.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Paragraph
Server
\end_layout

\begin_layout Standard
Wartet nur auf Aufgaben.
 Es können Objekte allokiert werden und darauf Befehle ausgeführt werden.
 Die Ergebnisse werden dann an der Client zurückgeschickt.
 Der Client muss diese dann wieder zusammensetzen,
\end_layout

\begin_layout Paragraph
Client
\end_layout

\begin_layout Standard
Sorgt für die Aufgaben und deren Verteilung an die Server mithilfe eines
 Round-Robin Verfahrens.
 
\end_layout

\begin_layout Paragraph
Messaging Middleware ZeroMQ
\end_layout

\begin_layout Paragraph
Netzwerkobjekte
\end_layout

\begin_layout Standard
Klassen die das Interface SaveableOnServer implementieren, müssen folgende
 Methoden bereitsstellen:
\end_layout

\begin_layout Itemize
getSerializedData(int& size): void* 
\end_layout

\begin_layout Itemize
setSerializedData(void* data): void 
\end_layout

\begin_layout Itemize
getServerType(): string 
\end_layout

\begin_layout Itemize
freeMem(): void 
\end_layout

\begin_layout Paragraph
Ausfallsicherheit
\end_layout

\begin_layout Standard
Damit der Client erkennen kann, welche Server aktuell im Netzwerk vorhanden
 sind, existiert neben jeder Haupt- verbindung eine zusätzliche Ping-Verbindung
 zu jedem bekannten Server.
 Diese wiederum öffnen analog zum Client auch einen zusätzlichen Socket,
 der lediglich für die Verwaltung des periodischen Pingsignals zuständig
 ist.
 Der Ping besteht dabei aus der Signatur des Clients, anhand derer der Server
 erkennen kann, mit welchem Client dieser sich verbunden hat.
 Die Antwort des Servers wiederum besteht aus der Signatur des Clients,
 mit welchem er aktuell gekoppelt ist.
 Sollte ein zweiter Client eine Anfrage an einen bereits gekoppelten Server
 senden, kann dieser anhand der zurückgesendeten Signatur feststellen, dass
 der Server bereits anderweitig vergeben ist.
 Auch Ausfälle eines Servers während der Programmlaufzeit können so vom
 Client erkannt werden.
 
\end_layout

\begin_layout Standard
Für den ersten Fall bietet es sich an, die Berechnung der partiellen Ableitungen
 
\begin_inset Formula $\frac{\partial L\left(\vec{h}\right)}{\partial h_{l}}$
\end_inset

 (vgl.
 Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:COKrigingTraining"

\end_inset

) auf mehrere Rechner zu verteilen.
 
\end_layout

\begin_layout Standard
Für den zweiten Fall ist ein leistungsstarker Rechner günstiger, da sich
 die aufwendigen numerischen Operationen schlechter aufteilen lassen.
 Besonders die Verwendung von leistungsstarken GPUs hat sich für diesen
 Fall als sehr effizient erwiesen und wird in Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Verwendung-von-GPGPU"

\end_inset

 beschrieben.
 Da die meisten Optimierungen auf einem Großrechner des DLR ausführt werden
 und dieser keine GPU-Infrastruktur bietet, ist eine Auslagerung der Matrixopera
tionen auf einen leistungsstarken externen Rechner in diesem Fall wünschenswert.
\end_layout

\begin_layout Standard
Um diesen Anforderungen gerecht zu werden, wurde ein asynchrones Server-Client
 System entwickelt (siehe 
\begin_inset CommandInset citation
LatexCommand cite
key "kueppers2016,kueppers2016b"

\end_inset

).
 Als Messaging-Middleware wurde ZeroMQ (siehe 
\begin_inset CommandInset citation
LatexCommand cite
key "ZeroMQ,Dworak2011"

\end_inset

) verwendet und für die (De-)Serialisierung eine eigene Implementation entwickel
t.
 Die Schnittstelle wurde erfolgreich getestet und konnte im zweiten Fall
 ab einer Matrixgröße von ca.
 3000x3000 gewinnbringend eingesetzt werden.
 Für den zweiten Fall stieg die Beschleunigung nahezu linear mit der Anzahl
 der Server.
 Für weitere Informationen und die genaue Implementierung sei auf 
\begin_inset CommandInset citation
LatexCommand cite
key "kueppers2016,kueppers2016b"

\end_inset

 verwiesen.
\end_layout

\begin_layout Standard
- Mehr schreiben, Link zu den Matrix Klassen bringen, Interface SaveAbleOnServer
 
\end_layout

\begin_layout Standard
- Serialisierung beschreiben
\end_layout

\begin_layout Standard
- Scheduler beschreiben
\end_layout

\begin_layout Standard
- Queue beschreiben und die Aufteilung in Paket, Asynchronität beschreiben
\end_layout

\begin_layout Itemize
Eigenes hochperformantes verteiltes System zur asynchronen Verteilung von
 Matrixoperationen während aller Kriging Operationen (Vorhersage und Training).
 Dieses Verfahren ist extrem flexibel und kann verschiedene Matrixoperationen
 automatische aufteilen und auf mehrere Server verteilten.
 Die Aufteilung erfolgt komplett asynchron, fällt also ein Server bspw.
 aus, so übernimmt ein anderer automatisch die Berechnung.
 Zudem können so verschiedene Architekturen verbunden werden, also bspw.
 CPU und GPU oder unterschiedliche Betriebssysteme.
\end_layout

\begin_layout Itemize
Interface Programmierung hervorheben
\end_layout

\begin_layout Itemize
Aufteilung der Pakete
\end_layout

\begin_layout Itemize
Asynchronität beschreiben
\end_layout

\begin_layout Itemize
Wie übernimmt ein anderer die Rechnung, falls einer ausfällt?
\end_layout

\begin_layout Itemize
Kein MPI nötig, dadurch oft Versionsprobleme oder Lib Probleme OpenMPI/MVAPICH
 usw.
 alles nicht kompatibel und in der Regel nicht asynchron-> Für eine Optimierung
 die über mehrere Rechner läuft und unterschiedlichste System ist dies kein
 Option.
\end_layout

\begin_layout Subsection
Effiziente Berechnung der Kovarianzfunktion
\begin_inset CommandInset label
LatexCommand label
name "sec:SoftwaretechnKorrelationsfunktionen"

\end_inset


\end_layout

\begin_layout Standard
Die in Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Kovarianzmatrix"

\end_inset

 beschriebenen Kovarianzfunktionen müssen für jeden Eintrag in der Kovarianzmatr
ix und auch deren Ableitung nach den Hyperparametern bestimmt werden.
 Für jeden Trainingsschritt mit einem Dichtefunktionsaufruf und den dazugehörige
n partiellen Ableitungen ergeben sich folgend Anzahl an Aufrufen der Kovarianzfu
nktion:
\end_layout

\begin_layout Enumerate
Berechnung der Dichtefunktion: 
\begin_inset Formula $\frac{n\left(n+1\right)}{2}$
\end_inset

 Aufrufe der Kovarianzfunktion
\end_layout

\begin_layout Enumerate
Berechnung von 
\begin_inset Formula $o$
\end_inset

 partiellen Ableitungen der Likelihood Funktion: 
\begin_inset Formula $o\frac{n\left(n+1\right)}{2}$
\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
Geht man von einem üblichen Beispiel mit 1000 Stützstellen und 80 Hyperparameter
n aus, so ergeben sich für die Dichtefunktion ca.
 500.000 Aufrufe und für die partiellen Ableitungen dann 80x500.000 Aufrufe.
 Insgesamt sind dies ca.
 40.5 Millionen Aufrufe für eine Iteration.
 Dies bedeutet, dass jeder gesparte Befehl innerhalb des Kovarianzfunktionsaufru
fs sich sehr stark auf die Laufzeit auswirkt.
 Folgend sind einige Möglichkeiten aufgelistet, wie man die Berechnung beschleun
igen kann:
\end_layout

\begin_layout Itemize
Exponentialfunktion der Hyperparameter 
\begin_inset Formula $e^{\theta_{l}}$
\end_inset

 im Vorraus berechnen
\end_layout

\begin_layout Itemize
Gauss Kovarianzfunktion: Puffern von Zwischenergebnissen
\end_layout

\begin_layout Itemize
Exponentialfunktion durch schnellere ersetzen
\end_layout

\begin_layout Itemize
CPU-Befehlssätze SSE/AVX verwenden
\end_layout

\begin_layout Paragraph*
Exponentialfunktion im Voraus berechnen
\end_layout

\begin_layout Standard
Da die Hyperparameter für eine Iteration konstant bleiben, ist es sinnvoll
 die Berechnung von 
\begin_inset Formula $e^{\theta_{l}}$
\end_inset

 (siehe Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:ExpoKorrelationsfunktion-1"

\end_inset

) nur einmal zu Anfang der Iteration durchzuführen und dann abzuspeichern.
 
\end_layout

\begin_layout Paragraph*
Puffern der Exponentialfunktion
\end_layout

\begin_layout Standard
Da für die Aufstellung der Kovarianzmatrix der innere Teil 
\begin_inset Formula $e^{-\frac{1}{2}\underset{l=1}{\overset{l<=k}{\sum}}\left(e^{\theta_{l}}\left|h_{l}\right|^{p}\right)}$
\end_inset

 (siehe Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:ExpoKovarianzfunktion"

\end_inset

) in den Gleichungen für die partiellen Ableitungen der Kovarianzfunktion
 nach den Hyperparametern (siehe Gleichungen 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:AbleitungKorrGauss"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:AbleitungsKorrGauss2"

\end_inset

) derselbe ist, macht es Sinn diesen zu puffern und bei Bedarf wiederzuverwenden.
 Da der Abruf aus dem RAM deutlich schneller ist, als die erneute Berechnung
 der Exponentialfunktion, beschleunigt dies die Berechnung der Ableitungsmatrize
n erheblich.
\end_layout

\begin_layout Paragraph*
Schnellere Exponentialfunktion 
\end_layout

\begin_layout Standard
Da die Implementierung der Exponentialfunktion der GCC-Bibliothek (Stand
 GCC v4.9) relativ langsam ist, diese Funktion aber mehrere Millionen Mal
 aufgerufen wird, ist es sinnvoll eine schnellere Implementierung zu verwenden.
 In 
\begin_inset CommandInset citation
LatexCommand cite
key "fmath2018"

\end_inset

 wird eine AVX beschleunigte Implementierung der Exponentialfunktion beschrieben
, diese ist ca.
 5x schneller als die GCC-Version.
 Der Fehler der berechneten Werte ist vergleichbar mit der GCC-Version.
 
\end_layout

\begin_layout Paragraph*
Streaming SIMD Extensions (SSE)
\begin_inset CommandInset label
LatexCommand label
name "subsec:Streaming-SIMD-Extensions"

\end_inset


\end_layout

\begin_layout Standard
\noindent
Die Streaming SIMD Extensions (SSE) sind eine von Intel entwickelte Befehlssatze
rweiterung der x86-Architektur.
 Mit Einführung des Pentium-III-(Katmai)-Prozessors wurde diese 1999 vorgestellt.
 Aufgabe der SSE Befehle ist es Programme durch Parallelisierung auf Instruktion
slevel zu beschleunigen, auch SIMD (Single Instruction Multiple Data) genannt.
 Die SSE-Befehlssatzerweiterung umfasst ursprünglich 70 Instruktionen und
 8 neue Register, genannt XMM0 bis XMM7.
 Ursprünglich wurden die 128
\begin_inset space ~
\end_inset

Bit breiten Register allerdings nicht in einem Schritt verarbeitet.
 Bei heutigen CPUs (z.B.
 Intel Core CPUs) werden die Register in einem Schritt verarbeitet, zudem
 wurde die Anzahl der Register von 8 auf 16 erhöht.
 
\end_layout

\begin_layout Standard
Es gibt zahlreiche Umsetzungen der SSE Befehle.
 Diese reichen von SSE bis SSE5, wobei ab SSE3 AMD und Intel jeweils eigene
 Implementationen der SSE Architektur vornahmen.
 Der Nachfolger von SSE heißt AVX (Advanced Vector Extensions) und verbreitert
 die Register auf 16x
\begin_inset space ~
\end_inset

256
\begin_inset space ~
\end_inset

Bit.
 
\end_layout

\begin_layout Standard
Innerhalb dieser Arbeit wurden nur SSE Befehle verwendet, da diese praktisch
 von allen aktuellen CPUs und auch Compilern unterstützt werden.
 Für die Verwendung von AVX sind relativ neue Kompiler und CPUs notwendig,
 dies kann bei einigen Kunden zu Problemen führen.
 Durch die 128
\begin_inset space ~
\end_inset

Bit Register können nun in einem Rechenschritt vier float (32
\begin_inset space ~
\end_inset

Bit) oder zwei double (64
\begin_inset space ~
\end_inset

Bit) Werte gleichzeitig verarbeitet werden.
 Um diese Funktionen zu nutzen, müssen im C++-Code spezielle SSE Befehle
 verwendet werden 
\begin_inset CommandInset citation
LatexCommand citep
key "AGN,INTEL"

\end_inset

.
 Das folgende Listing zeigt die Umsetzung der Gauss Korrelationsfunktion
 mit SSE Befehlen, wobei die Parallelisierung hier über die Hyperparameter
 gemacht wird.
 Diese Methode wird zur Berechnung der Einträge der Kovarianzmatrix verwendet
 und wird dementspchrend oft aufgerufen.
 Aus diesem Grund ist es sinnvoll diese Methode zu Beschleunigen.
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "language={C++},float,numbers=left,basicstyle={\scriptsize},tabsize=4"
inline false
status open

\begin_layout Plain Layout

__m128d correlSSE=_mm_setzero_pd();
\end_layout

\begin_layout Plain Layout

__m128d thetasExpSSE, point1SSE, point2SSE, pointDiffSSE;
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

array thetasExpArray;
\end_layout

\begin_layout Plain Layout

array point1Array;
\end_layout

\begin_layout Plain Layout

array point2Array;
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

for(i=0; i<point1.getNumVars()-1 ; i+=2){
\end_layout

\begin_layout Plain Layout

		thetasExpSSE =_mm_load_pd(&(thetasExpArray[i]));
\end_layout

\begin_layout Plain Layout

		point1SSE =_mm_load_pd(&(point1Array[i]));
\end_layout

\begin_layout Plain Layout

		point2SSE =_mm_load_pd(&(point2Array[i]));
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

		pointDiffSSE = _mm_sub_pd(point1SSE,point2SSE);
\end_layout

\begin_layout Plain Layout

		pointDiffSSE = _mm_mul_pd(pointDiffSSE,pointDiffSSE);
\end_layout

\begin_layout Plain Layout

		pointDiffSSE = _mm_mul_pd( thetasExpSSE, pointDiffSSE  );
\end_layout

\begin_layout Plain Layout

		correlSSE = _mm_add_pd( correlSSE,  pointDiffSSE );
\end_layout

\begin_layout Plain Layout

} 	
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

correlSSE = _mm_hadd_pd(correlSSE,correlSSE); 
\end_layout

\begin_layout Plain Layout

_mm_store_sd(&correl,correlSSE);
\end_layout

\begin_layout Plain Layout

for(; i<point1.getNumVars() ; i++) 	{
\end_layout

\begin_layout Plain Layout

		correl += thetasExp[0][i] * (point1.getVar(i) - point2.getVar(i))^2;
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

correl=fmath::expd(-0.5*correl);
\end_layout

\end_inset


\end_layout

\begin_layout Standard
In den Zeilen 1-2 werden verschiedene Variablen definiert vom Typ 
\begin_inset Quotes eld
\end_inset

__m128d
\begin_inset Quotes erd
\end_inset

, dieser Typ stellt ein 128 Bit großes SSE Datentypen dar und kann zwei
 64
\begin_inset space ~
\end_inset

Bit double Werte aufnehmen.
 Zudem wird die Variable correlSSE mithilfe der Funktion_mm_setzero_pd()
 auf 0 gesetzt.
 Die Zeilen 4-6 stellen Arrays dar, welche für die Berechnung der Korrelationsfu
nktion benötigt werden.
 Das Array thetasExpArray beinhaltet die berechneten Hyperparameter 
\begin_inset Formula $e^{\theta_{l}}$
\end_inset

.
 Da diese Werte für alle Einträge in der Kovarianzmatrix identisch sollten
 sie daher vor dem Belegen der Kovarianzmatrix berechnet werden.
 Danach werden die beiden Arrays initialisiert, welche die Ortsvariablen
 
\begin_inset Formula $\vec{x}_{1},\vec{x}_{2}\in\mathbb{R^{\mathrm{k}}}$
\end_inset

 beinhalten.
 Die darauffolgende for-Schleife iteriert über die Anzahl an freien Variablen.
 Der Zähler wird hier immer um den Wert 2 erhöht, da mit den SSE Routinen
 2 double Werte gleichzeitig berechnet werden können.
 In den Zeilen 9-11 werden 128Bit aus den Arrays an der Stelle i in die
 SSE-Register der CPU übertragen.
 Aus diesem Grund muss der Speicher zwingend 128Bit Speicherausrichtung
 besitzen.
 
\end_layout

\begin_layout Paragraph
Einschub: Speicherausrichtung
\begin_inset CommandInset label
LatexCommand label
name "par:Einschub-Speicherausrichtung"

\end_inset


\end_layout

\begin_layout Standard

\shape italic
In aktuellen C++ Compilern wird eine Speicherausrichtung von 128Bit im Normalfal
l gewährleistet.
 Tabelle 
\shape default

\begin_inset CommandInset ref
LatexCommand ref
reference "tab:128Bit-Speicherausrichtung"

\end_inset


\shape italic
 zeigt die Speicherausrichtung und die damit entstehende Problematik beim
 Programmieren.
 Die erste Zeile der Tabelle beschreibt den Index eines normalen Arrays
 mit 6 Einträgen und jeder Eintrag hat die Größe eines 64Bit (z.B.
 double) Werts.
 Der Compiler garantiert in diesem Fall einen zusammenhängenden Speicher
 von 128Bit, dargestellt durch die dritte Zeile.
\end_layout

\begin_layout Standard
\begin_inset Wrap table
lines 0
placement o
overhang 0col%
width "50col%"
status collapsed

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
64Bit
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
64Bit
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
64Bit
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
64Bit
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multicolumn="1" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

$
\backslash
underbrace{128Bit aligned}$
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:128Bit-Speicherausrichtung"

\end_inset

128Bit Speicherausrichtung
\end_layout

\end_inset


\end_layout

\end_inset

Die Zeilen 13-16 stellen dann die eigentliche Berechnung in den SSE-Registern
 der CPU dar.
 Durch die breiteren Register werden hier immer zwei Werte auf einmal verarbeite
t.
 In Zeile 19 werden die beiden Werte in den Registern zusammenaddiert und
 dann in Zeile 20 wieder zurück in den RAM kopiert.
 
\end_layout

\begin_layout Standard
Ist die Anzahl der Variablen nicht durch zwei teilbar, so bleibt ein Rest
 bestehen.
 Dieser wird in Zeile 21-23 auf konventionelle Weise berechnet.
 Die gemessenen Geschwindigkeitsvorteile liegen bei ca.
 30
\begin_inset space ~
\end_inset

%.
 
\end_layout

\begin_layout Subsection
Reduktion von Stützstellen
\end_layout

\begin_layout Standard
Während einer Optimierung können eine Vielzahl an Stützstellen erzeugt werden
 und damit große Kovarianzmatrizen entstehen.
 Aus diesem Grund ist es sinnvoll nur Stützstellen zu verwenden, welche
 dem jeweiligen Ersatzmodell einen wirklichen Informationszugewinn bringen.
 Eine gute Möglichkeit ist es, räumlich eng beieinander liegende Stützstellen
 zu entfernen.
 Als notwendige Metrik bietet sich die Verwendung der Korrelationsfunktion
 (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Kovarianzmatrix"

\end_inset

) an.
 Stützstellen mit sehr hohen Korrelationen haben nur einen sehr kleinen
 Abstand zueinander und sollten dem Ersatzmodell nur einen geringen Informations
anteil liefern.
 Solche Stützstellen könnten dann für das Training außer Acht gelassen werden.
 Allerdings macht dieses Vorgehen nur Sinn, wenn die Korrelationslängen
 des jeweiligen Kriging-Modells bereits gut geschätzt sind.
 Um dies zu gewährleisten, wird die Reduktion der Stützstellen nur durchgeführt,
 wenn die in Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:UltraRestart"

\end_inset

 beschriebene Initialisierungsoption gewählt wurde.
 Zusätzlich gilt die Bedingung, dass sich die Initialisierung bereits im
 
\begin_inset Quotes gld
\end_inset


\shape italic
Restart
\shape default

\begin_inset Quotes grd
\end_inset

 Modus befinden muss.
\end_layout

\begin_layout Standard
Folgend wird der verwendete Algorithmus vereinfacht dargestellt:
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "float,numbers=left,basicstyle={\scriptsize},tabsize=4,extendedchars=true"
inline false
status open

\begin_layout Plain Layout

map <float, pair<int,int> > korrMap;
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

for(p1 in points){
\end_layout

\begin_layout Plain Layout

	for(p2=p1.next() in points){
\end_layout

\begin_layout Plain Layout

		korrelation = correlation(p1,p2)
\end_layout

\begin_layout Plain Layout

		korrMap[korrelation] =pair(p1,p2)
\end_layout

\begin_layout Plain Layout

	}
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

pointsToDelete=[]
\end_layout

\begin_layout Plain Layout

for(korrPair in korrMap) {
\end_layout

\begin_layout Plain Layout

	if(korrMap.p1 in pointsToDelete or korrMap.p2 in pointsToDelete)
\end_layout

\begin_layout Plain Layout

		continue
\end_layout

\begin_layout Plain Layout

	deleteIndices.append(random(p1,p2))
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

for(deletePoint in deleteIndices)
\end_layout

\begin_layout Plain Layout

	points.remove(deletePoint)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Wrap figure
lines 12
placement o
overhang 0in
width "50col%"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../images/SoftwareTechnUmsetzung/SampleFilterAlgo_All.eps
	scale 20

\end_inset


\begin_inset Graphics
	filename ../images/SoftwareTechnUmsetzung/SampleFilterAlgo_Filtered.eps
	scale 20

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:PunkteFilterBeispiel"

\end_inset

Anwendung des Filters anhand eines analytischen Beispiels
\end_layout

\end_inset


\end_layout

\end_inset

In Zeile 3-8 werden die Korrelationen für alle möglichen Punktepaare berechnet
 und innerhalb der Map direkt sortiert.
 Die Schleife in Zeile 11-15 geht die sortierte Map durch, angefangen bei
 dem Größten Korrelationswert.
 Innerhalb der Schleife wird geprüft, ob einer der beiden Punkte bereits
 zum Löschen markiert wurde oder nicht.
 Wurde einer markiert, so wird nichts weiter unternommen.
 Wurde kein Punkt markiert, so wird dieser zum Löschen eingetragen.
 Auf diese Weise kann sichergestellt werden, dass nicht beide Punkte gelöscht
 werden.
 
\end_layout

\begin_layout Standard
In Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:PunkteFilterBeispiel"

\end_inset

 wird ein Beispiel für diesen Filter gezeigt.
 Es wurde die ZDT3 Funktion mit 2 Variablen verwendet (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:ZDT3"

\end_inset

).
 Auf dem linken Bild wurden 500 gleichverteilte Stützstellen erzeugt und
 nochmals 500 weitere Stützstellen normalverteilt um die Mitte des betrachteten
 Bereichs gelegt (mit einer Standardabweichung von 10% der Raumgröße).
 Damit soll eine lokale Anhäufung von Stützstellen simuliert werden.
 
\end_layout

\begin_layout Standard
Daraufhin wurde ein Ordinary-Kriging trainiert und der Filter angewandt,
 wobei der Filter die Stützstellen auf 100 reduziert hat.
 Das Ergebnis ist in Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:PunkteFilterBeispiel"

\end_inset

 rechts zu sehen.
 Die lokale Anhäufung in der Mitte ist praktisch nicht mehr vorhanden und
 die Verteilung der Punkte ist sehr gleichmäßig.
 Die Laufzeit des Filters ist im Vergleich zur restlichen Laufzeit zu vernachläs
sigen.
\end_layout

\begin_layout Subsection
Likelihood: Inverse durch Gleichungssysteme ersetzen 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Inverse-durch-Gleichungssysteme"

\end_inset


\end_layout

\begin_layout Standard
Mit Hilfe der Cholesky-Zerlegung (siehe Anhang 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Cholesky-Zerlegung"

\end_inset

) können lineare Gleichungssysteme sehr effizient gelöst werden.
 Dies kann man sich zunutze machen, um bei der Likelihood Berechnung auf
 die direkte Bestimmung der Inversen verzichten.
 Der Likelihoodterm (siehe 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Maximum-LikelihoodCovariance"

\end_inset

) sieht wie folgt aus:
\begin_inset Formula 
\begin{align*}
\log(N)= & -\log\left(\det(\mathbf{\mathbf{Cov}})\right)-\left(\vec{y}_{s}-\overrightarrow{F}\right)^{T}\mathbf{\mathbf{Cov}}^{-1}\left(\vec{y}_{s}-{}_{1}\overrightarrow{F}\right)
\end{align*}

\end_inset

Die Determinante der Kovarianzmatrix wird aus der Cholesky Zerlegung gewonnen
 (siehe 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Cholesky-Zerlegung"

\end_inset

).
 Der quadratische Term 
\begin_inset Formula $\left(\vec{y}_{s}-\overrightarrow{F}\right)^{T}\mathbf{\mathbf{Cov}}^{-1}\left(\vec{y}_{s}-\overrightarrow{F}\right)$
\end_inset

 beinhaltet allerdings noch die Inverse Kovarianzmatrix.
 Dieser kann mit Hilfe der Cholesky Zerlegung gewonnen werden, wir führen
 hierfür die Hilfsvektoren 
\begin_inset Formula $\vec{e}$
\end_inset

 und 
\begin_inset Formula $\vec{d}$
\end_inset

 ein:
\begin_inset Formula 
\begin{align*}
\left(\vec{y}_{s}-\overrightarrow{F}\right) & =\vec{e}\\
\mathbf{\mathbf{Cov}}^{-1}\vec{e} & =\vec{d}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\noindent
Bei der Cholesky Zerlegung wird die Matrix 
\begin_inset Formula $\mathbf{\mathbf{Cov}}$
\end_inset

 in ein Produkt aus einer unteren Dreicksmatrix und deren Transponierten
 zerlegt, die Dreiecksmatrix 
\begin_inset Formula $\mathbf{L}$
\end_inset

 gilt an dieser Stelle als bekannt:
\begin_inset Formula 
\begin{align*}
\mathbf{L}\mathbf{L}^{T} & =\mathbf{\mathbf{Cov}}
\end{align*}

\end_inset

Daraus folgt:
\begin_inset Formula 
\begin{align*}
\mathbf{\mathbf{\left(\mathbf{L}\mathbf{L}^{T}\right)}}^{-1}\vec{e} & =\vec{d}\\
\vec{e} & =\vec{d}\mathbf{\mathbf{\mathbf{L}\mathbf{L}^{T}}}
\end{align*}

\end_inset

Führt man nun folgende Substitution ein:
\begin_inset Formula 
\begin{align*}
\vec{d_{tmp}} & =\vec{d}\mathbf{\mathbf{\mathbf{L}}}\\
\vec{e} & =\vec{d_{tmp}}\mathbf{\mathbf{\mathbf{L}^{T}}}
\end{align*}

\end_inset

So kann dieses Gleichungssystem durch eine einfache Rückwärtssubstitution
 
\begin_inset Formula $\vec{d}_{tmp}$
\end_inset

 gelöst werden.
 Danach kann direkt das folgende Gleichungssystem durch Vorwärtseinsetzen
 gelöst werden und der Vektor 
\begin_inset Formula $\vec{d}$
\end_inset

 ist hiermit bekannt.
 
\begin_inset Formula 
\[
\vec{d_{tmp}}=\vec{d}\mathbf{\mathbf{\mathbf{L}}}
\]

\end_inset

Der Aufwand hierfür ist deutlich geringer als bei der Invertierung, da nur
 zwei Gleichungssysteme gelöst werden müssen anstatt 
\begin_inset Formula $n$
\end_inset

 Gleichungssysteme für die gesamte Invertierung.
\end_layout

\begin_layout Subsection
Ableitung Likelihood: Verzicht auf Inverse - Rückwärtsdifferentiation der
 Cholesky Zerlegung 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Ableitung-LikelihoodRueckMode"

\end_inset


\end_layout

\begin_layout Standard
Wie in Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:SpurApprox"

\end_inset

 bereits erwähnt, ist es bei der Berechnung des Likelihood Terms möglich
 auf die Invertierung der Kovarianzmatrix zu verzichten.
 Bei der Bestimmung der partiellen Ableitungen des Likelihood Terms nach
 den Hyperparametern ist dies allerdings schwieriger.
 Die Bestimmung der partiellen Ableitungen folgt dem folgenden Berechnungsschema
:
\end_layout

\begin_layout Enumerate
Über alle benötigen Hyperparameter 
\begin_inset Formula $h_{l}$
\end_inset


\end_layout

\begin_deeper
\begin_layout Enumerate
Bestimmung der Ableitung der Kovarianzmatrix
\begin_inset Formula $\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}$
\end_inset


\end_layout

\begin_layout Enumerate
Berechnung der Ableitung der quadratischen Form: 
\begin_inset Formula $\left(\vec{y}_{s}-\beta_{1}\overrightarrow{F}\right)^{T}\mathbf{\mathbf{\mathbf{Cov}}}^{-1}\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}\mathbf{Cov}^{-1}\left(\vec{y}_{s}-\beta_{1}\overrightarrow{F}\right)$
\end_inset


\end_layout

\begin_layout Enumerate
Berechnung der Ableitung der Determinante: 
\begin_inset Formula $\textrm{Spur}\left(\mathbf{\mathbf{Cov}}^{-1}\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}\right)$
\end_inset


\end_layout

\end_deeper
\begin_layout Standard
Punkt a bedeutet vom Aufwand die Aufstellung der symmetrischen Matrix 
\begin_inset Formula $\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}$
\end_inset

.
 Die Komplexität des Algorithmus liegt bei 
\begin_inset Formula $\mathcal{O}\left(n^{2}\right)$
\end_inset

 und kann zudem sehr gut parallelisiert werden.
 Die Bestimmung der einzelnen Ableitungen der Kovarianzmatrix hängt stark
 von dem verwendeten Kriging Modell und der verwendeten Korrelationsfunktion
 ab.
 Beim Gradient Enhanced Kriging können diese Einzelableitungen komplexer
 werden und damit auch vom numerischen Aufwand teurer.
 Dennoch können in der Regel sehr viele Teile aus der Aufstellung der Kovarianzm
atrix wiederverwendet werden, was den Aufwand erheblich reduziert und daher
 eher unerheblich macht.
 
\end_layout

\begin_layout Standard
Punkt b ist vom Aufwand her nahezu vernachlässigbar.
 In der Regel wurde der Vektor 
\begin_inset Formula $\left(\vec{y}_{s}-\beta_{1}\overrightarrow{F}\right)^{T}\mathbf{\mathbf{\mathbf{Cov}}}^{-1}$
\end_inset

 bereits in der Likelihood Berechnung bestimmt und es muss nur noch eine
 Vektor Matrix Multiplikation durchgeführt werden.
\end_layout

\begin_layout Standard
Punkt c ist der aufwendigste Teil, da nur für diesen Teil die Inverse bestimmt
 werden muss.
 Die Inverse wird natürlich außerhalb dieser Schleife nur einmal berechnet,
 dennoch könnte man ohne diesen Teil vollständig auf die direkte Berechnung
 der Inversen verzichten.
 Ist die Inverse bestimmt, liegt die Komplexität zur Berechnung der Spur
 bei 
\begin_inset Formula $\mathcal{O}\left(n^{2}\right)$
\end_inset

.
 
\end_layout

\begin_layout Standard
Der Hauptaufwand liegt also in der Berechnung der Inversen.
 Der genaue Ablauf zur Bestimmung der Inversen folgt dem Schema aus Kapitel
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Cholesky-Zerlegung"

\end_inset

.
 Grundlegend besteht dieses Schema aus zwei Schritten:
\end_layout

\begin_layout Enumerate
Cholesky Zerlegung der Kovarianzmatrix
\end_layout

\begin_layout Enumerate
Vorwärts- und Rückwärtssubstitution zur Bestimmung der Inversen
\end_layout

\begin_layout Standard
Der Aufwand beider Schritte liegt bei 
\end_layout

\begin_layout Enumerate
Ungefähr 
\begin_inset Formula $\frac{1}{6}n^{3}$
\end_inset

Multiplikationen/Additionen, 
\begin_inset Formula $\frac{1}{2}n^{2}$
\end_inset

 Divisionen, 
\begin_inset Formula $n$
\end_inset

 Wurzeloperationen 
\end_layout

\begin_layout Enumerate
Vorwärts- und Rückwärtseinsetzen insgesamt: 
\begin_inset Formula $n^{3}$
\end_inset

 Multiplikationen/Additionen
\end_layout

\begin_layout Standard
Der Hauptaufwand liegt also bei der Vorwärts- und Rückwärtssubstitution.
 Wobei sich diese für den Fall einer Invertierung hervorragend parallelisieren
 lässt.
 Da man das Vorwärts- und Rückwärtseinsetzen bei der Invertierung über 
\begin_inset Formula $n$
\end_inset

 Vektoren macht, kann man die Berechnung über die Vektoren parallelisieren.
 SIMD Routinen sind hier besonders effizient, da für jeden Vektor immer
 dieselbe Routine durchlaufen wird und nur die Daten sich ändern.
 Eine GPU, SSE oder AVX Beschleunigung ist hier also besonders anzustreben.
 Denkbar ist aber auch eine Parallelisierung auf Prozessebene, diese ließe
 sich nach demselben Schema aufteilen und die Teile dann natürlich auch
 über SIMD Befehle beschleunigen.
 
\end_layout

\begin_layout Standard
Ein kompletter Verzicht auf die Vorwärts- und Rückwärtssubstitution wäre
 dennoch erstrebenswert, da diese den größten Teil des Aufwands ausmacht.
 
\end_layout

\begin_layout Standard
Einen interessanten Ansatz hierzu kann man in 
\begin_inset CommandInset citation
LatexCommand cite
key "toal2009adjoint"

\end_inset

 finden.
 Dieser bedient sich der algorithmischen Differentiation im Rückwärtsmodus,
 der interessierte Leser sei auf 
\begin_inset CommandInset citation
LatexCommand cite
key "Mader2008,Griewank2008"

\end_inset

 verwiesen, welche einen sehr guten Überblick über die algorithmische Differenti
ation bieten.
 Dieser Ansatz bietet die Möglichkeit auf die Vor- und Rückwärtssubstitution
 zu verzichten, allerdings werden rückwärtsdifferenzierte Algorithmen des
 Cholesky Algorithmus und auch der Vor- und Rückwärtssubstitution benötigt.
 Für diese Algorithmen gibt es keine performante Implementation über Bibliotheke
n.
 
\end_layout

\begin_layout Standard
Aus diesem Grund in 
\begin_inset CommandInset citation
LatexCommand cite
key "Toal2011"

\end_inset

 ein Algorithmus vorgeschlagen, welcher die Invertierung zwar benötigt,
 aber keine rückwärtsdifferenzierten Algorithmen.
 Ein Geschwindigkeitsvorteil wird hierbei bei der Aufstellung der partiellen
 Ableitungen der Kovarianzmatrix 
\begin_inset Formula $\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}$
\end_inset

 erreicht.
 Diese muss bei dem verwendeten Algorithmus nicht mehr direkt erzeugt werden.
 Die Vorwärts- und Rückwärtssubstitution muss dennoch durchgeführt werden.
 Diese stellt grundlegend auch den Hauptanteil bei der Berechnung des Likelihood
s und der Ableitungen dar.
 Weiterhin müssen für jedes Kovarianzmodell eigene Algorithmen aufgestellt
 werden, was den Enticklungsaufwand stark erhöht.
\end_layout

\begin_layout Standard
\noindent
Eine andere Möglichkeit bietet die alleinige Rückwärtsdifferentiation der
 Determinante der Kovarianzmatrix.
 Dieser Ansatz bietet einen Geschwindigkeitsvorteil und zudem den Vorteil,
 dass der Quellcode sich nur minimal ändert und damit für alle Kriging-Verfahren
 und auch Kovarianzfunktionen gilt.
 Es wird allerdings eine rückwärtsdifferenzierte Version des Cholesky Algorithmu
s benötigt.
 Für diese bestehen mittlerweile aber sehr effiziente BLAS-Implementierungen.
 Der grundlegende Ansatz ist die Bestimmung der formellen Ableitung der
 gesuchten Ableitung:
\begin_inset Formula 
\begin{align}
 & \frac{\partial\left(ln\left(det\left(\mathbf{\mathbf{\mathbf{Cov}}}\left(h_{l}\right)\right)\right)\right)}{\partial h_{l}}\label{eq:lnDetCovRuckmodus}
\end{align}

\end_inset

Wobei die Determinante das Produkt über alle quadrierten Diagonalelemente
 der Cholesky zerlegten Dreiecksmatrix 
\begin_inset Formula $LL^{T}$
\end_inset

 ist:
\begin_inset Formula 
\begin{align}
ln\left(det\left(\mathbf{\mathbf{\mathbf{Cov}}}\left(h_{l}\right)\right)\right) & =ln\left(\prod_{i}L_{i,i}^{2}\right)=2\sum ln\left(L_{i,i}\right)
\end{align}

\end_inset

Daraus ergibt sich die folgende Verkettung, welche die Cholesky Zerlegung
 berücksichtigt 
\begin_inset Formula $f_{chol}$
\end_inset


\begin_inset Formula 
\begin{align}
 & \frac{\partial\left(ln\left(det\left(f_{chol}\left(\mathbf{\mathbf{\mathbf{Cov}}}\left(h_{l}\right)\right)\right)\right)\right)}{\partial h_{l}}
\end{align}

\end_inset

Die bestehenden Abbildungen sehen wie folgt aus:
\begin_inset Formula 
\begin{align}
\mathbf{\mathbf{\mathbf{Cov}}}:\mathbb{R}\longmapsto\mathbb{R}^{n^{2}}\\
f_{chol}:\mathbb{R}^{n^{2}}\longmapsto\mathbb{R}^{n^{2}}\nonumber \\
det:\mathbb{R}^{n^{2}}\longmapsto\mathbb{R}\nonumber \\
ln:\mathbb{R}\longmapsto\mathbb{R}\nonumber 
\end{align}

\end_inset

Der Logarithmus der Determinante wird als 
\begin_inset Formula $f_{lndet}$
\end_inset

 zusammengefasst
\begin_inset Formula 
\begin{align}
 & \frac{\partial\left(f_{lndet}\left(f_{chol}\left(\mathbf{\mathbf{\mathbf{Cov}}}\left(h_{l}\right)\right)\right)\right)}{\partial h_{l}}\\
 & f_{lndet}:\mathbb{R}^{n^{2}}\longmapsto\mathbb{R}\nonumber 
\end{align}

\end_inset

es gilt also
\begin_inset Formula 
\begin{align}
f_{lndet}\circ f_{chol}\circ\mathbf{\mathbf{\mathbf{Cov}}} & :\mathbb{R}\longmapsto\mathbb{R}
\end{align}

\end_inset

daraus resultieren die Jacobi Matrizen 
\begin_inset Formula $D_{cov}$
\end_inset

 der Größe 
\begin_inset Formula $n^{2}\times1$
\end_inset

, 
\begin_inset Formula $D_{chol}$
\end_inset

 der Größe 
\begin_inset Formula $n^{2}\times n^{2}$
\end_inset

 und 
\begin_inset Formula $D_{flndet}$
\end_inset

 der Größe 
\begin_inset Formula $1\times n^{2}$
\end_inset

 wobei 
\begin_inset Formula $\mathbf{\mathbf{C_{i,j}}}$
\end_inset

 einen Eintrag der Matrix 
\begin_inset Formula $\mathbf{\mathbf{\mathbf{Cov}}}$
\end_inset

 bedeutet.
 Damit wird die gesamte Ableitung zu:
\begin_inset Formula 
\begin{align}
\frac{\partial\left(f_{lndet}\left(f_{chol}\left(\mathbf{\mathbf{\mathbf{Cov}}}\left(h_{l}\right)\right)\right)\right)}{\partial h_{l}} & =D_{flndet}D_{chol}D_{cov}\label{eq:KettenregelCholesky}\\
 & =\sum_{i}\sum_{_{j<=i}}\sum_{k}\sum_{_{m<=k}}\frac{\partial f_{lndet}}{\partial\mathbf{\mathbf{\mathbf{L_{i,j}}}}}\frac{\partial\mathbf{\mathbf{\mathbf{L_{i,j}}}}}{\partial\mathbf{\mathbf{\mathbf{C_{k,m}}}}}\frac{\partial\mathbf{\mathbf{C_{k,m}}}}{\partial h_{l}}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Es gilt nun sich zu überlegen, wie man die hier gezeigte mehrdimensionale
 Kettenregel möglichst effizient bestimmen kann.
 Berechnet man die vollständige Summe, dann wäre die Komplexität für die
 Berechnung der Ableitung bei 
\begin_inset Formula $\mathcal{O}\left(n^{4}\right)$
\end_inset

.
 Der Aufwand wäre also deutlich größer als über die Bestimmung der Inversen.
 Benötigt wird also ein Algorithmus, welcher die notwendigen Terme der mehrdimen
sionalen Kettenregel ohne große Matrizen berechnen kann.
 Als erste Vereinfachung kann man sich versuchen die einzelnen Jacobi Vektoren
 zu bestimmen.
 Der Vektor 
\begin_inset Formula $D_{cov}$
\end_inset

 entspricht einfach nur allen Einträgen der Matrix 
\begin_inset Formula $\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}$
\end_inset

 und ist im Kriging daher bekannt.
 Als nächstes kann man den Vektor 
\begin_inset Formula $D_{flndet}$
\end_inset

 bestimmen, da man die Funktion 
\begin_inset Formula $f_{lndet}$
\end_inset

 kennt:
\begin_inset Formula 
\begin{align}
D_{flndet}^{T} & =\left(\begin{array}{c}
\frac{\partial f_{lndet}}{\partial\mathbf{\mathbf{\mathbf{L_{1,1}}}}}\\
\frac{\partial f_{lndet}}{\partial\mathbf{\mathbf{\mathbf{L_{2,1}}}}}\\
\vdots\\
\frac{\partial f_{lndet}}{\partial\mathbf{\mathbf{\mathbf{L_{n-1,n}}}}}\\
\frac{\partial f_{lndet}}{\partial\mathbf{\mathbf{\mathbf{L_{n,n}}}}}
\end{array}\right)=\left(\begin{array}{c}
\frac{\partial2\sum ln\left(L_{i,i}\right)}{\partial\mathbf{\mathbf{\mathbf{L_{1,1}}}}}\\
\frac{\partial2\sum ln\left(L_{i,i}\right)}{\partial\mathbf{\mathbf{\mathbf{L_{2,1}}}}}\\
\vdots\\
\frac{\partial2\sum ln\left(L_{i,i}\right)}{\partial\mathbf{\mathbf{\mathbf{L_{n-1,n}}}}}\\
\frac{\partial2\sum ln\left(L_{i,i}\right)}{\partial\mathbf{\mathbf{\mathbf{L_{n,n}}}}}
\end{array}\right)=\left(\begin{array}{c}
\frac{2}{L_{1,1}}\\
0\\
\vdots\\
0\\
\frac{2}{L_{n,n}}
\end{array}\right)
\end{align}

\end_inset

Die Bestimmung des Vektors kann auch als Diagonalmatrix interpretiert werden
 welche sehr schnell aus der Cholesky zerlegten Matrix bestimmt werden kann.
 
\begin_inset Formula 
\begin{align}
\bar{D}_{flndet}= & \left[\begin{array}{ccc}
\frac{2}{L_{1,1}} & \cdots & 0\\
\vdots & \ddots & \vdots\\
0 & \cdots & \frac{2}{L_{n,n}}
\end{array}\right]
\end{align}

\end_inset

Auffällig ist hierbei, das der Großteil des Jacobi Vektors aus 0 Einträgen
 besteht, mit dieser Information lässt sich Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:KettenregelCholesky"

\end_inset

 stark vereinfachen, da nur noch die Einträge 
\begin_inset Formula $\frac{\partial f_{lndet}}{\partial\mathbf{\mathbf{\mathbf{L_{i,j}}}}}\neq0\left|i=j\right.$
\end_inset

 sind:
\begin_inset Formula 
\begin{align}
\frac{\partial\left(f_{lndet}\left(f_{chol}\left(\mathbf{\mathbf{\mathbf{Cov}}}\left(h_{l}\right)\right)\right)\right)}{\partial h_{l}} & =\sum_{i}\sum_{k}\sum_{_{m<=k}}\frac{\partial f_{lndet}}{\partial\mathbf{\mathbf{\mathbf{L_{i,i}}}}}\frac{\partial\mathbf{\mathbf{\mathbf{L_{i,i}}}}}{\partial\mathbf{\mathbf{\mathbf{C_{k,m}}}}}\frac{\partial\mathbf{\mathbf{C_{k,m}}}}{\partial h_{l}}\label{eq:KettenregelCholeskyReduced}
\end{align}

\end_inset

Die Komplexität liegt somit nur noch bei 
\begin_inset Formula $\mathcal{O}\left(n^{3}\right)$
\end_inset

.
 
\end_layout

\begin_layout Standard
Als nächsten Schritt muss man sich nun überlegen, wie man den mittleren
 Teil der Kettenregel (
\begin_inset Formula $\frac{\partial\mathbf{\mathbf{\mathbf{L_{i,i}}}}}{\partial\mathbf{\mathbf{\mathbf{C_{k,m}}}}}$
\end_inset

) bestimmen kann.
 Hierfür gibt es prinzipiell zwei Möglichkeiten:
\end_layout

\begin_layout Enumerate
Man geht von den Werten 
\begin_inset Formula $\frac{\partial\mathbf{\mathbf{C_{k,m}}}}{\partial h_{l}}$
\end_inset

 aus und bestimmt ausgehend von diesen die Einträge von 
\begin_inset Formula $\frac{\partial\mathbf{\mathbf{\mathbf{L_{i,i}}}}}{\partial h_{l}}$
\end_inset

 über eine vorwärts differenzierte Cholesky Zerlegung
\end_layout

\begin_layout Enumerate
Man geht von den Werten 
\begin_inset Formula $\frac{\partial f_{lndet}}{\partial\mathbf{\mathbf{\mathbf{L_{i,i}}}}}$
\end_inset

 aus und bestimmt ausgehend von diesen die Einträge von 
\begin_inset Formula $\frac{\partial f_{lndet}}{\partial\mathbf{\mathbf{\mathbf{C_{k,m}}}}}$
\end_inset

über eine rückwärts differenzierte Cholesky Zerlegung
\end_layout

\begin_layout Standard
Grundsätzlich sollten beide Vorgehensweise vom numerischen Aufwand gleichwertig
 sein.
 Da man allerdings für jeden der Hyperparameter 
\begin_inset Formula $h_{l}$
\end_inset

 die Matrix 
\begin_inset Formula $\frac{\partial\mathbf{\mathbf{C_{k,m}}}}{\partial h_{l}}$
\end_inset

 bestimmen muss und damit wiederum 
\begin_inset Formula $\frac{\partial\mathbf{\mathbf{\mathbf{L_{i,i}}}}}{\partial\mathbf{\mathbf{\mathbf{C_{k,m}}}}}$
\end_inset

, muss man also die vorwärts differenzierte Cholesky Zerlegung 
\begin_inset Formula $o$
\end_inset

-mal aufrufen.
 In Fall 2 ist dies nicht so, denn die Berechnung ist unabhängig von der
 Anzahl der Hyperparameter.
 Aus diesem Grund verspricht der rückwärtsdifferenzierte Fall einen Vorteil
 bei der Bestimmung der partiellen Ableitungen der Hyperparameter.
\end_layout

\begin_layout Standard
Der numerische Aufwand für einen solchen rückwärtsdifferenzierten Cholesky
 Algorithmus liegt bei dem ungefähr doppelten Aufwand einer normalen Cholesky
 Zerlegung 
\begin_inset CommandInset citation
LatexCommand cite
key "Smith1995"

\end_inset

.
 Das ist immer noch deutlich schneller als eine Vor- und Rückwärtssubstitution.
 Der in 
\begin_inset CommandInset citation
LatexCommand cite
key "Smith1995"

\end_inset

 beschriebene Algorithmus ist allerdings nur schwer parallelisierbar und
 auch für SIMD Architekturen nur schlecht geeignet.
 In Anhang 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Beschleunigter-BackChodec"

\end_inset

 wird eine parallelisierte und SIMD-beschleunigte Variante des Algorithmus
 nach Smith präsentiert.
 
\end_layout

\begin_layout Standard
In der Arbeit von 
\begin_inset CommandInset citation
LatexCommand cite
key "Murray2016,Sarkka2013"

\end_inset

 werden einige moderne Varianten präsentiert, welche es ermöglichen Standard
 Level 2-3 BLAS Routinen zu verwenden.
 Diese stellen die effizientesten Methoden dar und werden folgend auch verwendet.
\end_layout

\begin_layout Subsection
Vergleich zwischen der Invertierung und der Rückwärtsdifferenzierung
\end_layout

\begin_layout Standard
Bei dem hier vorgestelltem Algorithmus handelt es sich prinzipiell nicht
 um eine klassische Rückwärtsdifferenzierung wie z.B.
 in 
\begin_inset CommandInset citation
LatexCommand cite
key "toal2009adjoint"

\end_inset

.
 Diese differenzieren die gesamte Ableitung des Likelihoods rückwärts.
 Diese Algorithmen haben jedoch den Nachteil, dass der Quellcode deutlich
 komplexer und schwerer zu warten ist, insbesondere wenn man mehrere Korrelation
sfunktionen und Verfahren anbietet.
 In beiden Fällen ist es aber nicht direkt ersichtlich, dass die Rückwärtsdiffer
enzierte Methode die schneller ist.
 Die Vermutung ist allerdings, dass die Algortihmen der Rückwärtsdifferenzierung
 weniger Operationen benötigen und sich besser beschleunigen lassen.
 Ein direkter Vergleich der benötigten Operationen innerhalb der Algorithmen
 ist allerdings so gut wie unmöglich, da meist sehr stark optimierte Bibliotheke
n wie die Intel MKL oder ATLAS Bibliothek verwendet werden.
 Diese bedienen sich oft komplexer Algorithmen wie z.B.
 den Strassen Algorithmus, welcher eine Matrix Multiplikation mit einer
 Komplexität von 
\begin_inset Formula $\mathcal{O}\left(n^{log_{2}7}\right)$
\end_inset

 berechnen kann.
 Oft werden die Algorithmen je nach Matrix Größe umgeschaltet, sodass sich
 die echte Komplexität kaum noch bestimmen lässt.
 In der Regel wird diese auch nicht dokumentiert.
 Dennoch lässt sich davon ausgehen, dass diese Bibliotheken das aktuelle
 Maximum an Geschwindigkeit darstellen, sodass eine gute und auch realistische
 Vergleichbarkeit gewährleistet ist.
 Aus diesem Grund sollen in diesem Abschnitt die Unterschiede der Verfahren
 über Benchmarks ermittelt werden.
 
\end_layout

\begin_layout Standard
Betrachtet man den Teil der Berechnung zur Bestimmung der Ableitung des
 Likelihoods nach den Hyperparameter, in dem sich die beiden Verfahren untersche
iden, so handelt es sich prinzipiell nur um Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:lnDetCovRuckmodus"

\end_inset

.
 Die analytische Ableitung ist wie folgt bestimmt:
\begin_inset Formula 
\begin{equation}
\frac{\partial\left(ln\left(det\left(\mathbf{\mathbf{\mathbf{Cov}}}\left(h_{l}\right)\right)\right)\right)}{\partial h_{l}}=\textrm{Spur}\left(\mathbf{\mathbf{Cov}}^{-1}\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}\right)
\end{equation}

\end_inset

Für beide Verfahren gilt die gleiche Ausgangssituation: Die nach den Hyperparame
tern abgeleitete Kovarianzmatrix ist bekannt 
\begin_inset Formula $\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}$
\end_inset

 und auch die Cholesky-zerlegte Matrix 
\begin_inset Formula $\mathbf{L}$
\end_inset

 ist bekannt.
\end_layout

\begin_layout Paragraph
\noindent
Ablauf Vorwärtsdifferentiation 
\end_layout

\begin_layout Enumerate
Bestimmung der differenzierten Kovarianzmatrix 
\begin_inset Formula $\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}$
\end_inset

 für jeweils einen Hyperparameter 
\begin_inset Formula $h_{l}$
\end_inset


\end_layout

\begin_layout Enumerate
Bestimmung der Cholesky Zerlegung 
\begin_inset Formula $\mathbf{L}$
\end_inset

 
\end_layout

\begin_layout Enumerate
Bestimmung von 
\begin_inset Formula $\mathbf{\mathbf{Cov}}^{-1}$
\end_inset

, da die zerlegte Matrix bekannt ist, muss noch eine Vor- und Rückwärtssubstitut
ion durchgeführt werden diese benötigt relativ genau 
\begin_inset Formula $n^{3}$
\end_inset

 Operationen.
\end_layout

\begin_layout Enumerate
Die Bestimmung der quadratischen Form 
\begin_inset Formula $\left(\vec{y}_{s}-\overrightarrow{F}\right)^{T}\mathbf{\mathbf{\mathbf{Cov}}}^{-1}\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}\mathbf{Cov}^{-1}\left(\vec{y}_{s}-\overrightarrow{F}\right)$
\end_inset


\end_layout

\begin_layout Enumerate
Das Matrixprodukt 
\begin_inset Formula $\mathbf{\mathbf{Cov}}^{-1}\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}$
\end_inset

, wobei hiervon nur die Diagonale berechnet werden muss, daher liegt diese
 Berechnung bei ca.
 
\begin_inset Formula $n^{2}$
\end_inset

 Operationen.
 Durch die Spur kann man sparen, es gibt keine BLAS Routine dafür.
 
\end_layout

\begin_layout Paragraph
\noindent
Ablauf Rückwärtsdifferentiation 
\end_layout

\begin_layout Enumerate
Bestimmung der differenzierten Kovarianzmatrix 
\begin_inset Formula $\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}$
\end_inset

 für jeweils einen Hyperparameter 
\begin_inset Formula $h_{l}$
\end_inset


\end_layout

\begin_layout Enumerate
Bestimmung der Cholesky Zerlegung 
\begin_inset Formula $\mathbf{L}$
\end_inset

 
\end_layout

\begin_layout Enumerate
Die Bestimmung der Rückwärtsdifferenzierten Cholesky Zerlegung 
\begin_inset Formula $\frac{\partial\mathbf{\mathbf{\mathbf{L_{i,i}}}}}{\partial\mathbf{\mathbf{\mathbf{C_{k,m}}}}}$
\end_inset

 inlkusive Aufstellen der Seed Matrix 
\begin_inset Formula $\mathbf{\bar{L}}$
\end_inset

 (siehe 
\begin_inset Formula $\frac{\partial f_{lndet}}{\partial\mathbf{\mathbf{\mathbf{L_{i,i}}}}}$
\end_inset

) dieses benötigt 
\begin_inset Formula $n$
\end_inset

 Operationen
\end_layout

\begin_layout Enumerate
Die Bestimmung der quadratischen Form 
\begin_inset Formula $\left(\vec{y}_{s}-\overrightarrow{F}\right)^{T}\mathbf{\mathbf{\mathbf{Cov}}}^{-1}\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}\mathbf{Cov}^{-1}\left(\vec{y}_{s}-\overrightarrow{F}\right)$
\end_inset


\end_layout

\begin_layout Enumerate
Die Bestimmung des Produkts der aus Punkt 2 berechneten Matrix und den Einträgen
 der differenzierten 
\begin_inset Formula $\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}$
\end_inset

 
\begin_inset Formula $\sim\frac{n^{2}}{2}+\frac{n}{2}$
\end_inset


\end_layout

\begin_layout Paragraph
Benchmark
\end_layout

\begin_layout Standard
Folgend wird ein zeitlicher Vergleich über ein Benchmark angestellt.
 Als Benchmark dienten zufällig erzeugte Testdaten aus der ZDT3 Funktion
 (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:ZDT3"

\end_inset

) mit jeweils 8 Parametern.
 Es wurden jeweils 10 Kriging Iterationen durchgeführt und die Zeiten für
 die Erzeugung der partiellen Ableitungen des Likelihoods gemessen.
 Berechnet wurde der Testfall auf zwei Xeon E5 2640 v3 mit insgesamt 16
 Threads.
 Für alle Berechnungen wurde die Intel MKL Bibliothek verwendet.
 
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../images/SoftwareTechnUmsetzung/BackwardBenchPartDerTimeFull.eps
	scale 55

\end_inset


\begin_inset Graphics
	filename ../images/SoftwareTechnUmsetzung/BackwardBenchPartDerTimeStep2-3.eps
	scale 55

\end_inset


\begin_inset Graphics
	filename ../images/SoftwareTechnUmsetzung/BackwardBenchPartDerTimeStep5.eps
	scale 55

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Vergleich-der-Zeiten"

\end_inset

Vergleich der Zeiten der Berechnung der partiellen Ableitungen des Likelihood-Te
rms
\end_layout

\end_inset


\end_layout

\end_inset

 Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Vergleich-der-Zeiten"

\end_inset

 zeigt die benötigte Zeit für die Erzeugung der partiellen Ableitungen.
 Der Rückwärtsmodus war in diesem Fall ca.
 1.5x schneller als der Vorwärtsmodus.
 Die folgenden Abbildungen zeigen die Zeiten der verschiedenen Schritte
 im Vergleich.
 Die Zeiten der Schritte 1 und 4 sind identisch und werden daher nicht gezeigt,
 die Ergebnisse können aber im Anhang 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Rückwärtsdifferenzierung-des-LikelihoodBenchmark"

\end_inset

 gefunden werden.
 Unterschiede können in Schritt 2-3 und Schritt 5 gesehen werden, in beiden
 Fällen ist der Rückwärtsmodus schneller.
 
\end_layout

\begin_layout Subsection
Ableitung Likelihood: Verzicht auf Inverse - Approximation 
\begin_inset CommandInset label
LatexCommand label
name "subsec:SpurApprox"

\end_inset


\end_layout

\begin_layout Standard
Wie bereits beschrieben ist es bei der Bestimmung der partiellen Ableitungen
 nach den Hyperparametern des Likelihood Terms deutlich schwieriger auf
 die Invertierung zu verzichten.
 Dies liegt an der Bestimmung der Ableitung der Determinante nach den Hyperparam
etern.
 
\begin_inset Formula 
\begin{align*}
\frac{\partial L\left(\vec{h}\right)}{\partial h_{l}}= & -\textrm{Spur}\left(\mathbf{\mathbf{Cov}}^{-1}\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}\right)+\left(\left(\vec{y}_{s}-\overrightarrow{F}\right)^{T}\mathbf{\mathbf{\mathbf{Cov}}}^{-1}\frac{\partial\mathbf{\mathbf{\mathbf{Cov}}}}{\partial h_{l}}\mathbf{\mathbf{Cov}}^{-1}\left(\vec{y}_{s}-\overrightarrow{F}\right)\right)
\end{align*}

\end_inset

Wie bereits Spur in Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Ableitung-LikelihoodRueckMode"

\end_inset

 beschrieben, liegt die Schwierigkeit in der Berechnung der Spur.
 Die Spur einer Matrix lässt sich laut 
\begin_inset CommandInset citation
LatexCommand cite
key "Avron2011,hutchinson1989stochastic,MarkGibbs1997"

\end_inset

 statistisch schätzen:
\begin_inset Formula 
\[
Spur\left(R\right)\approx E\left[\vec{d}^{T}R\vec{d}\right]
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Spur\left(R\right)\approx\frac{1}{N}\sum\vec{d}^{T}R\vec{d}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\vec{d}=\left[\begin{array}{c}
N\left(0,1\right)\\
\vdots\\
N\left(0,1\right)
\end{array}\right]
\]

\end_inset

Die Approximation benötigt leider einen sehr großen Zufallsvektor 
\begin_inset Formula $\vec{d}$
\end_inset

 um eine ausreichende Genauigkeit zu erhalten.
 Dies macht die Methode letztlich wieder ineffizient.
 Zudem bleibt immer eine Restunsicherheit in den partiellen Ableitungen
 die sich negativ auf das Training auswirken kann.
 
\end_layout

\begin_layout Subsection
Verwendung von GPUs 
\begin_inset CommandInset label
LatexCommand label
name "sec:Verwendung-von-GPGPU"

\end_inset


\end_layout

\begin_layout Standard
Die Verwendung von GPUs (Graphical Processing Unit) zur Beschleunigung von
 intensiven Rechenoperationen findet innerhalb der wissenschaftlichen Gemeinde
 immer größere Anwendung und Zuspruch (vgl.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Cook2012"

\end_inset


\series bold
)
\series default
.
 Meistens werden solche GPUs als Zusatzkarten für Rechner angeboten und
 verfügen oftmals über eigenen schnellen onboard-Speicher.
 Der Unterschied zwischen einer konventionellen CPU und einer GPU besteht
 hauptsächlich in der Architektur der Prozessoren.
 Während CPUs bis zu ca.
 20 (nach heutigem Stand) hochgetaktete Kerne besitzen und komplexe (bis
 zu 3-Schichtige) Cache Strukturen, so sind GPUs meist mit mehreren tausend
 niedrig getakteten Kernen ausgestattet.
 
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="6">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Jahr
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
SIMD Einheiten
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Cores
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
FMA Einheiten
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Gesamt
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Intel E7-8870
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2011
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
8
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
10
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
80
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Intel Plat.
 8180
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2017
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
16
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
28
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
896
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Nvidia P100
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2017
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3584
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:CoresCPUGPU"

\end_inset

Anzahl der Rechneneinheiten für verschiedene CPUs / GPUs
\end_layout

\end_inset


\end_layout

\end_inset

Auch die Cache Struktur fällt bei GPUs deutlich simpler aus.
 Weiterhin ist die sehr direkte Anbindung des Speichers auf der Platine
 der GPU selbst oftmals ein Vorteil.
 Durch immer größer werdende SIMD (Single Instruction Multiple Data) Einheiten
 in modernen CPUs (bspw.
 AVX512 mit 512 breiten Registern) verschwindet der Unterschied allerdings
 zusehends, wie die folgende Tabelle zeigt.
 
\end_layout

\begin_layout Standard
Tabelle 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:CoresCPUGPU"

\end_inset

 zeigt zwei verschiedene CPUs von Intel und eine aktuelle GPU von NVidia.
 Vergleicht man die realen Recheneinheiten auf den CPUs, so hat diese sich
 fast verzehnfacht.
 
\begin_inset Wrap figure
lines 0
placement o
overhang 0col%
width "50col%"
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../images/SoftwareTechnUmsetzung/MotherboardSchaubild.png
	scale 20

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:BusSystem"

\end_inset

Typischer Aufbau eines Bus-Systems
\end_layout

\end_inset


\end_layout

\end_inset

Auch auf programmiertechnischer Seite verschwindet der Unterschied zwischen
 CPU und GPU.
 So ist der Aufwand eine einfache Matrixoperation (wie z.B.
 eine Matrixmultiplikation) zu programmieren, die die entsprechende Hardware
 vollständig ausnutzt, zu einer Expertenaufgabe geworden.
 Dieser Umstand gilt für CPUs und GPUs gleichermaßen.
 Aus diesem Grund bieten sowohl Intel als auch NVidia zahlreiche hardwareoptimie
rte Bibliotheken für alle Arten von Rechenoperationen an.
\end_layout

\begin_layout Standard
Allerdings gibt es Unterschiede zwischen GPU und CPU bei dem Transfer von
 Daten.
 Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:BusSystem"

\end_inset

 zeigt den vereinfachten Aufbau eines Bus-Systems wie es auf aktuellen Mainboard
s zu finden ist.
 
\end_layout

\begin_layout Standard
Es soll folgend der Ablauf einer Matrix-Zerlegung auf der GPU und CPU beschriebe
n werden:
\end_layout

\begin_layout Subparagraph
CPU:
\end_layout

\begin_layout Enumerate
CPU erzeugt und belegt Matrix A im RAM (typische Transferraten von 100GB/sec)
\end_layout

\begin_layout Enumerate
CPU zerlegt Matrix A im RAM 
\end_layout

\begin_layout Subparagraph
GPU:
\end_layout

\begin_layout Enumerate
CPU erzeugt und belegt Matrix A im RAM (typische Transferraten von 100GB/sec)
\end_layout

\begin_layout Enumerate
GPU kopiert Matrix A vom RAM in den GPU-RAM über den PCIe Bus (typische
 Transferraten von 15GB/sec)
\end_layout

\begin_layout Enumerate
GPU zerlegt Matrix A im GPU-RAM (typische Transferraten von 320GB/sec)
\end_layout

\begin_layout Enumerate
GPU kopiert Matrix A zurück in den RAM (typische Transferraten von 15GB/sec)
\end_layout

\begin_layout Standard
Wie man erkennt, kann der PCIe Bus mit 15GB/sec (Stand 2017) zum Flaschenhals
 der Operation werden.
 Die Beschleunigung der Rechnung auf der Karte selbst, muss den Overhead
 des Transfers überwiegen.
 Erst dann lohnt sich der Einsatz einer solchen GPU.
 
\end_layout

\begin_layout Standard
Ob der praktische Einsatz für ein Kriging-Verfahren wie es in AutoOpti verwendet
 wird sinnvoll ist, soll innerhalb dieses Abschnittes beleuchtet werden.
 In 
\begin_inset CommandInset citation
LatexCommand cite
key "Toal2016"

\end_inset

 wird die Verwendung von GPUs innerhalb eines Kriging-Verfahren bereits
 als gewinnbringend beschrieben.
 Innerhalb dieser Arbeit wurden allerdings nur kleine Matrizen betrachtet
 (n<1000), die verwendete Bibliothek nicht beschrieben, die Overhead-Anteile
 nicht beschrieben und auch die Fließkommagenauigkeit wurde nicht angegeben.
 Dies kann von Bedeutung sein, da eine höhere Genauigkeit (von 64Bit) bei
 einigen GPUs zu massiven Leistungseinbrüchen führt.
 Weiterhin stellt sich auch die Frage, ob es während einer Optimierung möglich
 und sinnvoll ist, mehrere Trainings auf einer GPU durchzuführen.
 Folgend sollen diese Fragestellungen betrachtet werden.
\end_layout

\begin_layout Paragraph
Umgesetzte Algorithmen 
\end_layout

\begin_layout Standard
Wie bereits erwähnt, ist es nicht sinnvoll alle Algorithmen als GPU-Version
 umzusetzen, da diese durch den Transfer letztlich langsamer wären.
 Aus diesem Grund sind in der 
\begin_inset Quotes gld
\end_inset


\shape italic
CudaMatrix
\shape default

\begin_inset Quotes grd
\end_inset

 Klasse (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Matrixoperationen"

\end_inset

 ), nur die zeitkritischen Algorithmen implementiert.
 Für alle anderen wird die 
\begin_inset Quotes gld
\end_inset


\shape italic
OpenMPMatrix
\shape default

\begin_inset Quotes grd
\end_inset

-Klasse verwendet.
 Die dort implementierten Algorithmen sind: 
\end_layout

\begin_layout Itemize
Cholesky Zerlegung
\end_layout

\begin_layout Itemize
Rückwärtsdifferenzierte Cholesky Zerlegung
\end_layout

\begin_layout Itemize
Matrix Multiplikation, Addition, Subtraktion
\end_layout

\begin_layout Itemize
Lösen eines Gleichungssystem mit zerlegter Matrix
\end_layout

\begin_layout Standard
Die genaue Umsetzung ist in 
\begin_inset CommandInset citation
LatexCommand cite
key "kueppers2016,kueppers2016b,Kueppers2016c"

\end_inset

 beschrieben.
 
\end_layout

\begin_layout Paragraph*
Fließkommagenauigkeit
\end_layout

\begin_layout Standard
Innerhalb eines Kriging Verfahrens ist es praktisch unerlässlich die numerischen
 Berechnung mit doppelter Fließkommagenauigkeit (64Bit) durchzuführen.
 Aus diesem Grund sollte die Leistung der einzelnen GPU-Architekturen berücksich
tigt werden.
 In Tabelle 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Vergleich-der-Rechenleistung"

\end_inset

 sind alle NVidia Architekturen der letzten Jahre gelistet.
\begin_inset Wrap table
lines 0
placement o
overhang 0col%
width "50col%"
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="6" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Architektur
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Jahr
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
DP/SP
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Fermi
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2010
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1/2x
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Kepler
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2012
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1/3x
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Maxwell
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2014
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1/32x
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Pascal
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2016
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1/2x
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Volta
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2017
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1/2x
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:Vergleich-der-Rechenleistung"

\end_inset

Vergleich der Rechenleistung verschiedener NVidia Architekturen bei Double
 Precision (64Bit) und Single Precision (32Bit)
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Auffällig ist hier die Maxwell Architektur die eine deutlich niedrigere
 Leistung bei doppelter Genauigkeit bringt.
 Die Unterschiede liegen meist in der Prozessorarchitektur begründet, so
 haben die Kepler GPUs der Tesla Reihe alle pro SP-Core einen zusätzlich
 DP-Core.
 Daher auch das Verhältnis von 1/3.
 Die Maxwell Architektur verzichtet hingegen auf jegliche DP-Einheiten und
 kann doppelte Genauigkeit nur 
\begin_inset Quotes gld
\end_inset

emulieren
\begin_inset Quotes grd
\end_inset

.
\end_layout

\begin_layout Paragraph
Wirtschaftliche Betrachtung
\end_layout

\begin_layout Standard
Neben der reinen Rechenleistung sollten auch wirtschaftliche Aspekte Berücksicht
igt werden.
 Insbesondere spielen der Straßenpreis und auch der Stromverbrauch eine
 sehr wichtige Rolle.
 In Anhang 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Wirtschaftliche-Betrachtung-CPUGPU"

\end_inset

 ist ein tabellarischer Vergleich zwischen verschiedenen GPUs und CPUs angestell
t worden, besonders wichtig sind dabei die Werte Watt/GFlop und GFlop/Euro.
 Hier ist schnell ersichtlich, dass in beiden Punkten der Einsatz von GPUs
 rentabel ist.
 Allerdings beruht der Vergleich auf der theoretischen Rechenleistung, welche
 nicht immer erreicht werden kann.
 Die oftmals vertretene Meinung, dass viele Algorithmen aufgrund der schlechten
 Parallelisierbarkeit besser auf CPUs ausführbar sind, stimmt nur noch bedingt
 (siehe Tabelle 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:CoresCPUGPU"

\end_inset

).
 
\end_layout

\begin_layout Standard
Der Energieverbrauch pro Rechenleistung ist mittlerweile ein sehr wichtiges
 Kriterium für die Auswahl einer geeigneten CPU/GPU für einen Supercomputer.
 Dies wird sehr schnell klar, wenn man sich die leistungsstärksten Supercomputer
 ansieht (Stand Juni 2018), da diese bereits mehrere Megawatt an Leistung
 benötigen:
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="7" columns="5">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Energiebedarf
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
CPUs/GPUs
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Rechenleistung
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Standort
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Summit
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
15000kW
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
IBM Power9+Nvidia V100
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
200000 TFlop
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
USA
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
TaihuLight
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
15379kW
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Sunway SW26010
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
93014 TFlop
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
China
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Tianhe-2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
17808 kW
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Intel E5-2692+Phi 31S1P
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
33862 TFlop
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
China
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Piz Daint
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2272kW
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Intel E5-2690+Nvidia P100
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
19590 TFlop
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Schweiz
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
...
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
...
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
...
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
...
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
...
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Hazel Hen
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3200kW
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Intel E5-2680
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
7420 TFlop
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Deutschland
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:Architektur-und-Energiebedarf"

\end_inset

Architektur und Energiebedarf der Supercomputer mit der höchsten theoretischen
 Rechenleistung (Stand Juni 2018)
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Wrap figure
lines 0
placement o
overhang 0col%
width "50col%"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../images/SoftwareTechnUmsetzung/GPUSupercomputerEntw.png
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Top500GPUAnteile"

\end_inset

Entwicklung der Beschleuniger-Anteile an Supercomputern (Quelle:
\begin_inset CommandInset citation
LatexCommand cite
key "top500"

\end_inset

)
\end_layout

\end_inset


\end_layout

\end_inset

Weiterhin ist erkennbar, dass der Anteil an GPUs stark zugenommen hat, was
 bei der benötigten Leistung nachvollziehbar ist.
 Vergleicht man die Spitzenmodelle von Nvidia (V100) mit dem Platinum 8180
 von Intel, so liegt der Energiebedarf bei 0.04Watt/GFlop (V100) im Vergleich
 zu 0.134 Watt/GFlop (Platinum 8180).
 Der in TaihuLight-Supercomputer stellt hier eine Ausnahme dar und verwendet
 die in China entwickelten SunWay Prozessoren, diese Entscheidung hatte
 allerdings politisch motivierte Hintergründe (siehe 
\begin_inset CommandInset citation
LatexCommand cite
key "USRegu2015"

\end_inset

).
 Die Supercomputer in Deutschland sind vergleichsweise ineffizient was Leistung
 und Verbrauch angeht, da meist keine Beschleunigerkarten verwendet werden.
 Der globale Trend zeigt allerdings eine deutliche Zunahme, wie Abbildung
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Top500GPUAnteile"

\end_inset

 zeigt.
\end_layout

\begin_layout Paragraph*
Benchmarks
\end_layout

\begin_layout Standard
Innerhalb dieses Abschnittes sollen einige Benchmark-Ergebnisse der entwickelten
 Kriging-Software gezeigt werden.
 Im ersten Teil geht es um die Ausnutzung der theoretischen Rechenleistung,
 damit soll die Frage geklärt werden, ob es möglich ist die voll Kapazität
 einer GPU innerhalb eines Kriging Verfahrens zu nutzen.
 Danach sollen die Overhead-Anteile in Abhängigkeit der Matrixgröße, für
 ein Training gezeigt werden.
 Als letzter Punkt soll dann die Nutzung mehrerer Trainings auf einer GPU
 gezeigt werden.
 
\end_layout

\begin_layout Subparagraph*
Vergleich der theoretischen und erreichten Rechenleistung für ein Training
\end_layout

\begin_layout Standard
Folgende Tabelle zeigt die theoretische und die real gemessene Rechenleistung
 für ein Training mit 10000-15000 Stützstellen und 20 Parametern für verschieden
e Hardware-Konfigurationen.
 Die Anzahl der Trainingsschritte sowie die Ergebnisse waren jeweils identisch.
 
\end_layout

\begin_layout Standard
Als Referenz wurde ein Rechner mit 2xIntel Xeon E5-2695v2 verwendet.
 Die GPU-Benchmarks wurden auf dem NVidia-PSG-Cluster 
\begin_inset CommandInset citation
LatexCommand cite
key "Nvidia2018"

\end_inset

 ausgeführt
\begin_inset Foot
status open

\begin_layout Plain Layout
An dieser Stelle möchte ich mich persönlich bei NVidia bedanken, für die
 Möglichkeit die Benchmarks auf dem PSG-Cluster ausführen zu dürfen.
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="6" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Name
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Theoret.
 Beschleunigung
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Erreichte Beschleunigung
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2xIntel E5-2695v2 (Ref.)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1x
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1x
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2xIntel E5-2698v3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2.55x
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2.58x
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Nvidia K40
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3.11x
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3.6x
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2xNvidia K40
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
6.22x
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
6.21x
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Nvidia K80
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
6.3x
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5.32x
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:SollIstBenchmarksGPU"

\end_inset

Theoretische und erreichte Werte der Benchmarks 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Die Ergebnisse zeigen, dass bei nahezu allen Benchmarks die theoretische
 Beschleunigung erreicht wurde.
 Die einzige Ausnahme stellt die K80 dar, diese hat allerdings zwei Prozessoren
 auf einer Platine und stellt somit einen Sonderfall dar.
 Die theoretischen Werte liegen bei dieser Karte mit hoher Wahrscheinlich
 niedriger.
 
\end_layout

\begin_layout Standard
Grundsätzlich lässt sich aber sagen, dass die Rechenkapazität der GPUs für
 ein Kriging Verfahren sehr gut Nutzbar ist.
 
\end_layout

\begin_layout Subparagraph*
Overhead-Anteile bei der Berechnung
\end_layout

\begin_layout Standard
\begin_inset Wrap figure
lines 0
placement o
overhang 0col%
width "50col%"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../images/SoftwareTechnUmsetzung/GPUOverhead.png
	scale 20

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:OverheadGPU"

\end_inset

Overhead-Anteile bei einem Kriging-Training mit einer GPU (Nvidia K6000)
\end_layout

\end_inset


\end_layout

\end_inset

Wie bereits beschrieben, muss im Vergleich zu einer CPU, ein zusätzlicher
 Transfer durchgeführt werden und eine Initialisierung durchlaufen werden.
 Beides schmälert die Rechenleistung der GPU.
 Daher soll folgend ein Benchmark gezeigt werden, in dem die Anteile der
 Initialisierung und des Transfers im Vergleich zu der Rechenzeit ins Verhältnis
 gesetzt werden.
 Bei dem Beispiel handelt es sich um dasselbe wie in Tabelle 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:SollIstBenchmarksGPU"

\end_inset

 gezeigt.
 Allerdings wurde das Benchmark auf eine NVidia-Quadro-K6000 durchgeführt.
 
\end_layout

\begin_layout Standard
In Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:OverheadGPU"

\end_inset

 sind die Ergebnisse zu sehen.
 Bis zu einer Matrixgröße von 2000x2000 steigt der prozentuale Anteil des
 Transfers und liegt bei ca.
 15% der gesamten Zeit.
 Die Initialisierung benötigt immer eine konstante Zeit und daher nimmt
 der Anteil mit steigender Größe kontinuierlich ab.
 Erst ab einer Größe von 2000x2000 kann die GPU das volle Potential nutzen.
 Weitere Entwicklungen der Hardware (PCIe 4.0 und NVLink) werden diesen Wert
 mit der Zeit allerdings verkleinern.
\end_layout

\begin_layout Paragraph*
GPU Resourcenverteilung bei parallelen Trainings
\end_layout

\begin_layout Standard
Aufgrund der besonderen Beschaffenheit von GPUs, stellt sich die Frage,
 inwiefern diese Zusatzkarten Multiprozessfähig sind.
 Besonders wichtig ist hierbei der Punkt, wie die Karten damit umgehen,
 wenn mehrere Prozesse sich die Resource teilen.
 Also bspw.
 mehrere Trainings auf einer GPU gleichzeitig ausgeführt werden.
 Die Schwierigkeit liegt dabei in der Übertragung auf die GPU und auch in
 der Ausführung der unterschiedlichen Prozess auf einer Karte, da diese
 sehr stark auf einen Prozess ausgelegt sind, welcher den GPU-Speicher linear
 durchläuft und so die volle Bandbreite des Speichers nutzen kann.
\end_layout

\begin_layout Standard
Greifen mehrere Prozesse auf unterschiedliche Bereiche des GPU-Speichers
 zu, so kann die Performance der Karte stark darunter leiden.
 Letztlich hängt dies von der Lastaufteilung innerhalb der Karte ab, welche
 von 
\begin_inset Quotes gld
\end_inset

außen
\begin_inset Quotes grd
\end_inset

 schwer beeinflussbar ist.
 Aus diesem Grund wurde ein Benchmark ausgeführt (siehe Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:MultiTrainingsBenchmark"

\end_inset

), bei dem jeweils 2 und 4 gleichzeitige Trainings bei unterschiedlicher
 Matrixgröße getestet wurden.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "75col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename ../images/SoftwareTechnUmsetzung/GPUBenchmarks.png
	lyxscale 20
	scale 10
	BoundingBox 0bp 1550bp 3565bp 3028bp
	clip

\end_inset


\end_layout

\end_inset


\begin_inset space \hspace*{\fill}
\end_inset


\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "21col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:MultiTrainingsBenchmark"

\end_inset

Vergleich von mehreren Trainings gleichzeitig auf verschiedenen CPUs und
 GPUs
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Das Ergebnis zeigt, dass die Geschwindigkeit nahezu linear mit Anzahl der
 Trainings skaliert und sich damit die Rechenkapazität der Karten noch deutlich
 besser nutzen lassen.
 Jedoch kann der GPU-RAM eine Beschränkung darstellen, so wie es bei 4 gleichzei
tigen Trainings auf einer K40 bei 15000 Stützstellen zu sehen ist.
 
\end_layout

\begin_layout Standard
Weiterhin wurden noch Tests durchgeführt, wie gut sich zwei unterschiedliche
 starke GPUs mit mehreren Trainings bedienen lassen, die Ergebnisse sind
 in Anhang 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:GPU-Resourcenverteilung-ParalleleTrainigns"

\end_inset

 zu finden.
\end_layout

\begin_layout Paragraph*
Nvidia K40 / K6000 Bios
\end_layout

\begin_layout Standard
Für die Benchmarks standen über das NVidia-PSG Cluster K40 und K80 GPUs
 zur Verfügung.
 Danach war innerhalb des Instituts für Antriebstechnik jedoch nur noch
 eine NVidia Quadro K6000 vorhanden, grundsätzlich besitzen die GPUs dieselben
 Prozessoren (GK110) und RAM (GDDR5 384Bit ECC).
 Zwischen den GPUs konnte ein Leistungsunterschied von ca.
 30% festgestellt werden.
 Der Unterschied in den Karten ist rein durch das GPU-Bios festgelegt, und
 entsteht durch den sogenannten 
\begin_inset Quotes gld
\end_inset

PowerTable
\begin_inset Quotes grd
\end_inset

, in diesem sind die elektrischen-Leistungen für die verschiedenen Taktfrequenzb
ereiche der GPU festgelegt.
 Die Werte der maximalen Leistung der K6000 liegen deutlich unter der K40,
 daher ist des der Karte nicht gestattet die volle Taktfrequenz zu erreichen.
 Durch das NVFlash-Tool ist es möglich das Bios der GPU zu manipulieren.
 Praktisch erfolgt dies durch Download des Bios, dann Editierung mit einem
 Hex-Editor und Upload.
 Bei der K6000 wurde dies durchgeführt und die Leistungswerte entsprechend
 der K40 angepasst.
 So war es möglich weitere Benchmarks mit der K6000 auf K40 Niveau durchzuführen.
\end_layout

\begin_layout Section
Laufzeit-Analysesoftware für Krigingmodelle
\begin_inset CommandInset label
LatexCommand label
name "sec:Laufzeit-Analysesoftware-für-Kri"

\end_inset


\end_layout

\begin_layout Standard
Während einer Optimierung werden mehrere Ersatzmodelle trainiert, wobei
 das Training sehr häufig durchgeführt wird.
 Aus diesem Grund ist es von großer Bedeutung, die Ersatzmodelle während
 einer Optimierung stetig zu überwachen.
 Besonderer Wert sollte dabei auf folgende Punkte gelegt werden:
\end_layout

\begin_layout Itemize
Güte der einzelnen Ersatzmodelle 
\end_layout

\begin_layout Itemize
Trainingszeit
\end_layout

\begin_layout Itemize
Evtl.
 Fehler in den Daten oder in der Prozesskette
\end_layout

\begin_layout Standard
Um eine solche Überwachung übersichtlich zu gestalten, wurde im Rahmen dieser
 Arbeit eine Software entwickelt, welche den aktuellen Stand der Ersatzmodelle
 und die Entwicklung grafisch darstellt.
 Das Programm wurde in der Programmiersprache Python geschrieben und erzeugt
 nach Ausführung eine PDF Datei.
 Folgend sollen einige der wichtigsten grafischen Ausgaben gezeigt und deren
 Einsatz erläutert werden.
 Als Beispiel wird dafür das Mukoko Projekt verwendet, welches in Kapitel
 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Reale-Turbomaschinen-Optimierung"

\end_inset

 noch ausführlicher beschrieben wird.
\end_layout

\begin_layout Subsection*
Vorhersagefehler
\end_layout

\begin_layout Standard
\begin_inset Wrap figure
lines 13
placement o
overhang 0in
width "50col%"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../images/khonprediction.pdf
	scale 70
	BoundingBox 0bp 0bp 563bp 376bp
	clip

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:KhonFehlerVorhersage"

\end_inset

Exemplarische Ausgabe eines vorhergesagten Fehlers der maximalen mechanischen
 Dehnung eines Rotors.
 
\end_layout

\end_inset


\end_layout

\end_inset

Eine einfache Möglichkeit die Qualität der Ersatzmodelle zu bestimmen ist
 die Überprüfung der Differenz zwischen Vorhersage und realen Werten.
 Da der Optimierungsalgorithmus aber ein exploratives Vorgehen (siehe Kapitel
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:EVG"

\end_inset

) wählen kann, ist es möglich, dass dieser bewusst Vorhersagen mit hoher
 vorhergesagter Standardabweichung auswählt.
 Entsprechend sollte auch der Vorhersagefehler an solchen Stellen größer
 sein.
 Daher ist diese Art der Überprüfung sehr ungenau und macht prinzipiell
 nur über lange Zeiträume Sinn.
 Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:KhonFehlerVorhersage"

\end_inset

 zeigt den typischen Verlauf eines solchen Vorhersagefehlers.
 In blau dargestellt sind die Vorhersagen der Stützstellen und in rot die
 nachgerechneten Werte.
 Die angezeigten Fehlerbalken entsprechen der vorhergesagten Standardabweichung.
 Die X-Achse stellt die jeweilige Optimierungsiteration dar.
 Die grüne Kurve beschreibt die absolute Differenz zwischen Vorhersage und
 realem Wert.
 In dieser Abbildung ist erkennbar, dass zu anfang der Optimierung die vorherges
agte Standardabweichung zu hoch ist, da nahzu keiner der echten Werte innerhalb
 der Fehlerbalken liegt.
 Erst nach ca.
 40 Iterationen ist eine Besserung erkennbar.
\end_layout

\begin_layout Subsection*
Entwicklung des Likelihoods
\end_layout

\begin_layout Standard
Der Verlauf des Likelihood-Werts ist eine sehr gute Möglichkeit das Training
 der Ersatzmodelle zu begutachten, sowie fehlerhafte Daten aufzudecken.
 In Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:KhonGobalConvergence"

\end_inset

 sind zwei verschiedene Plots unterschiedlicher Ersatzmodelle derselben
 Optimierung gezeigt.
 Auf der Ordinate ist der Likelihood-Wert aufgetragen, wobei ein möglichst
 kleiner Wert gut ist.
 Auf der Abszisse ist der Iterationsschritt der Optimierung dargestellt.
 Die roten Punkte stellen diejenigen Optimierungsschritt dar, in denen das
 Training noch nicht den 
\begin_inset Quotes gld
\end_inset


\shape italic
Restart
\shape default

\begin_inset Quotes grd
\end_inset

 Modus (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:UltraRestart"

\end_inset

) verwendet hat.
 Solange dieser Plot noch rote Punkte aufweist, kann davon ausgegangen werden,
 dass die Hyperparameter der Ersatzmodelle noch nicht optimal eingestellt
 sind.
 
\end_layout

\begin_layout Standard
Weiterhin lassen sich auch Aussagen über die Güte der Daten anhand des Kurvenver
laufs treffen.
 In Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:KhonGobalConvergence"

\end_inset

 rechts, ist ab Iteration 1000 ein Ausreißer im Verlauf des Likelihood-Plots
 zu sehen.
 Dieser Ausreißer wurde während der laufenden Optimierung bemerkt und es
 konnte ein Fehler in den Daten festgestellt werden.
 Dieser resultierte aus einer Prozesskettenänderung während der Laufzeit
 und führet zu fehlerhaften Daten.
 Der Fehler konnte während der Laufzeit behoben werden und die Optimierung
 mit wenig Zeitverlust fortgesetzt werden.
 Ohne diese grafische Darstellung wäre es in der damaligen Optimierung zu
 einem erheblichen Zeitverlust gekommen.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../images/SoftwareTechnUmsetzung/Mukoko/khon_global_convergence1.png
	scale 70

\end_inset


\begin_inset Graphics
	filename ../images/SoftwareTechnUmsetzung/Mukoko/khon_global_convergence12.png
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:KhonGobalConvergence"

\end_inset

Verlauf von zwei Ersatzmodellen der Mukoko Optimierung, wobei das rechte
 Ersatzmodell fehlerhafte Daten bekam
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection*
Hyperparameter auf Plausibilität überprüfen
\end_layout

\begin_layout Standard
\begin_inset Wrap figure
lines 0
placement o
overhang 0col%
width "50col%"
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../images/SoftwareTechnUmsetzung/Mukoko/matrix.png
	scale 30

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Hyperparameter-Matrix-aus-einer"

\end_inset

Hyperparameter-Matrix aus einer laufenden Optimierung
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset

Die eingestellten Hyperparameter von allen Ersatzmodellen während einer
 Optimierung zu überprüfen ist aufgrund der bloßen Anzahl bereits sehr schwierig.
 Betrachtet man bspw.
 die Mukoko Optimierung, so wurden 38 Ersatzmodelle verwendung und 158 Parameter
, was zu über 6000 Hyperparametern führt.
 Dennoch ist es zumindest möglich eine Plausibilitäts-Überprüfung durchzuführen.
 Hierfür müssen die Optimierungsparameter und auch die Ersatzmodelle sinnvoll
 numeriert werden.
 Bspw.
 sollten alle Parameter von einem Rotor in einer Reihe vorkommen oder die
 Aerodynamischen und Strukturmechanischen Ersatzmodelle jeweils in einer
 Gruppierung sein.
 Typischerweise wird eine solche Gruppierung naturgemäß von den Anwendern
 gewählt, da diese oft die übersichtlichste Darstellung bietet.
\end_layout

\begin_layout Standard
Versteht man die Hyperparameter eines Ersatzmodells als eine Art 
\begin_inset Quotes gld
\end_inset


\shape italic
Wichtigkeit
\shape default

\begin_inset Quotes grd
\end_inset

 des Parameters, so kann man diese bspw.
 nach Größe einfärben.
 In dem gewählten Plot, stellt grün einen hohen Wert dar und rot einen sehr
 niedrigen.
 Damit lässt sich eine grafische Matrix Erzeugen wie sie exemplarisch in
 Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Hyperparameter-Matrix-aus-einer"

\end_inset

 gezeigt wird.
 Innerhalb dieses Plots sind grüne und rote/gelbe Blöcke zu erkennen.
 Bspw.
 sieht man, dass die Statoren 1&2 für die Strukturmechanik keine Rolle zu
 spielen scheinen.
 Diese Information ist plausibel, da die Statoren für die strukturmechanische
 Bewertung auch keine Rolle gespielt haben.
 Weiterhin kann man zwischen Rotor 1 und Rotor 2 alternierende grüne/rote
 Blöcke im Bereich der strukturmechnischen Ersatzmodelle erkennen.
 Auch diese Information ist plausibel, da die freien Variablen für Rotor
 1 natürlich nur einen sehr geringen Einfluss auf die strukturmechanischen
 Ergebnisse von Rotor 2 haben sollten.
 
\end_layout

\begin_layout Standard
Mithilfe dieser einfachen Informationen ist es zumindest grob möglich, die
 Plausibilität der Ersatzmodelle auf einfache Weise zu überprüfen.
 
\end_layout

\begin_layout Subparagraph*
Hyperparameter Co-Kriging 
\end_layout

\begin_layout Standard
Im Falle eines Co-Kriging Modells existieren mehrere Kovarianzfunktionen
 und damit Hyperparametersätze.
 Für den gezeigten Matrix-Plot möchte man allerdings nur einen zusammengesetzten
 Satz sehen.
 Im Folgenden soll eine Möglichkeit gezeigt werden, diese grafische zusammenzufa
ssen:
\end_layout

\begin_layout Standard
Angenommen alle Parameter außer dem betrachteten Parameter spielen keine
 Rolle, dann vereinfacht sich die Gauss-Korrelations-Formel zu:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
cov\left(x_{1},x_{2}\right)=a^{2}*\sigma_{l}^{2}*e^{-e^{\theta_{l}}\left|x_{1}-x_{2}\right|^{2}}+\sigma_{err}^{2}*e^{-e^{\theta_{err}}\left|x_{1}-x_{2}\right|^{2}}
\]

\end_inset


\end_layout

\begin_layout Standard
Nimmt man weiterhin an, dass der Abstand 
\begin_inset Formula $\left|x_{1}-x_{2}\right|=1$
\end_inset

 ist, vereinfacht sich die Formel weiter.
 Diese Annahme ist in der hier verwendeten Implementierung sinnvoll, da
 alle Koordinaten auf einen Erwartungswert von 0 und eine Standardabweichung
 von 1 normiert wurden.
 
\begin_inset Formula 
\[
cov\left(x_{1},x_{2}\right)=a^{2}*\sigma_{l}^{2}*e^{-e^{\theta_{l}}}+\sigma_{err}^{2}*e^{-e^{\theta_{err}}}
\]

\end_inset


\end_layout

\begin_layout Standard
Die Gesamtvarianz des Modells liegt bei:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\sigma_{ges}^{2}=a^{2}*\sigma_{l}^{2}+\sigma_{err}^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
Die Korrelation wird hier als sinnvolleres Maß als die Kovarianz angesehen,
 da der Wertebereich bekannt ist.
 Die Korrelation ergibt sich wie folgt:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
corr_{ges}\left(x_{1},x_{2}\right)=\frac{cov\left(x_{1},x_{2}\right)}{\sigma_{ges}^{2}}=\frac{a^{2}*\sigma_{l}^{2}*e^{-e^{\theta_{l}}}+\sigma_{err}^{2}*e^{-e^{\theta_{err}}}}{a^{2}*\sigma_{l}^{2}+\sigma_{err}^{2}}
\]

\end_inset


\end_layout

\begin_layout Standard
Mit dieser Formel hat man eine Abschätzung für einen zusammengefassten Hyperpara
meter, dieser ermöglicht z.B.
 Diagramme.
\end_layout

\begin_layout Paragraph*
Anteile der Differenz- und Low-Fidelity-Lovarianzfunktion 
\end_layout

\begin_layout Standard
Im Falle einer Multifidelity Optimierung ist oft von Interesse, wie stark
 die verschiedenen Gütestufen in das Co-Kriging Modell einfließen.
 Von Anwenderseite ist ein einfacher Prozentwert wünschenswert, da dieser
 einfach zu interpretieren ist.
 Eine Möglichkeit der Abschätzung eines solchen prozentualen Anteils ist
 es von einer vollen Korrelation auszugehen und die Anteile der Kovarianz
 hoher Güte im Verhältnis der Kovarianz niedriger Güte.
 Betrachtet man hierfür den Teil 
\begin_inset Formula $cov_{1,1}$
\end_inset

 und 
\begin_inset Formula $cov_{2,2}$
\end_inset

 von Gleichung 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:KovarianzfunktionenCoKrigingGauss"

\end_inset

 und geht weiterhin von einer vollen Korrelation 
\begin_inset Formula $c_{2}\left(\vec{h}\right)=1$
\end_inset

, 
\begin_inset Formula $c_{diff}\left(\vec{h}\right)=1$
\end_inset

 aus und vernachlässigt den Rauschterm 
\begin_inset Formula $\lambda_{diff}$
\end_inset

, so ergibt sich:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
cov_{1,1}\left(\vec{h}=0\right)= & a^{2}\sigma_{2}^{2}+\sigma_{diff}^{2}\\
cov_{2,2}\left(\vec{h}=0\right)= & a^{2}\sigma_{2}^{2}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Setzt man die beiden Terme ins Verhältnis 
\begin_inset Formula $LF_{perc}=\frac{a^{2}\sigma_{2}^{2}}{a^{2}\sigma_{2}^{2}+\sigma_{diff}^{2}}$
\end_inset

 so erhält man eine einfache Abschätzung des Anteils der Kovarianzfunktion
 niedriger Güte 
\begin_inset Formula $cov_{2,2}$
\end_inset

 an der Kovarianz hoher Güte 
\begin_inset Formula $cov_{1,1}$
\end_inset

 bei voller Korrelation.
 Geht man bspw.
 von den Extremfällen aus:
\end_layout

\begin_layout Enumerate
Hohe und niedrige Güte unkorreliert
\end_layout

\begin_layout Enumerate
Hohe und niedrige Güte identisch
\end_layout

\begin_layout Standard
Ergeben sich folgende Werte:
\end_layout

\begin_layout Enumerate
Dieser Fall wird beim Training durch den Skalierungsfaktor gelöst, dieser
 wird auf Null gesetzt und damit eine vollständige Unkorreliertheit erreicht.
 Der Anteil der Kovarianzfunktion niedriger Güte wäre dann: 
\begin_inset Formula $LF_{perc}=\frac{0\sigma_{2}^{2}}{0\sigma_{2}^{2}+\sigma_{diff}^{2}}=0$
\end_inset

 
\end_layout

\begin_layout Enumerate
Sind beide Funktionen identisch, so wird die Differenzkovarianzfunktion
 nicht benötigt und im Training durch 
\begin_inset Formula $\sigma_{diff}^{2}=0$
\end_inset

 ausgeschaltet.
 Der Anteil der Kovarianzfunktion niedriger Güte wäre dann: 
\begin_inset Formula $LF_{perc}=\frac{a^{2}\sigma_{2}^{2}}{a^{2}\sigma_{2}^{2}+0}=1$
\end_inset


\end_layout

\begin_layout Standard
Die Gewichtung der beiden Kovarianzfunktionen durch die Hyperparameter 
\begin_inset Formula $\vec{\theta}\in\mathbb{R^{\textrm{k}}}$
\end_inset

 (siehe Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Kovarianz-parametrisiertes-Model"

\end_inset

) werden damit allerdings nicht dargestellt.
 Dennoch kann diese Art der Darstellung eine einfache und schnelle Methode
 sein, um einen Eindruck der Gewichtungen untereinander zu bekommen.
 In Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:ASME-Veröffentlichung:-Optimieru"

\end_inset

 wird ein erfolgreiches Beispiel aus einer Optimierung eines transsonischen
 Verdichters gezeigt.
 Bei einigen Ersatzmodellen dieser Optimierung war bekannt, dass einige
 Daten niedriger Güte keinen Korrelation zu den Daten hoher Güte aufweisen
 können.
 Dies konnte in der entsprechenden Grafik (siehe Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Anteile-der-Kovarianzfunktionen"

\end_inset

 - Ersatzmodell Nummer 9) erkannt werden.
 
\end_layout

\begin_layout Standard
Ein weiteres Beispiel aus Kapitel 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Kopplung-mehrerer-Ersatzmodelle:"

\end_inset

 entspricht dem Gegenteiligen Fall.
 Die Berechnung der maximale mechanische Dehnung des Rotors, war in beiden
 Gütestufen identisch.
 Dies konnte ebenfalls in der entsprechenden Abbildung 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Anteile-der-Kovarianzfunktionen-1"

\end_inset

 (Ersatzmodell Nummer 6) erkannt werden.
 
\end_layout

\end_body
\end_document
